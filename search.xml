<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>github文件夹有白色箭头并且不能打开的解决办法</title>
    <url>/2022/11/20/github%E6%96%87%E4%BB%B6%E5%A4%B9%E6%9C%89%E7%99%BD%E8%89%B2%E7%AE%AD%E5%A4%B4%E5%B9%B6%E4%B8%94%E4%B8%8D%E8%83%BD%E6%89%93%E5%BC%80%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
    <content><![CDATA[<p>Github文件夹有白色箭头并且不能打开?可能是因为你提交的Git文件中有叫做.git的文件！</p>
<span id="more"></span>

<h1 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1.问题描述"></a>1.问题描述</h1><p>前几天在Git上向GitHub提交了自己的文件，但是在GitHub却无法打开文件夹，并且文件夹上面还多了一个白色的箭头？本着求知的精神，我上百度上找了找，发现是因为我提交的这个文件本身就已经是Git仓库了，而子文件里面还藏着Git仓库，也就是说子文件里还有.git隐藏文件。因为层层的嵌套关系，导致GitHub对文件的识别发生了错误。</p>
<h1 id="2-解决方案"><a href="#2-解决方案" class="headerlink" title="2.解决方案"></a>2.解决方案</h1><p>把子文件的.git文件夹删掉就好了</p>
<ol>
<li>执行<code>git rm --cached [文件夹名]</code></li>
<li>执行<code>git add [文件夹名]</code></li>
<li>执行<code>git commit -m &quot;git folder report an error!&quot;</code></li>
<li>执行<code>git push origin [branch_name] </code></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/11/20/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>blog            //文章分类</category>
      </categories>
  </entry>
  <entry>
    <title>图像处理之扇形与矩形图像之间的相互转换</title>
    <url>/2022/11/23/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B%E6%89%87%E5%BD%A2%E4%B8%8E%E7%9F%A9%E5%BD%A2%E5%9B%BE%E5%83%8F%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<p>数字图像处理作业–将图像进行扇形和矩形之间的变换！</p>
<span id="more"></span>

<h1 id="图像处理之扇形与矩形图像之间的相互转换（Python）"><a href="#图像处理之扇形与矩形图像之间的相互转换（Python）" class="headerlink" title="图像处理之扇形与矩形图像之间的相互转换（Python）"></a>图像处理之扇形与矩形图像之间的相互转换（Python）</h1><h1 id="1-应用"><a href="#1-应用" class="headerlink" title="1.应用"></a>1.应用</h1><p>在分析扇形与矩形图像之间相互处理的程序之前，需要大概了解一下它们存在的意义是什么？</p>
<p>那当然字如其名，将扇形转化为矩形，将矩形转化为扇形啦！🤪🤪🤪</p>
<p>原理当然是这样，但是用处还是很多的！就比如说你上课的时候坐在角落，老师讲到重要内容的时候需要拍照记录。可是你拍出来的效果却是斜的，虽然勉强看的懂，但是看的不舒服。文档校正应运而生。当然，你斜着扫二维码的时候也是同种原理。即使你没有意识到，但是它却实实在在存在。该映射学术名称叫做中心投影变换 &amp;nbsp;  –&gt; &amp;nbsp;  <em><strong>Perspective Mapping</strong></em></p>
<p>我们的扇形与矩形之间的变换也有很多应用，只是我暂时没有想到。</p>
<h1 id="2-引用"><a href="#2-引用" class="headerlink" title="2.引用"></a>2.引用</h1><p>刚拿到课程题目的时候我不是很懂，于是上百度搜寻相关的资料。本着研究中心投影变换的初衷，但是却没想到找到了相关的代码，真是意外的收获。CSDN大佬<strong>天元浪子</strong>在这篇博文中是研究从矩形到扇形的变换，而我是相反的。代码我copy到了文末，用于与原来的代码作比较，下面是原文链接。</p>
<blockquote>
<p><a href="https://blog.csdn.net/xufive/article/details/104675998">https://blog.csdn.net/xufive/article/details/104675998</a></p>
</blockquote>
<p>如果需要用的是MATLAB，那么可以参考以下两个链接。</p>
<blockquote>
<p><a href="https://blog.csdn.net/u014495306/article/details/74079963">https://blog.csdn.net/u014495306/article/details/74079963</a></p>
<p><a href="https://blog.csdn.net/weixin_34068198/article/details/94256613">https://blog.csdn.net/weixin_34068198/article/details/94256613</a></p>
</blockquote>
<h1 id="3-使用"><a href="#3-使用" class="headerlink" title="3.使用"></a>3.使用</h1><p>代码我就不打算分析了，看注释很快就可以理解。</p>
<p>&#96;&#96;# -<em>- coding:utf-8 -</em>-</p>
<p>import numpy as np</p>
<p>from PIL import Image</p>
<p>import matplotlib.pyplot as plt</p>
<p>def square2fan(input, output, angle&#x3D;45):</p>
<h1 id="将扇形图像转化为矩阵图像"><a href="#将扇形图像转化为矩阵图像" class="headerlink" title="将扇形图像转化为矩阵图像"></a>将扇形图像转化为矩阵图像</h1><pre><code>input      - 输入文件名
output      - 输出文件名
angle       - 扇形夹角度数
angle在这个例子中是45度，如果改大的话将会缩小输出图片的宽度cols

im = Image.open(input)  # 打开输入图像为PIL对象 
mode = im.mode  # 输入图像模式\
w, h = im.size  # 输入图像分辨率(宽在前，高在后)
rows, cols = int(np.ceil(h)), int(np.ceil(w))  # 输出图像高度和宽度
in_interval = np.array(im)  # 输入图像转为numpy数组
# 生成输出图像的numpy数组（全透明）
out_interval = np.zeros((rows, cols, in_interval.shape[2]), dtype=np.uint8)

alpha = np.radians(np.linspace(-angle, angle, w))  # 生成扇形角度序列，长度与输入图像宽度一致
for i in range(w):  # 遍历输入图像的每一列
    # 当前列各像素在输出图像上的行号

    # d = np.cos(alpha[i])*h 和 d = np.cos(alpha[i])*rows效果等同，方便后边的切片
    d = np.cos(alpha[i])*h
    lats = np.int_(np.linspace(0, d, h)).astype(np.int)
    # 当前列各像素在输出图像上的列号
    d = np.sin(alpha[i])*h
    lons = np.int_(np.linspace(cols/2,
                   cols/2+d, h)).astype(np.int)
    # 将算出来的扇形的斜列的值，放进空矩阵中
    out_interval[:, i] = in_interval[(lats, lons)]
# 保存为文件
im = Image.fromarray(out_interval, mode=im.mode)
im.save(output)
</code></pre>
<p>if <strong>name</strong> &#x3D;&#x3D; ‘<strong>main</strong>‘:<br>    square2fan(‘out.png’, ‘rectangle.png’, angle&#x3D;45)</p>
<p>&#96;&#96;</p>
<h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h1><p>题目不难，但是花了我挺多时间，也暴露出了我一些问题…😅😅😅</p>
<blockquote>
<p>对Python的库不是很熟悉（其实不经常用，记不得我觉得也很正常）</p>
<p>嗯？让我想想我到底还有啥问题先？</p>
<p>……</p>
<p>好像并没有什么问题?😦</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>激活函数</title>
    <url>/2022/11/23/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p>学习一下机器学习中常见的激活函数，大部分只是了解即可，不必深究</p>
<span id="more"></span>

<h1 id="常用的激活函数"><a href="#常用的激活函数" class="headerlink" title="常用的激活函数"></a>常用的激活函数</h1><h2 id="首先要知道什么是激活函数？"><a href="#首先要知道什么是激活函数？" class="headerlink" title="首先要知道什么是激活函数？"></a>首先要知道什么是激活函数？</h2><p>激活函数就是在神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端。它类似于人类大脑中基于神经元的模型，激活函数最终决定了要发射给下一个神经元的内容。</p>
<p>它的可视化过程如图所示：</p>
<p><img src="https://ask.qcloudimg.com/http-save/8352478/mn5asmil0s.png?imageView2/2/w/1620" alt="激活函数工作过程"></p>
<p>如果不用激励函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合。神经网络中使用激活函数来加入非线性因素，提高模型的表达能力。</p>
<h2 id="1-sigmoid激活函数"><a href="#1-sigmoid激活函数" class="headerlink" title="1. sigmoid激活函数"></a>1. sigmoid激活函数</h2><p><img src="https://ask.qcloudimg.com/http-save/8352478/nhi9swy8ln.png?imageView2/2/w/1620" alt="sigmoid函数"></p>
<p>Sigmoid 函数的图像看起来像一个 S 形曲线。它的表达式如下：</p>
<p>f(z) &#x3D; \frac{1}{1+e^{-z} } </p>
<p>Sigmoid函数是传统神经网络中最常用的激活函数，一度被视为神经网络的核心所在。 </p>
<p>从数学上来看，Sigmoid函数对中央区的信号增益较大，对两侧区的信号增益小，在信号的特征空间映射上，有很好的效果。从神经科学上来看，中央区酷似神经元的兴奋态，两侧区酷似神经元的抑制态，因而在神经网络学习方面，可以将重点特征推向中央区，将非重点特征推向两侧区。</p>
<h3 id="1-1-在什么情况下适合使用-Sigmoid-激活函数呢？"><a href="#1-1-在什么情况下适合使用-Sigmoid-激活函数呢？" class="headerlink" title="1.1 在什么情况下适合使用 Sigmoid 激活函数呢？"></a>1.1 在什么情况下适合使用 Sigmoid 激活函数呢？</h3><ul>
<li>Sigmoid 函数的输出范围是 0 到 1。由于输出值限定在 0 到 1，因此它对每个神经元的输出进行了归一化；</li>
<li>用于将预测概率作为输出的模型。由于概率的取值范围是 0 到 1，因此 Sigmoid 函数非常合适；</li>
<li>梯度平滑，避免「跳跃」的输出值；</li>
<li>函数是可微的。这意味着可以找到任意两个点的 sigmoid 曲线的斜率；</li>
<li>明确的预测，即非常接近 1 或 0。</li>
<li></li>
</ul>
<h3 id="1-2-Sigmoid-激活函数有哪些缺点？"><a href="#1-2-Sigmoid-激活函数有哪些缺点？" class="headerlink" title="1.2 Sigmoid 激活函数有哪些缺点？"></a>1.2 Sigmoid 激活函数有哪些缺点？</h3><ul>
<li>倾向于梯度消失；</li>
<li>函数输出不是以 0 为中心的，这会降低权重更新的效率；</li>
<li>Sigmoid 函数执行指数运算，计算机运行得较慢。</li>
</ul>
<p>现在基本上已经用不上sigmoid函数了。</p>
<h2 id="2-TanHyperbolic（tanh）双曲正切激活函数"><a href="#2-TanHyperbolic（tanh）双曲正切激活函数" class="headerlink" title="2. TanHyperbolic（tanh）双曲正切激活函数"></a>2. TanHyperbolic（tanh）双曲正切激活函数</h2><p><img src="https://ask.qcloudimg.com/http-save/8352478/gm9p8du88z.png?imageView2/2/w/1620" alt="tanh函数"></p>
<p>tanh 激活函数的图像也是 S 形，表达式如下：</p>
<p>f(z) &#x3D; tanh(z) &#x3D;  \frac{e^{z} - e^{-z}  }{e^{z} + e^{-z} }  &#x3D; \frac{2}{1 + e^{-2z} }-1 </p>
<p>tanh 是双曲正切函数。tanh 函数和 sigmoid 函数的曲线相似。但是它比 sigmoid 函数更有一些优势。</p>
<ul>
<li><p>sigmoid函数和tanh函数都存在一个问题：当神经网络的层数增多的时候，由于在进行反向传播的时候，链式求导，多项相乘，函数进入饱和区（导数接近于零的地方）就会逐层传递，这种现象被称为梯度消失。</p>
</li>
<li><p>首先要明确的一点是，当输入较大或较小时，输出几乎是平滑的并且梯度较小，这不利于权重更新。tanh 整个函数以 0 为中心，比 sigmoid 函数更好。在实际操作的时候，tanh 函数延迟了饱和期，在特征相差比较明显的时候效果会更好，并且在循环过程中也能够不断地扩大特征的效果。</p>
</li>
<li><p>在一般的二元分类问题中，tanh 函数用于隐藏层，而 sigmoid 函数用于输出层，但这并不是固定的，需要根据特定问题进行调整。</p>
</li>
</ul>
<h2 id="3-softmax激活函数"><a href="#3-softmax激活函数" class="headerlink" title="3. softmax激活函数"></a>3. softmax激活函数</h2><p>公式表达为：</p>
<p>f(z) &#x3D; \frac{e^{Z_j} }{\sum_{k}^{}e^{Z_k} } </p>
<p>Sigmoid函数如果用来分类的话，只能进行二分类，而这里的softmax函数可以看做是Sigmoid函数的一般化，可以进行多分类。</p>
<h3 id="3-0-Softmax激活函数的特点："><a href="#3-0-Softmax激活函数的特点：" class="headerlink" title="3.0 Softmax激活函数的特点："></a>3.0 Softmax激活函数的特点：</h3><ul>
<li>在零点不可微。</li>
<li>负输入的梯度为零，这意味着对于该区域的激活，权重不会在反向传播期间更新，因此会产生永不激活的死亡神经元。</li>
</ul>
<h3 id="3-1-sigmoid与softmax比较-–-gt-sigmoid"><a href="#3-1-sigmoid与softmax比较-–-gt-sigmoid" class="headerlink" title="3.1 sigmoid与softmax比较 –&gt; sigmoid"></a>3.1 sigmoid与softmax比较 –&gt; sigmoid</h3><p>二分类和多分类其实没有多少区别。用的公式仍然是y &#x3D; wx + b。 但有一个非常大的区别是他们用的激活函数是不同的。 逻辑回归用的是sigmoid，这个激活函数的除了给函数增加非线性之外还会把最后的预测值转换成在[0,1]中的数据值。也就是预测值是0&lt;y&lt;1。 我们可以把最后的这个预测值当做是一个预测为正例的概率。在进行模型应用的时候我们会设置一个阈值，当预测值大于这个阈值的时候，我们判定为正例子，反之我们判断为负例。这样我们可以很好的进行二分类问题。 </p>
<h3 id="3-2-sigmoid与softmax比较-–-gt-softmax"><a href="#3-2-sigmoid与softmax比较-–-gt-softmax" class="headerlink" title="3.2 sigmoid与softmax比较 –&gt; softmax"></a>3.2 sigmoid与softmax比较 –&gt; softmax</h3><p>Softmax函数是用于多类分类问题的激活函数，在多类分类问题中，超过两个类标签则需要类成员关系。对于长度为K的任意实向量，Softmax函数可以将其压缩为长度为K，值在[0,1]范围内，并且向量中元素的总和为1的实向量。</p>
<blockquote>
<p>Softmax函数与正常的max函数不同：max函数仅输出最大值，但Softmax函数确保较小的值具有较小的概率，不会直接丢弃。我们可以认为它是arg max函数的概率版本或“soft”版本。Softmax函数的分母结合了原始输出值的所有因子，这意味着Softmax函数获得的各种概率彼此相关。</p>
</blockquote>
<blockquote>
<p>利用 softmax 可以用于多分类问题，而用多个logistic回归通过叠加也同样可以实现多分类的效果，但是 softmax回归进行的多分类，类与类之间是互斥的，即一个输入只能被归为一类。多个logistic回归进行多分类，输出的类别并不是互斥的，即”苹果”这个词语既属于”水果”类也属于”3C”类别。</p>
</blockquote>
<h2 id="4-ReLU-激活函数"><a href="#4-ReLU-激活函数" class="headerlink" title="4. ReLU 激活函数"></a>4. ReLU 激活函数</h2><p><img src="https://ask.qcloudimg.com/http-save/8352478/ck888so4in.png?imageView2/2/w/1620" alt="ReLu激活函数"></p>
<p>ReLu函数的全称为Rectified Linear Units–&gt;修正线性单元,表达式为</p>
<p>f(z) &#x3D; max(0,z)</p>
<h3 id="Sigmoid-，tanh与ReLU-比较"><a href="#Sigmoid-，tanh与ReLU-比较" class="headerlink" title="Sigmoid ，tanh与ReLU 比较"></a>Sigmoid ，tanh与ReLU 比较</h3><p>sigmoid，tanh 会出现梯度消失问题，ReLU 的导数就不存在这样的问题。</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>从计算的角度上，Sigmoid和Tanh激活函数均需要计算指数，复杂度高，而ReLU只需要一个阈值即可得到激活值。</li>
<li>ReLU的非饱和性有效地解决梯度消失的问题，提供相对宽的激活边界。</li>
<li>ReLU的单侧抑制，提供了网络的稀疏表达能力</li>
</ul>
<p><strong>稀疏表示（Sparse Representations）的定义：用较少的基本信号的线性组合来表达大部分或者全部的原始信号。</strong></p>
<p><em>具体稀疏性的体现是：Relu会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生。</em><strong>只能说有利有弊了…</strong></p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>Dead ReLU 问题。当输入为负时，ReLU 完全失效，在正向传播过程中，这不是问题。但是在反向传播过程中，如果输入负数，则梯度将完全为零，即在训练过程中会导致神经元死亡。sigmoid 函数和 tanh 函数也具有相同的问题。</li>
<li>我们发现 ReLU 函数的输出为 0 或正数，这意味着 ReLU 函数不是以 0 为中心的函数。</li>
</ul>
<p><strong>神经元死亡会导致该神经元在之后不被任何数据激活，即流经该神经元的梯度永远为0，不对任何数据产生响应。在实际训练中，如果学习率设置较大，会导致一定比例的神经元不可逆死亡，进而参数梯度无法更新，整个训练过程失败。</strong></p>
<h2 id="5-softplus激活函数"><a href="#5-softplus激活函数" class="headerlink" title="5. softplus激活函数"></a>5. softplus激活函数</h2><p>公式表达式为：</p>
<p>softplus(z)&#x3D;log(1+e^z)</p>
<p>softplus函数与ReLU函数接近,但比较平滑, 同ReLU一样是单边抑制,有宽广的接受域(0,+inf), 但是由于指数运算,对数运算计算量大的原因,而不太被人使用。</p>
<p><img src="https://images2018.cnblogs.com/blog/1252882/201807/1252882-20180707095338849-1750990328.png" alt="softplus激活函数"></p>
<p>可以看到，softplus可以看作是ReLu的平滑。根据神经科学家的相关研究，softplus和ReLu与脑神经元激活频率函数有神似的地方。也就是说，在生物层面上，相比于早期的激活函数，softplus和ReLu更加接近脑神经元的激活模型。其中，<strong>RELU函数的引入给神经网络增加了生物学特性，可以称为灵魂激活函数。</strong></p>
<p>softplus的导数就是sigmoid函数，还是很巧合的。还有一点就是，据说softplus的出现要比ReLu要早，也就是说softplus可以看成是ReLu的鼻祖？</p>
<h2 id="6-Leaky-ReLU激活函数"><a href="#6-Leaky-ReLU激活函数" class="headerlink" title="6. Leaky ReLU激活函数"></a>6. Leaky ReLU激活函数</h2><p>它是一种专门设计用于解决 Dead ReLU 问题的激活函数：</p>
<p><img src="https://ask.qcloudimg.com/http-save/8352478/zdls8bt48h.png?imageView2/2/w/1620" alt="Leaky ReLu"></p>
<p>当 x &lt; 0的时候， f(x) &#x3D; \alpha x,其中\alpha 非常小，这样可以避免在x &lt; 0的时候，不能够学习的情况。</p>
<p>f(x) &#x3D; max(\alpha x,x)</p>
<blockquote>
<p>将\alpha 作为可学习的参数，称为Parametric Rectifier(PReLU)</p>
<p>当\alpha 从高斯分布中随机产生时称为Random Rectifier（RReLU）</p>
<p>当固定为\alpha &#x3D; 0.01时,称为Leaky ReLU</p>
</blockquote>
<h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><ul>
<li>不会过拟合(saturate)</li>
<li>计算简单有效</li>
<li>比sigmoid&#x2F;tanh收敛快</li>
</ul>
<h2 id="7-其他常见的激活函数"><a href="#7-其他常见的激活函数" class="headerlink" title="7. 其他常见的激活函数"></a>7. 其他常见的激活函数</h2><p>其他常见的激活函数还有</p>
<ul>
<li>Noisy ReLU</li>
<li>指数线性单元ELU(exponential linear unit)</li>
<li>SELU</li>
<li>GELU</li>
<li>Swish</li>
<li>…</li>
</ul>
<p>还有挺多的激活函数没有列举，但是我目前常见的就只有以上列举的几种，剩下的激活函数等到到时候用到的时候再来补充就好了！</p>
<p><em>参考的网站：</em></p>
<blockquote>
<p><a href="https://www.cnblogs.com/makefile/p/activation-function.html">https://www.cnblogs.com/makefile/p/activation-function.html</a><br><a href="https://www.cnblogs.com/nxf-rabbit75/p/9276412.html">https://www.cnblogs.com/nxf-rabbit75/p/9276412.html</a><br><a href="https://cloud.tencent.com/developer/article/1800954">https://cloud.tencent.com/developer/article/1800954</a><br><a href="https://blog.csdn.net/hy592070616/article/details/120618490">https://blog.csdn.net/hy592070616/article/details/120618490</a><br><a href="https://blog.csdn.net/weixin_42057852/article/details/84644348?spm=1001.2101.3001.6650.11&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-11-84644348-blog-120618490.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-11-84644348-blog-120618490.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=15">https://blog.csdn.net/weixin_42057852/article/details/84644348?spm=1001.2101.3001.6650.11&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-11-84644348-blog-120618490.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-11-84644348-blog-120618490.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=15</a></p>
<p><a href="https://www.cnblogs.com/pinard/p/6437495.html">https://www.cnblogs.com/pinard/p/6437495.html</a></p>
</blockquote>
]]></content>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title>数学建模大赛</title>
    <url>/2022/11/23/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%A4%A7%E8%B5%9B/</url>
    <content><![CDATA[<p>直到今天为止，数模比赛已经结束咯！任务完成，参赛题目也提交了，结果如何就看人品了🤗</p>
<span id="more"></span>

<h1 id="1-数模比赛"><a href="#1-数模比赛" class="headerlink" title="1.数模比赛"></a>1.数模比赛</h1><p>直到今天为止，数模比赛已经结束咯！任务完成，参赛题目也提交了，结果如何就看人品了🤗<br>这是是第一次使用Markdown写短文，虽然说Markdown很容易上手，但是一些细节上的东西总是无法反应过来😵😵😵</p>
<blockquote>
<p>下面是我学习Markdown的一些经历，希望在写作的时候对你有些帮助！😉</p>
<p>点击跳转Markdown  –&gt;目前这项功能还在开发中，ちょっと待っね！</p>
</blockquote>
<h1 id="2-比赛前"><a href="#2-比赛前" class="headerlink" title="2.比赛前"></a>2.比赛前</h1><h2 id="2-1第一次校赛"><a href="#2-1第一次校赛" class="headerlink" title="2.1第一次校赛"></a>2.1第一次校赛</h2><p>虽然说今年四月份就开始准备数模比赛了，到今天有五个多月的时间，但是我们队真正学习的时间却不多，至少对我来说。可能我真正静下心来学习数模知识的时间还不足两个星期吧！😅</p>
<p>刚开始我的工作是负责建模的工作，在队长的敦促下，买了份价值一百五的学习视频及教程。我对于视频学习并没有多大的想法，我还是更喜欢看书学。这就是为什么iPad里的电子书都发霉发臭了，都不曾被我看过的原因吧？再一点，比起付费的资料，我更喜欢白嫖（虽然这并不好），因为在我认为在网上寻找资料是一件很享受的事情，おかしいでしょ？</p>
<p>一个队伍的核心成员应该是建模手，作为整支队伍的leader，我带领着队伍齐头并进，最后连校三等都没有…</p>
<p>😀😀😀但是这也是在意料之内的，因为没有什么知识储备，脑子里当时就只有层次分析法这几个简单的模型，再加上论文的阅读次数都不足双位数，能获奖就有鬼！而且为期三天的数模，我们整整搞了十天才提交上去，虽然但是有多少水分谁不不揭穿了啊！</p>
<h2 id="2-2暑假"><a href="#2-2暑假" class="headerlink" title="2.2暑假"></a>2.2暑假</h2><p>搞完校赛，处理完期末考试，差不多就进入了暑假。由于和写作手的配合没有那么好，所以我们打算换一名成员。队长推荐了一名算法高手，很显然，我该换岗位了。</p>
<p>在漫长的暑假，我只希望自己能够每天抽出时间读一篇，哪怕是一篇数模优秀文章也好！但是事与愿违，事…还是没做成。后面学校组织训练，我们参加并且完成了一篇19年的C题。嗯，很显然我们又是十天左右才完成。当时就想着，这么搞肯定得玩完。于是思前想后，打算用LaTeX替换现在的WPS，说不定写作工具变了，我们的工作就更有效率了呢？😲</p>
<p>好主意！下一次训练连半成品都没有交上去…</p>
<p>当时学习LaTeX花了不到半天时间，便清楚它的工作流程，于是迫不及待的去找了一些有数模LaTeX的tex文件。看到了一个钟意的，便敲定了，也就是现在我使用的这也数模模板。</p>
<p>由于我没有将模板与正文分离，所以我两次写论文的时候，都是夹着别人的论文一起写的，这次数模也不例外…</p>
<blockquote>
<p>我将LaTeX文件放到了这里，模板和正文自己分离。懒😪😪😪</p>
<p>这项工作也还在完善中，请稍后！</p>
</blockquote>
<p>然后就开学咯🎉</p>
<h2 id="2-3开学到比赛前这段时间"><a href="#2-3开学到比赛前这段时间" class="headerlink" title="2.3开学到比赛前这段时间"></a>2.3开学到比赛前这段时间</h2><p>很显然，我什么都没有干。</p>
<h1 id="3-比赛"><a href="#3-比赛" class="headerlink" title="3.比赛"></a>3.比赛</h1><p>据说参加国赛需要校赛经历，我们已经算是合格的国赛选手了吧？我们比赛的时间是9月15号（周四）晚上六点钟到9月18号（周日）晚上十点钟之前。又多了四个小时时间，Lucky！希望能够用这多出来的四个小时改变点什么…</p>
<h2 id="3-1周四晚上"><a href="#3-1周四晚上" class="headerlink" title="3.1周四晚上"></a>3.1周四晚上</h2><p>出赛题的时候我们在饭堂，不是因为我们不准备坐着等题，而是我忘记打包进实验室了。当天晚上我们商量好，要确定选题，不要犹豫。今年的A题对于我们来说，简直是魔鬼程度的。两三页篇幅的说明，让我们望而祛步🙄。如果硬啃的话，肯定可以理解它想要表达什么，但是求解确实一大难事。后面看别人大佬绞尽脑汁的想，才发现这个决定无疑对我们来说是十分正确的。</p>
<p>选题按理来说应该要由建模手和编程手决定，因为他们更清楚问题的复杂性。他们现在卡在了B题和C题之前，队长更想选C题，但是算法糕手希望能够挑战一下。他内心看起来很动摇，因为他看不出解题思路。其实我和新队员也是第一次见面，之前都是在WeChat上聊天。谢天谢地，我们俩很快就磨合了，变得更多少年的好友一般畅所欲言？！</p>
<p>我在几何方面很敏感，但是对数学公式很感冒。当时想过选数学专业，但是哪有人只学几何不用数学公式啊？恰好B题就是与几何有关的，我用高中的知识看出了第一小问的求解思路，然后我就坚持选B题。最后没有依我，选择了C题。我当时虽然很不爽，但是我确实只想得出第一问，对于全局来说，我还是服气的。虽然题目更简单了，但是意味着更多人选。只有语文建模基础足够深厚，才有机会获得一个最小的省三。<strong>最后统计有三百八十多人选择了C题，这个人数差不多就是去年我们学校的参赛人数…</strong></p>
<h2 id="3-2周五"><a href="#3-2周五" class="headerlink" title="3.2周五"></a>3.2周五</h2><p>周五我们搜寻资料，解决了第一小问，然后卡在了第二小问的预测上，想了差不多一天的时间都没有想出来。确实浪费了很多时间，也做了很多无用功。第一小问的论文我很快就与论文交接了，但是剩余的时间与其是在划水，倒不如说是在无用功。C题与化学有关，于是我想着会用到化学方程式，去找了很多。但是最后发现要么就是用不上，要么就是没时间用。</p>
<h2 id="3-3周六"><a href="#3-3周六" class="headerlink" title="3.3周六"></a>3.3周六</h2><p>C题有大概六七个小问，想要查看原题的话点击这里。</p>
<p>我们一天时间才解决了第一小问，如果再这么下去，论文很有可能写不完。虽然我们也很努力，我也是第一次尝试了这种朝八晚十二的作息规律。嗯？怎么和我平时的作息有点像？关键是放弃了宝贵的午休时间。没有午休我的精神状态就会下降，特别是写论文的时候，无法理解模型的概念与问题的解决思路，又没有文思泉涌，将会导致写出来的论文质量差。一天除了睡觉的时间都呆在实验室，看起来很努力，在我看来是在做无用功（包括我）。队长和建模手对于模型的选择有一定的困难，导致了问题的拖延。明白了这一点，今天开始我尝试着来安排工作。</p>
<p>对于模型，需要用指标来衡量。我肯定表现好的模型，否定表现差的模型。这种斩钉截铁的工作模式很快让我和各位都进入了流水线上，开始各司其职。当然，前提是做出了跳过第二小问的决定。</p>
<p>直到晚上，第二问第一小问、第三问和第四问的问题都得到了解决。但是跟他们一起讨论，导致我到目前为止并没有进行论文撰写，也就是说只完成了论文进度还是停留在周五。</p>
<h2 id="3-4周日"><a href="#3-4周日" class="headerlink" title="3.4周日"></a>3.4周日</h2><p>即便如此，我早上还是睡到了差不多九点，因为我认为工作效率才是最重要的，假努力欺骗的是自己还有身边的人。但时间真的很赶！早上我留在宿舍通过大屏操作LaTeX很快就完成了第二问的论文撰写，并且我交代队友明天早上完成第三问的论文撰写以及求解出第二小问的预测结果。队友很给力，差不多两点我去实验室的时候他们已经完成了这两个任务。但我看完论文结构后猛地一惊，发现摘要和问题分析没有写！包括第四问在内，还有一些零零星星的结果没有贴到论文中，六个小时能够完成吗？真是一项挑战啊！我不禁擦了擦额头上的假汗😰😰😰</p>
<p>我安排他们完成了问题二和问题三的问题分析，因为他们求解的他们来写这种解题思路的话简直如鱼得水。而第四问的方法是我想出来的，所以我先完成第四问先。但是做了一半，发现SPSSPro上的热力图根本无法反映出我想要的结果。于是在三点钟的时候我临时改用了其它方法，用画图代替了建立模型的繁琐。</p>
<p>大概五点钟我们就完成了基本上的任务，但是对于XeLatex编译出来的文件，还是有很多bug。并且每一个bug都是包含致命错误的，一旦出现即无缘获奖（<em>虽然说这次的也不知道能不能够获奖😵‍💫</em>）其中解决的很多问题都是以前遇到过但是解决不出的🤔</p>
<ul>
<li>从使用之初一直困扰我的表格边框以及复杂表格的LaTeX代码</li>
<li>LaTeX含特殊字符的那段文字会超出编译生成的PDF之外</li>
<li>LaTeX中图片并列</li>
<li>LaTeX正文会被图片和表格夹断，阅读出现障碍</li>
<li>LaTeX模板上页眉的内容不知道在哪个文件清空</li>
<li>LaTeX附录粘贴代码有点麻烦</li>
</ul>
<p><code>解决方案放到了LaTeX篇，如果有需要请点击此处跳转...</code></p>
<p>多亏LaTeX有在源代码和PDF相互跳转到指定位置的功能，不然真的用不下去了😭😭😭</p>
<p>我们一起改论文，改到了7点57还有很多问题，但是8点钟之前可以提交多次PDF论文和RAR压缩包，也就是说MD5码在8点钟之前是允许反复更改的。但是在8点到10点之内，就只能提交一次文件和生成指定不可变的MD5码。并且MD5码在8点后生成的，就不允许更改文件了，一旦你更改文件，或许只是打开一下PDF都有可能让MD5码发生改变，机器会判定在10点钟之后正式提交参赛作品的时候你的文件发生了改动，这个时候它是不承认你的MD5码，也就是说你无法参赛了。这是一个很严重的问题，自己辛辛苦苦做了这么久，结果却交不上去，心态多少有点崩溃。所以我们为了保险起见，先在8点钟之前提交一次。</p>
<p>然后我们预测在9点钟之前正式将作品做最后一次的提交（10点钟之前的提交可以认为只是参赛资格的获取），但是发现bug根本改不过来。三个人忙得团团转，当时想着9点半之前提交就好了，网络不会这么拥挤的。但是忙到了9点半，bug依然有，而且严重程度会让论文直接降档。没办法，抱着试一逝的心态，我们改bug改到了9点45。虽然说还有不少bug，但都是不痛不痒的，对阅读论文没有什么大影响的小问题了。</p>
<p>我编译出最新的PDF，通过WeChat准备发给队长时，由于轻薄本已经承担了太多软件，并且三四天都没有合过眼了。LaTeX直接卡退，屏幕被黑块笼罩着，就像我们此刻的心情一样。大概到9点50的时候，电脑缓过来了，我赶紧将PDF发给队长。压缩完我的LaTeX代码文件后突然发现我电脑里的压缩软件是360压缩，只能生成zip类型的压缩包。而我之前一直想着队长有WinRAR就够了，反正是他通过客户端提交的。下载WinRAR显然不切实际，由于多天的劳累，我们的CPU已经转不过来了。我赶紧将文件压缩成zip格式，然后发给建模手，因为此时队长在忙活着PDF名称的修改。但未承想建模手把我的文件解压放进总附件文件中，压缩后找不到找不到压缩包，遂叫我来操作。我看到他的安装路径，狂点桌面，然后点击确定。终于，我们的压缩包出现在了桌面。但他的桌面都是蓝蓝的doc和绿绿xls，一时间竟无法找出压缩包！此时时间已经来到了9点55分。一顿丝滑的操作后视野来到了队长这边，只见他颤颤巍巍地移动着鼠标，指尖高频触动着鼠标左键，但就是无法达到那最后的终点！“好了吗？”“好！冲！”伴随着呐喊声，我们点击了提交。幸运的是，软件并没有卡顿，显得如此顺理成章，此时时间是9点57分。一切都结束后，没有欢呼、没有喝彩，只留下一片鸦雀无声。紧绷着的心情还没有完全放松下来，眼前还停留着黑白的文字与代码，一切都还显得这么历历在目！</p>
<h1 id="4-Final"><a href="#4-Final" class="headerlink" title="4.Final"></a>4.Final</h1><p>虽然过程很苦很累，甚至对一百蚊有点舍不得。但就最后两个小时的感受而言，让我觉得这钱交的值了！自打上大学以来，还是第一次切实地体会到了团队合作的重要性。以前一直都是单打独斗，现在发现自己并不是万能的，队友就是用来弥补自己的缺点的。虽然说有百分之五十的概率获奖，但是无论结果如何我都能平淡接受，因为这场比赛我已经获得了自己想要的东西！<em>（其实心里还是想着希望得个省三就好了，因为有一千块钱回血…）</em>🐤🐤🐤</p>
]]></content>
  </entry>
</search>
