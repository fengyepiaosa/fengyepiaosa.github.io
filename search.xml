<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>L1和L2正则化</title>
    <url>/2022/11/23/L1%E5%92%8CL2%E6%AD%A3%E5%88%99%E5%8C%96/</url>
    <content><![CDATA[<p>了解什么是L1正则化和L2正则化，以及什么是正则化？</p>
<span id="more"></span>

<h1 id="L1正则化和L2正则化"><a href="#L1正则化和L2正则化" class="headerlink" title="L1正则化和L2正则化"></a>L1正则化和L2正则化</h1><h2 id="1-正则化"><a href="#1-正则化" class="headerlink" title="1. 正则化"></a>1. 正则化</h2><h3 id="1-1-什么是正则化？"><a href="#1-1-什么是正则化？" class="headerlink" title="1.1 什么是正则化？"></a>1.1 什么是正则化？</h3><p>Regularization，中文翻译过来可以称为正则化，或者叫做规范化。什么是规则？闭卷考试中不能查书，这就是规则，一个限制。同理，在这里，规则化（正则化）就是说给损失函数加上一些限制，通过这种规则去规范他们再接下来的循环迭代中，不要自我膨胀。</p>
<h3 id="1-2-正则化有什么用？"><a href="#1-2-正则化有什么用？" class="headerlink" title="1.2 正则化有什么用？"></a>1.2 正则化有什么用？</h3><p><img src="https://img-blog.csdnimg.cn/2020031610373195.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTk2MDg5MA==,size_16,color_FFFFFF,t_70" alt="回归模型的拟合程度"></p>
<p><img src="https://img-blog.csdnimg.cn/20200316112556508.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTk2MDg5MA==,size_16,color_FFFFFF,t_70" alt="分类模型的拟合程度"></p>
<p>可以看出，两张图的最后一个模型，都存在着过拟合的现象。</p>
<blockquote>
<p>解决过拟合的方案有：<br>清洗数据<br>减少模型参数，降低模型复杂度<br>增加惩罚因子（正则化），保留所有的特征，但是减少参数的大小（magnitude）</p>
</blockquote>
<p>可见，正则化就是解决模型过拟合的其中一个方法。</p>
<h3 id="1-3-正则化怎么用？"><a href="#1-3-正则化怎么用？" class="headerlink" title="1.3 正则化怎么用？"></a>1.3 正则化怎么用？</h3><p>机器学习中几乎都可以看到损失函数后面会添加一个额外项，常用的额外项一般有两种，一般英文称作 ℓ1 \ell_1ℓ 1-norm 和 ℓ2 \ell_2ℓ2​-norm，中文称作 L1正则化 和 L2正则化，或者 L1范数 和 L2范数。</p>
<p>L1正则化和L2正则化可以看做是损失函数的惩罚项。所谓『惩罚』是指对损失函数中的某些参数做一些限制。<strong>对于线性回归模型，使用L1正则化的模型建叫做Lasso回归，使用L2正则化的模型叫做Ridge回归（岭回归）</strong>。下图是Python中Lasso回归的损失函数，式中加号后面一项α ∣ ∣ w ∣ ∣ 1 \alpha||w||_1α∣∣w∣∣ 1即为L1正则化项。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwOTA0MTg0MjI4MTU4?x-oss-process=image/format,png#pic_center" alt="Lasso回归损失函数"></p>
<p>下图是Python中Ridge回归的损失函数，式中加号后面一项α ∣ ∣ w ∣ ∣ 2 2 \alpha||w||_2^2α∣∣w∣∣22即为L2正则化项。</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwOTA0MTg0MzE0MzMz?x-oss-process=image/format,png#pic_center" alt="岭回归损失函数"></p>
<p>一般回归分析中w表示特征的系数，从上式可以看到正则化项是对系数做了处理（限制）。L1正则化和L2正则化的说明如下：</p>
<ul>
<li>L1正则化是指权值向量w中各个元素的绝对值之和，通常表示为∣ ∣ w ∣ ∣ 1 ||w||_1∣∣w∣∣ 1<br>​- L2正则化是指权值向量w中各个元素的平方和然后再求平方根（可以看到Ridge回归的L2正则化项有平方符号），通常表示为∣ ∣ w ∣ ∣ 2 ||w||_2∣∣w∣∣ 2​</li>
</ul>
<p>一般都会在正则化项之前添加一个系数，Python的机器学习包sklearn中用α表示，一些文章也用λ表示。这个系数需要用户指定。</p>
<ul>
<li>L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择</li>
<li>L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合</li>
</ul>
<h2 id="2-稀疏模型与特征选择的关系"><a href="#2-稀疏模型与特征选择的关系" class="headerlink" title="2. 稀疏模型与特征选择的关系"></a>2. 稀疏模型与特征选择的关系</h2><blockquote>
<p>上面提到L1正则化有助于生成一个稀疏权值矩阵，进而可以用于特征选择。为什么要生成一个稀疏矩阵？</p>
</blockquote>
<p>稀疏矩阵指的是很多元素为0，只有少数元素是非零值的矩阵，即得到的线性回归模型的大部分系数都是0. 通常机器学习中特征数量很多，例如文本处理时，如果将一个词组（term）作为一个特征，那么特征数量会达到上万个（bigram）。在预测或分类时，那么多特征显然难以选择，但是如果代入这些特征得到的模型是一个稀疏模型，表示只有少数特征对这个模型有贡献，绝大部分特征是没有贡献的，或者贡献微小（因为它们前面的系数是0或者是很小的值，即使去掉对模型也没有什么影响），此时我们就可以只关注系数是非零值的特征。这就是稀疏模型与特征选择的关系。</p>
<h2 id="3-L1正则化"><a href="#3-L1正则化" class="headerlink" title="3. L1正则化"></a>3. L1正则化</h2><p>为什么L1正则化可以产生稀疏模型（L1是怎么让系数等于零的）？</p>
<h3 id="正则化和特征选择的关系"><a href="#正则化和特征选择的关系" class="headerlink" title="正则化和特征选择的关系"></a>正则化和特征选择的关系</h3><p>假设有如下带L1正则化的损失函数：<br>J &#x3D; J 0 + α ∑ w ∣ w ∣ (1) J &#x3D; J_0 + \alpha \sum_w{|w|} \tag{1}J&#x3D;J0​+α w∑∣w∣(1)</p>
<p>其中J 0 J_0J 0是原始的损失函数，加号后面的一项是L1正则化项，α \alphaα是正则化系数。注意到L1正则化是权值的绝对值之和，J JJ是带有绝对值符号的函数，因此J JJ是不完全可微的。机器学习的任务就是要通过一些方法（比如梯度下降）求出损失函数的最小值。当我们在原始损失函数J 0 J_0J 0​<br> 后添加L1正则化项时，相当于对J 0 J_0J<br>0​<br> 做了一个约束。令L &#x3D; α ∑ w ∣ w ∣ L &#x3D; \alpha \sum_w{|w|}L&#x3D;α∑<br>w​<br> ∣w∣，则J &#x3D; J 0 + L J &#x3D; J_0 + LJ&#x3D;J<br>0​<br> +L，此时我们的任务变成在L LL约束下求出J 0 J_0J<br>0​<br> 取最小值的解。考虑二维的情况，即只有两个权值w 1 w^1w<br>1<br> 和w 2 w^2w<br>2<br> ，此时L &#x3D; ∣ w 1 ∣ + ∣ w 2 ∣ L &#x3D; |w^1|+|w^2|L&#x3D;∣w<br>1<br> ∣+∣w<br>2<br> ∣。对于梯度下降法，求解J 0 J_0J<br>0​<br> 的过程可以画出等值线，同时L1正则化的函数L LL也可以在w 1 w 2 w^1w^2w<br>1<br> w<br>2的二维平面上画出来。如下图：</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwOTA0MTg0NDI4NDU5?x-oss-process=image/format,png#pic_center" alt="L1正则化"></p>
<p>图中等值线是J 0 J_0J 0​<br> 的等值线，黑色方形是L LL函数的图形。L &#x3D; ∣ w 1 ∣ + ∣ w 2 ∣ L &#x3D; |w^1|+|w^2|L&#x3D;∣w<br>1<br> ∣+∣w<br>2<br> ∣，这个函数画出来就是一个方框（可以自己动手画一下）。<br>在图中，当J 0 J_0J<br>0​<br> 等值线与L LL图形首次相交的地方就是最优解。上图中J 0 J_0J<br>0​<br> 与L LL在L LL的一个顶点处相交，这个顶点就是最优解。注意到这个顶点的值是( w 1 , w 2 ) &#x3D; ( 0 , w ) (w^1, w^2) &#x3D; (0, w)(w<br>1<br> ,w<br>2<br> )&#x3D;(0,w)。可以直观想象，因为L LL函数有很多『突出的角』（二维情况下四个，多维情况下更多），J 0 J_0J<br>0​<br> 与这些角接触的机率会远大于与L LL其它部位接触的机率（这是很直觉的想象，突出的角比直线的边离等值线更近写），而在这些角上，会有很多权值等于0（因为角就在坐标轴上），这就是为什么L1正则化可以产生稀疏模型，进而可以用于特征选择。</p>
<p>而正则化前面的系数α \alphaα，可以控制L LL图形的大小。α \alphaα越小，L LL的图形越大（上图中的黑色方框）；α \alphaα越大，L LL的图形就越小，可以小到黑色方框只超出原点范围一点点，这是最优点的值( w 1 , w 2 ) &#x3D; ( 0 , w ) (w1,w2)&#x3D;(0,w)(w1,w2)&#x3D;(0,w)中的w ww可以取到很小的值。</p>
<p>我觉得下面的博主讲的挺易懂的：<br><a href="https://blog.csdn.net/u011426016/article/details/119836598">https://blog.csdn.net/u011426016/article/details/119836598</a></p>
<h2 id="4-L2正则化"><a href="#4-L2正则化" class="headerlink" title="4. L2正则化"></a>4. L2正则化</h2><p>假设有如下带L2正则化的损失函数：</p>
<p>J &#x3D; J 0 + α ∑ w w 2 (2) J &#x3D; J_0 + \alpha \sum_w{w^2} \tag{2}<br>J&#x3D;J<br>0​<br> +α<br>w<br>∑​<br> w<br>2<br> (2)</p>
<p>同样可以画出他们在二维平面上的图形，如下：</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwOTA0MTg0NjQ2OTYz?x-oss-process=image/format,png#pic_center" alt="L2正则化"></p>
<p>二维平面下L2正则化的函数图形是个圆（绝对值的平方和，是个圆），与方形相比，被磨去了棱角。因此J 0 J_0J<br>0​<br> 与L LL相交时使得w 1 w^1w<br>1<br> 或w 2 w^2w<br>2<br> 等于零的机率小了许多（这个也是一个很直观的想象），这就是为什么L2正则化不具有稀疏性的原因，因为不太可能出现多数w ww都为0的情况。</p>
<h3 id="为什么梯度下降的等值线与正则化函数第一次交点是最优解？"><a href="#为什么梯度下降的等值线与正则化函数第一次交点是最优解？" class="headerlink" title="为什么梯度下降的等值线与正则化函数第一次交点是最优解？"></a>为什么梯度下降的等值线与正则化函数第一次交点是最优解？</h3><p>评论中有人问到过这个问题，这是带约束的最优化问题。这应该是在大一的高等数学就学到知识点，因为这里要用到拉格朗日乘子。如果有这样的问题，就需要复习一下高等数学了。这里有一个比较详细的数学讲解，可以参考：带约束的最优化问题。</p>
<p>如果还不清楚的话，可以参考博客：<br><a href="https://blog.csdn.net/jinping_shi/article/details/52433975">https://blog.csdn.net/jinping_shi/article/details/52433975</a></p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.cnblogs.com/zingp/p/10375691.html">https://www.cnblogs.com/zingp/p/10375691.html</a></p>
<p><a href="https://www.cnblogs.com/skyfsm/p/8456968.html">https://www.cnblogs.com/skyfsm/p/8456968.html</a></p>
<p><a href="https://blog.csdn.net/u012162613/article/details/44261657?spm=1001.2101.3001.6650.3&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-44261657-blog-104891561.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-44261657-blog-104891561.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=6">https://blog.csdn.net/u012162613/article/details/44261657?spm=1001.2101.3001.6650.3&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3-44261657-blog-104891561.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-3-44261657-blog-104891561.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=6</a></p>
<p><a href="https://songjian.blog.csdn.net/article/details/104891561?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-104891561-blog-79425831.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-104891561-blog-79425831.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=2">https://songjian.blog.csdn.net/article/details/104891561?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-104891561-blog-79425831.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-104891561-blog-79425831.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=2</a></p>
<p><a href="https://blog.csdn.net/haima1998/article/details/79425831">https://blog.csdn.net/haima1998/article/details/79425831</a></p>
]]></content>
      <categories>
        <category>Mathine Learning</category>
      </categories>
  </entry>
  <entry>
    <title>Jupyter Notebook</title>
    <url>/2022/11/23/Jupyter-Notebook/</url>
    <content><![CDATA[<p>Jupyter Notebook的常见操作-需要熟记！</p>
<span id="more"></span>

<h1 id="Jupyter-Notebook常见快捷键操作"><a href="#Jupyter-Notebook常见快捷键操作" class="headerlink" title="Jupyter Notebook常见快捷键操作"></a>Jupyter Notebook常见快捷键操作</h1><blockquote>
<p>首先要知道Jupyter有三种cell类型</p>
</blockquote>
<ol>
<li><strong>Code</strong></li>
<li><strong>Markdown</strong></li>
<li><strong>Raw NBConvert</strong>（普通文本，运行不会输出结果）</li>
</ol>
<blockquote>
<p>两种模式</p>
</blockquote>
<ol>
<li><strong>编辑模式（Enter）</strong></li>
<li><strong>命令模式（Esc）</strong></li>
</ol>
<h2 id="1-两种模式都可以使用的快捷键"><a href="#1-两种模式都可以使用的快捷键" class="headerlink" title="1.两种模式都可以使用的快捷键"></a>1.两种模式都可以使用的快捷键</h2><ul>
<li><strong>Shift+Enter</strong>执行本单元代码，并且跳转到下一单元</li>
<li><strong>Ctrl+Enter</strong>执行本单元代码，留在本单元</li>
</ul>
<h2 id="2-命令模式"><a href="#2-命令模式" class="headerlink" title="2.命令模式"></a>2.命令模式</h2><ul>
<li><strong>Y</strong>：cell切换到Code模式</li>
<li><strong>M</strong>：cell切换到Markdown模式</li>
<li><strong>A</strong>：在当前cell的上面添加cell</li>
<li><strong>B</strong>：在当前cell的下面添加cell</li>
<li><strong>双击D</strong>：删除当前cell</li>
<li><strong>Z</strong>：回退</li>
<li><strong>Ctrl+Shift+减号</strong>：分隔cell，在光标处</li>
<li><strong>L</strong>：为当前cell加上行号</li>
</ul>
<h2 id="3-编辑模式：按Enter或鼠标单击代码块内部进入"><a href="#3-编辑模式：按Enter或鼠标单击代码块内部进入" class="headerlink" title="3.编辑模式：按Enter或鼠标单击代码块内部进入"></a>3.编辑模式：按Enter或鼠标单击代码块内部进入</h2><ul>
<li><strong>Ctrl+鼠标单击</strong>：多光标操作</li>
<li><strong>Ctrl+Z</strong>：回退</li>
<li><strong>Tab键</strong>：代码补全</li>
<li><strong>Ctrl</strong>：注释多行代码</li>
</ul>
]]></content>
      <categories>
        <category>notebook operation</category>
      </categories>
  </entry>
  <entry>
    <title>github文件夹有白色箭头并且不能打开的解决办法</title>
    <url>/2022/11/20/github%E6%96%87%E4%BB%B6%E5%A4%B9%E6%9C%89%E7%99%BD%E8%89%B2%E7%AE%AD%E5%A4%B4%E5%B9%B6%E4%B8%94%E4%B8%8D%E8%83%BD%E6%89%93%E5%BC%80%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
    <content><![CDATA[<p>Github文件夹有白色箭头并且不能打开?可能是因为你提交的Git文件中有叫做.git的文件！</p>
<span id="more"></span>

<h1 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1.问题描述"></a>1.问题描述</h1><p>前几天在Git上向GitHub提交了自己的文件，但是在GitHub却无法打开文件夹，并且文件夹上面还多了一个白色的箭头？本着求知的精神，我上百度上找了找，发现是因为我提交的这个文件本身就已经是Git仓库了，而子文件里面还藏着Git仓库，也就是说子文件里还有.git隐藏文件。因为层层的嵌套关系，导致GitHub对文件的识别发生了错误。</p>
<h1 id="2-解决方案"><a href="#2-解决方案" class="headerlink" title="2.解决方案"></a>2.解决方案</h1><p>把子文件的.git文件夹删掉就好了</p>
<ol>
<li>执行<code>git rm --cached [文件夹名]</code></li>
<li>执行<code>git add [文件夹名]</code></li>
<li>执行<code>git commit -m &quot;git folder report an error!&quot;</code></li>
<li>执行<code>git push origin [branch_name] </code></li>
</ol>
]]></content>
      <categories>
        <category>git operation</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>工具操作</tag>
      </tags>
  </entry>
  <entry>
    <title>cv2报错处理</title>
    <url>/2022/11/24/cv2%E6%8A%A5%E9%94%99%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<p>cv2报错：raise TypeError(“Image data of dtype {} cannot be converted to “TypeError: Image data of dtype object cannot be converted to float</p>
<span id="more"></span>

<h1 id="raise-TypeError-“Image-data-of-dtype-cannot-be-converted-to-“-TypeError-Image-data-of-dtype-object-cannot-be-converted-to-float"><a href="#raise-TypeError-“Image-data-of-dtype-cannot-be-converted-to-“-TypeError-Image-data-of-dtype-object-cannot-be-converted-to-float" class="headerlink" title="raise TypeError(“Image data of dtype {} cannot be converted to “     TypeError: Image data of dtype object cannot be converted to float"></a>raise TypeError(“Image data of dtype {} cannot be converted to “     TypeError: Image data of dtype object cannot be converted to float</h1><p>刚想要研究一下CV2内置的图像类型的不同，结果发现CSDN上找的代码跑不出来？其实也正常，天下哪有免费的午餐，拿到的代码还不是得修修改改？</p>
<h1 id="报错如下"><a href="#报错如下" class="headerlink" title="报错如下"></a>报错如下</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">raise TypeError(&quot;Image data of dtype &#123;&#125; cannot be converted to &quot;     TypeError: Image data of dtype object cannot be converted to float</span><br></pre></td></tr></table></figure>

<p>至于解决方案众说纷坛，有说要看看数据类型是不是不对应，还有的人说路径里面有中文。其实我的文件夹真的有中文，但是更改之后，报错依旧。</p>
<p>网上都说是引入图片路径的问题，但是我这句代码应该也没有错吧？因为下载的visual code插件可以成功显示出图片在代码的左边，左思右想决定还是更改路径试试。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># cv2.imread()接口读图像，读进来直接是BGR 格式数据格式在 0~255，通道格式为(W,H,C)</span><br><span class="line">img_BGR = cv2.imread(&#x27;sea.jpg&#x27;)</span><br></pre></td></tr></table></figure>

<p>更改成visual code直接复制图片的相对路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">img_BGR = cv2.imread(&#x27;web\sea.jpg&#x27;)</span><br></pre></td></tr></table></figure>

<p>后面发现真的成功运行。这次运行的代码文件和图片文件在同一个文件夹里，但是却要加个前缀，可能与我IDE打开的工作区有关吧？</p>
<p>总之就是路径的问题。</p>
<h1 id="不存在skimage库"><a href="#不存在skimage库" class="headerlink" title="不存在skimage库"></a>不存在skimage库</h1><p>Python库函数的下载放到了另外一篇文章…</p>
]]></content>
      <categories>
        <category>Library function</category>
      </categories>
      <tags>
        <tag>report an error</tag>
        <tag>库函数</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/11/20/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>blog            //文章分类</category>
      </categories>
  </entry>
  <entry>
    <title>pip安装新库</title>
    <url>/2022/11/24/pip%E5%AE%89%E8%A3%85%E6%96%B0%E5%BA%93/</url>
    <content><![CDATA[<p>书接上回，研究一下在visual code上如何通过pip安装库函数，这次要安装的库函数是skimage</p>
<span id="more"></span>

<h1 id="pip安装skimage库"><a href="#pip安装skimage库" class="headerlink" title="pip安装skimage库"></a>pip安装skimage库</h1><p>研究如何在visual code上如何通过pip安装库函数</p>
<h1 id="找到Python的路径"><a href="#找到Python的路径" class="headerlink" title="找到Python的路径"></a>找到Python的路径</h1><p>我的是<em>“D:\Python\Scripts”</em></p>
<p>visual code或者cmd命令台执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd D:\Python\Scripts</span><br></pre></td></tr></table></figure>

<p><em>新发现，我的Python是全局的，所以直接打开cmd便可以执行pip指令，这样就免去了切换到指定目录下的过程</em></p>
<p>然后输入pip install skimage</p>
<h1 id="pip版本要更新"><a href="#pip版本要更新" class="headerlink" title="pip版本要更新"></a>pip版本要更新</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">D:\Python\Scripts&gt;pip install skimage</span><br><span class="line">Collecting skimage</span><br><span class="line">  Using cached skimage-<span class="number">0.0</span>.tar.gz (<span class="number">757</span> <span class="built_in">bytes</span>)</span><br><span class="line">  Preparing metadata (setup.py) ... error</span><br><span class="line">  error: subprocess-exited-<span class="keyword">with</span>-error</span><br><span class="line"></span><br><span class="line">  × python setup.py egg_info did <span class="keyword">not</span> run successfully.</span><br><span class="line">  │ exit code: <span class="number">1</span></span><br><span class="line">  ╰─&gt; [<span class="number">3</span> lines of output]</span><br><span class="line"></span><br><span class="line">      *** Please install the `scikit-image` package (instead of `skimage`) ***</span><br><span class="line"></span><br><span class="line">      [end of output]</span><br><span class="line"></span><br><span class="line">  note: This error originates <span class="keyword">from</span> a subprocess, <span class="keyword">and</span> <span class="keyword">is</span> likely <span class="keyword">not</span> a problem <span class="keyword">with</span> pip.</span><br><span class="line">error: metadata-generation-failed</span><br><span class="line"></span><br><span class="line">× Encountered error <span class="keyword">while</span> generating package metadata.</span><br><span class="line">╰─&gt; See above <span class="keyword">for</span> output.</span><br><span class="line"></span><br><span class="line">note: This <span class="keyword">is</span> an issue <span class="keyword">with</span> the package mentioned above, <span class="keyword">not</span> pip.</span><br><span class="line">hint: See above <span class="keyword">for</span> details.</span><br><span class="line"></span><br><span class="line">[notice] A new release of pip available: <span class="number">22.1</span><span class="number">.2</span> -&gt; <span class="number">22.3</span></span><br><span class="line">[notice] To update, run: python.exe -m pip install --upgrade pip</span><br></pre></td></tr></table></figure>


<p>没办法，照着提示更新</p>
<h1 id="更新完下载仍然报错"><a href="#更新完下载仍然报错" class="headerlink" title="更新完下载仍然报错"></a>更新完下载仍然报错</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">D:\Python\Scripts&gt;.\pip install skimage</span><br><span class="line">Collecting skimage</span><br><span class="line">  Using cached skimage-0.0.tar.gz (757 bytes)</span><br><span class="line">  Preparing metadata (setup.py) ... error</span><br><span class="line">  error: subprocess-exited-with-error</span><br><span class="line"></span><br><span class="line">  × python setup.py egg_info did not run successfully.</span><br><span class="line">  │ exit code: 1</span><br><span class="line">  ╰─&gt; [3 lines of output]</span><br><span class="line"></span><br><span class="line">      *** Please install the `scikit-image` package (instead of `skimage`) ***</span><br><span class="line"></span><br><span class="line">      [end of output]</span><br><span class="line"></span><br><span class="line">  note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">error: metadata-generation-failed</span><br><span class="line"></span><br><span class="line">× Encountered error while generating package metadata.</span><br><span class="line">╰─&gt; See above for output.</span><br><span class="line"></span><br><span class="line">note: This is an issue with the package mentioned above, not pip.</span><br><span class="line">hint: See above for details.</span><br></pre></td></tr></table></figure>

<p>原来是库函数命名的问题，为什么我要的是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from skimage import io, data</span><br></pre></td></tr></table></figure>
<p>但是却给了我个“scikit-image”呢？</p>
<p>不知道，更改名字后执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">D:\Python\Scripts&gt;pip install scikit-image</span><br></pre></td></tr></table></figure>
<p><strong>成功！</strong></p>
<h1 id="pip下载切换清华源-in-common-use"><a href="#pip下载切换清华源-in-common-use" class="headerlink" title="pip下载切换清华源(in common use)"></a>pip下载切换清华源(in common use)</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install imutils -i https://pypi.tuna.tsinghua.edu.cn/simple/</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Library function</category>
      </categories>
      <tags>
        <tag>库函数</tag>
        <tag>安装</tag>
      </tags>
  </entry>
  <entry>
    <title>Last summer whisper-杏里</title>
    <url>/2022/11/26/last-summer-whisper/</url>
    <content><![CDATA[<p>六七十年代日本歌曲-Last Summer Whisper，有夏天的感觉，但感觉更多的是烦恼…</p>
<span id="more"></span>

<div class="video-container"><iframe src="https://www.youtube.com/embed/SNq4zqTN_DQ" frameborder="0" loading="lazy" allowfullscreen></iframe></div>

<p><strong>Last Summer Whisper</strong></p>
<p>作词：角松敏生<br>作曲：角松敏生</p>
<hr>
<p>夏の雨上りの街に　そっと灯りまたたきだす</p>
<p>别れの后で电话をしたことを</p>
<p>ゆるして欲しいけど　ねえ</p>
<p>もう一度だけあの店で会いたい</p>
<p>それで终りにする</p>
<p>Baby love again　二人の爱はもどりはしないけど</p>
<p>Baby love again　せめてあなたをにくみたくはないの</p>
<p>好きな香りつけてきたの　夏の黄昏によく似合うわ</p>
<p>あの日のままで　话をして欲しい</p>
<p>海の好きなあなた　ねぇ　私はずっと頬づえつきながら</p>
<p>闻いてるだけでいい</p>
<p>Baby love again　やさしさだけが重すぎただけなの</p>
<p>Baby love again　せめて笑ってこの夜终らすわ</p>
<p>明日から二人　别々の日々でも　この街のどこかでね</p>
<p>生きてるかぎり　会える気がするのよ</p>
<p>その时は笑颜で</p>
<p>Baby love again　二人の爱はもどりはしないけど</p>
<p>Baby love again　せめてあなたをにくみたくはないの</p>
<p>にくみたくはないの…</p>
<hr>
]]></content>
      <categories>
        <category>Things of Interest</category>
      </categories>
      <tags>
        <tag>音视频</tag>
        <tag>Youtube</tag>
      </tags>
  </entry>
  <entry>
    <title>交叉验证补充</title>
    <url>/2022/11/23/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%A1%A5%E5%85%85/</url>
    <content><![CDATA[<p>前面我介绍了K折交叉验证该如何划分，还有具体的使用效果。但是对于K折交叉验证该什么时候用，怎么使用还没有讲的很清楚，这里我就再学习一遍加深记忆吧！</p>
<span id="more"></span>

<h1 id="交叉验证补充"><a href="#交叉验证补充" class="headerlink" title="交叉验证补充"></a>交叉验证补充</h1><p>事情的起因是我看到了下面一段代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import KFold, train_test_split</span><br></pre></td></tr></table></figure>

<p>这个KFolder怎么和train_test_split都在一起？我查了一下，发现train_test_split就是我之前所鄙夷的简单交叉验证。没有验证集，都是总集合不断打乱然后划分训练集和测试集，利用测试集的表现性能（也就是损失函数）来评估最优的模型和参数。由于是随机的将原始数据分组，所以最后验证集分类准确率的高低与原始数据的分组有很大的关系，得到的结果并不具有说服性<a href="https://blog.csdn.net/u010986753/article/details/98069124">…</a></p>
<h1 id="对K折交叉验证的再理解"><a href="#对K折交叉验证的再理解" class="headerlink" title="对K折交叉验证的再理解"></a>对K折交叉验证的再理解</h1><p>前面我介绍了K折交叉验证该如何划分，还有具体的使用效果。但是对于K折交叉验证该什么时候用，怎么使用还没有讲的很清楚，这里我就再学习一遍加深记忆吧！</p>
<p>K折交叉只是一种划分数据集的策略。把它和传统划分数据集（train_test_split）的方式进行比较，它可以避免固定划分数据集的局限性、特殊性，这个优势在小规模数据集上更明显。不用K折交叉验证就不能进行模型评估和模型选择了吗？当然不是。只要有测试集，就能进行模型评估；只要有验证集，就能进行模型选择。所以N折交叉验证只是在做这两件事时的一种可选的优化手段。当数据集很小时，建议用交叉验证的方法来避免过拟合。</p>
<p>引用<a href="https://zhuanlan.zhihu.com/p/113623623">王亮博主</a>的观点，K折交叉验证可以分成两个用途：</p>
<ol>
<li>模型选择</li>
<li>模型评估</li>
</ol>
<h2 id="1-模型选择"><a href="#1-模型选择" class="headerlink" title="1.模型选择"></a>1.模型选择</h2><p>当对训练集和验证集采取Kfolder进行划分的时候，被称为是模型选择，也就是参数选择。验证集是在训练过程中用于检验模型的训练情况，从而确定合适的超参数。而测试集完全不参与训练的数据，仅仅用来观测测试效果、测试模型的泛化能力。</p>
<p>具体的过程是，首先在训练集和验证集上对多种模型选择（超参数选择）进行验证，选出平均误差最小的模型（超参数）。选出合适的模型（超参数）后，可以把训练集和验证集合并起来，在上面重新把模型训练一遍，得到最终模型，然后再用测试集测试其泛化能力。	</p>
<h2 id="2-模型选择"><a href="#2-模型选择" class="headerlink" title="2.模型选择"></a>2.模型选择</h2><p>交叉验证的另一个用途，就是模型是确定的，没有多个候选模型需要选，只是用交叉验证的方法来对模型的performance进行评估。这种情况下，数据集被划分成训练集、测试集两部分，训练集和测试集的划分采用N折交叉的方式。我的理解是，找出一种训练集与测试集的划分方法，让测试集的表现最好！这一点如果在数据量小的时候还好，K个组合中的分数差距可能会比较大。但如果数据量大起来了，相比这K组的测试集表现都差不多吧？这也说明了K折只适合用于小样本的数据集上…</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>当用交叉验证进行模型选择时，可以从多种模型中选择出泛化能力最好的（即最不容易发生过拟合）的模型。从这个角度上讲，交叉验证是避免发生过拟合的手段。同样是解决过拟合的方法，交叉验证与正则化不同：交叉验证通过寻找最佳模型的方式来解决过拟合；而正则化则是通过约束参数的范数来解决过拟合。</p>
<p>当用交叉验证进行模型评估时，交叉验证不能解决过拟合问题，只能用来评估模型的performance。</p>
<p>如果还不熟悉的话建议拿<a href="https://blog.csdn.net/weixin_43685844/article/details/88635492">练习1</a>和<a href="https://zhuanlan.zhihu.com/p/250253050">练习2</a>练练手</p>
]]></content>
      <categories>
        <category>Mathine Learning</category>
      </categories>
  </entry>
  <entry>
    <title>交叉验证</title>
    <url>/2022/11/23/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/</url>
    <content><![CDATA[<p>这里介绍一下K-Fold交叉验证，这是防止过拟合的一种方法…</p>
<span id="more"></span>

<h1 id="K-Fold-交叉验证-Cross-Validation-的理解与应用"><a href="#K-Fold-交叉验证-Cross-Validation-的理解与应用" class="headerlink" title="K-Fold 交叉验证 (Cross-Validation)的理解与应用"></a>K-Fold 交叉验证 (Cross-Validation)的理解与应用</h1><h1 id="1-简单介绍一下验证集"><a href="#1-简单介绍一下验证集" class="headerlink" title="1.简单介绍一下验证集"></a>1.简单介绍一下验证集</h1><p>在机器学习建模过程中，通行的做法通常是将数据分为训练集和测试集。测试集是与训练独立的数据，完全不参与训练，用于最终模型的评估。在训练过程中，经常会出现过拟合的问题，就是模型可以很好的匹配训练数据，却不能很好在预测训练集外的数据。如果此时就使用测试数据来调整模型参数，就相当于在训练时已知部分测试数据的信息，会影响最终评估结果的准确性。通常的做法是在训练数据再中分出一部分做为验证(Validation)数据，用来评估模型的训练效果。<em>验证集的好处在于，可以对训练的模型进行评估，并且更换超参数后继续训练评估…</em></p>
<h1 id="2-通过验证集理解K-Fold-交叉验证"><a href="#2-通过验证集理解K-Fold-交叉验证" class="headerlink" title="2.通过验证集理解K-Fold 交叉验证"></a>2.通过验证集理解K-Fold 交叉验证</h1><p>验证数据取自训练数据，但不参与训练，这样可以相对客观的评估模型对于训练集之外数据的匹配程度。模型在验证数据中的评估常用的是交叉验证，又称循环验证。它将原始数据分成K组(K-Fold)，将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型。</p>
<p>这K个模型分别在验证集中评估结果，最后的误差MSE(Mean Squared Error)加权平均就得到交叉验证误差。交叉验证有效利用了有限的数据，并且评估结果能够尽可能接近模型在测试集上的表现，可以做为模型优化的指标使用。</p>
<h1 id="3-简单介绍一下常用的回归评价指标MSE、RMSE、MAE、R-Squared"><a href="#3-简单介绍一下常用的回归评价指标MSE、RMSE、MAE、R-Squared" class="headerlink" title="3.简单介绍一下常用的回归评价指标MSE、RMSE、MAE、R-Squared"></a>3.简单介绍一下常用的回归评价指标MSE、RMSE、MAE、R-Squared</h1><p>如果说分类问题的评价指标是<strong>准确率</strong>，那么回归算法的评价指标就是<em>MSE，RMSE，MAE、R-Squared</em>。在进行机器学习实验二的K-fold的时候，遇到了评价指标MSE，在好奇心的驱使下，我尝试研究这<a href="https://www.jianshu.com/p/9ee85fdad150">四个评价指标…</a></p>
<h2 id="3-1-均方误差-MSE"><a href="#3-1-均方误差-MSE" class="headerlink" title="3.1 均方误差-MSE"></a>3.1 均方误差-MSE</h2><p><img src="/%22F:%5C%E5%9B%BE%E7%89%87%5Cwebsite%5Cformula1.png%22" alt="MSE"></p>
<p>MSE （Mean Squared Error）叫做均方误差。这里的y帽指的是预测值。这个公式长得有点像是线性回归模型的损失函数。</p>
<h2 id="3-2-均方根误差-RMSE"><a href="#3-2-均方根误差-RMSE" class="headerlink" title="3.2 均方根误差-RMSE"></a>3.2 均方根误差-RMSE</h2><p><img src="/%22F:%5C%E5%9B%BE%E7%89%87%5Cwebsite%5Cformula2.png%22" alt="RMSE"></p>
<p>RMSE（Root Mean Squard Error）均方根误差。这就是给MSE开一个根号，目的是更好的描述数据。因为开一个根号，RMSE在单位上就应该与所研究的数据的单位差不多了。</p>
<h2 id="3-3-平均绝对误差-MAE"><a href="#3-3-平均绝对误差-MAE" class="headerlink" title="3.3 平均绝对误差-MAE"></a>3.3 平均绝对误差-MAE</h2><p><img src="/%22F:%5C%E5%9B%BE%E7%89%87%5Cwebsite%5Cformula3.png%22" alt="MAE"></p>
<p>MAE(平均绝对误差)，这个看起来与上面的没有差别。<strong>有均方根的地方好像就会有绝对值？？？</strong></p>
<h2 id="3-4-R方-R-Squared"><a href="#3-4-R方-R-Squared" class="headerlink" title="3.4 R方-R Squared"></a>3.4 R方-R Squared</h2><p><img src="/%22F:%5C%E5%9B%BE%E7%89%87%5Cwebsite%5Cformula4.png%22" alt="R Squared"></p>
<p><img src="/%22F:%5C%E5%9B%BE%E7%89%87%5Cwebsite%5Cformula5.png%22" alt="R Squared"></p>
<p>分类算法的衡量标准是正确率，它的范围是从零到一，很直观，并且在不同模型上也是一样的，看正确率就完事了。所以回归模型上有没有这种衡量的标准呢？答案是有的，它就是R Aquared也就是<strong>R方</strong>。至于式子的意思，应该也是很好理解的，但是<a href="https://www.jianshu.com/p/9ee85fdad150">参考博主</a>写得有点不明不白，暂且就不深究了吧？总的来说，就是描述我们训练出来的模型的所有误差与当y帽等于y平均值时的误差之间的偏离程度。当R方结果为1时，表示我们的模型完全正确，这个时候分式项为0。</p>
<p>上面的公式可以化简成如下，此时分式分子就变成了均方误差MSE，分母变成了方差var（标准差是std）</p>
<p><img src="/%22F:%5C%E5%9B%BE%E7%89%87%5Cwebsite%5Cformula6.png%22" alt="R Squared"></p>
<h1 id="4-K-Fold用来干啥？"><a href="#4-K-Fold用来干啥？" class="headerlink" title="4.K-Fold用来干啥？"></a>4.K-Fold用来干啥？</h1><h2 id="有些博主认为K折交叉验证用来进行模型调优，方便找到使得模型泛化性能最优的超参数？我认为，模型调优实在算不上，应该算是用来模型选择的吧？用来评价模型的泛化能力，从而在多个模型中进行选择。"><a href="#有些博主认为K折交叉验证用来进行模型调优，方便找到使得模型泛化性能最优的超参数？我认为，模型调优实在算不上，应该算是用来模型选择的吧？用来评价模型的泛化能力，从而在多个模型中进行选择。" class="headerlink" title="有些博主认为K折交叉验证用来进行模型调优，方便找到使得模型泛化性能最优的超参数？我认为，模型调优实在算不上，应该算是用来模型选择的吧？用来评价模型的泛化能力，从而在多个模型中进行选择。"></a><a href="https://blog.csdn.net/xiaohutong1991/article/details/107924703">有些博主</a>认为K折交叉验证用来进行模型调优，方便找到使得模型泛化性能最优的超参数？我认为，模型调优实在算不上，应该算是用来模型选择的吧？用来评价模型的泛化能力，从而在多个模型中进行选择。</h2><pre><code>sklearn.model_selection.KFold(n_splits=3, shuffle=False, random_state=None)
</code></pre>
<p>根据代码对K-Fold的参数进行剖析：</p>
<blockquote>
<p>n_splits：将数据集划分n_splits个互斥子集，每次用其中一个子集当作验证集，剩下的n_splits-1个作为训练集，进行n_splits次训练和测试，得到n_splits个结果。表示划分几等份</p>
<p>shuffle：在每次划分时，是否进行洗牌</p>
<p>若为Falses时，其效果等同于random_state等于整数，每次划分的结果相同</p>
<p>若为True时，每次划分的结果都不一样，表示经过洗牌，随机取样的</p>
<p>random_state：随机种子数，如果设置了具体数值比如42（随便一个具体数值），那么每次运行结果都是一样的，不会随机产生结果，即每次运行结果都可以复现</p>
</blockquote>
<h1 id="5-K-Fold什么时候用呢？"><a href="#5-K-Fold什么时候用呢？" class="headerlink" title="5.K-Fold什么时候用呢？"></a>5.K-Fold什么时候用呢？</h1><p>问起什么时候才需要用到交叉验证，当然是数据不是很充足的时候才用交叉验证啦！凭借经验，一般数据样本量小于一万条的时候，我们就会采用交叉验证的方法来训练优化选择模型。如果样本量是大于一万条的话，那么我们就是用最常规的方法，也就是将数据集分成三份分别是训练集、验证集和测试集。直接用验证集来评估模型预测的好坏和选择模型及其对应的参数。把最终得到的模型再用于测试集，最终决定使用哪个模型以及对应参数。毕竟你数据量真有这么大，你还要将你的训练成本扩大K倍，权衡利弊使用K-Fold是不明智之选。<em>选择的k值常常是小于等于10的。</em></p>
<p><a href="https://zhuanlan.zhihu.com/p/32627500">知乎用户-鱼遇雨欲语与余</a>根据切分方式的不同，将交叉验证分成了下面三种：</p>
<h2 id="5-1-简单交叉验证"><a href="#5-1-简单交叉验证" class="headerlink" title="5.1 简单交叉验证"></a>5.1 简单交叉验证</h2><p>所谓简单，是相对其他交叉验证而言的。我们先是随机地将样本数据分成两部分，比如说我分了百分之六十的训练集，百分之四十的测试集。训练集训练模型，测试集验证模型以及参数。接着我们将样本打乱，然后重新选择训练集和测试集，继续训练数据和验证模型。最后一步就是选择损失函数评估最优的模型和参数了。<em>在我看来，简单是真的简单，为了评估最优的模型和参数，不惜连测试集都用了…</em></p>
<h2 id="5-2-S折交叉验证"><a href="#5-2-S折交叉验证" class="headerlink" title="5.2 S折交叉验证"></a>5.2 S折交叉验证</h2><p>这是经常会用到的一种验证方法。和第一种方法不同，S折交叉验证先将数据集Dataset随机划分成S个大小相同的互斥子集，每次选择S-1份作为训练集，剩下的1份用来做测试集。当这一轮完成后，重新随机选择  份来训练数据。若干轮（小于  ）之后，选择损失函数评估最优的模型和参数。<em>需要注意的是，交叉验证法评估结果的稳定性和保真性在很大程度上取决于S的取值。那纳闷了，选择哪个S是最好的呢？我认为不论选择哪个S值，应该对最后的模型和参数选择不产生太大的影响吧？</em></p>
<h2 id="5-3-留一交叉验证-Leave-one-out-Cross-Validation"><a href="#5-3-留一交叉验证-Leave-one-out-Cross-Validation" class="headerlink" title="5.3 留一交叉验证 Leave-one-out Cross Validation"></a>5.3 留一交叉验证 Leave-one-out Cross Validation</h2><p>这是一种特别抠门的方法，每一次只用一个样本来预测模型的好坏，也就是说每一次只有一个测试集。这种方法被视为S折交叉验证的特例，只在样本量非常少的情况下才使用。还有一种更抠门的方法是<a href="https://zhuanlan.zhihu.com/p/32412775">自助法</a>…</p>
]]></content>
      <categories>
        <category>Mathine Learning</category>
      </categories>
  </entry>
  <entry>
    <title>图像处理之扇形与矩形图像之间的相互转换</title>
    <url>/2022/11/23/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E4%B9%8B%E6%89%87%E5%BD%A2%E4%B8%8E%E7%9F%A9%E5%BD%A2%E5%9B%BE%E5%83%8F%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<p>数字图像处理作业–将图像进行扇形和矩形之间的变换！</p>
<span id="more"></span>

<h1 id="图像处理之扇形与矩形图像之间的相互转换（Python）"><a href="#图像处理之扇形与矩形图像之间的相互转换（Python）" class="headerlink" title="图像处理之扇形与矩形图像之间的相互转换（Python）"></a>图像处理之扇形与矩形图像之间的相互转换（Python）</h1><h1 id="1-应用"><a href="#1-应用" class="headerlink" title="1.应用"></a>1.应用</h1><p>在分析扇形与矩形图像之间相互处理的程序之前，需要大概了解一下它们存在的意义是什么？</p>
<p>那当然字如其名，将扇形转化为矩形，将矩形转化为扇形啦！🤪🤪🤪</p>
<p>原理当然是这样，但是用处还是很多的！就比如说你上课的时候坐在角落，老师讲到重要内容的时候需要拍照记录。可是你拍出来的效果却是斜的，虽然勉强看的懂，但是看的不舒服。文档校正应运而生。当然，你斜着扫二维码的时候也是同种原理。即使你没有意识到，但是它却实实在在存在。该映射学术名称叫做中心投影变换 &amp;nbsp;  –&gt; &amp;nbsp;  <em><strong>Perspective Mapping</strong></em></p>
<p>我们的扇形与矩形之间的变换也有很多应用，只是我暂时没有想到。</p>
<h1 id="2-引用"><a href="#2-引用" class="headerlink" title="2.引用"></a>2.引用</h1><p>刚拿到课程题目的时候我不是很懂，于是上百度搜寻相关的资料。本着研究中心投影变换的初衷，但是却没想到找到了相关的代码，真是意外的收获。CSDN大佬<strong>天元浪子</strong>在这篇博文中是研究从矩形到扇形的变换，而我是相反的。代码我copy到了文末，用于与原来的代码作比较，下面是原文链接。</p>
<blockquote>
<p><a href="https://blog.csdn.net/xufive/article/details/104675998">https://blog.csdn.net/xufive/article/details/104675998</a></p>
</blockquote>
<p>如果需要用的是MATLAB，那么可以参考以下两个链接。</p>
<blockquote>
<p><a href="https://blog.csdn.net/u014495306/article/details/74079963">https://blog.csdn.net/u014495306/article/details/74079963</a></p>
<p><a href="https://blog.csdn.net/weixin_34068198/article/details/94256613">https://blog.csdn.net/weixin_34068198/article/details/94256613</a></p>
</blockquote>
<h1 id="3-使用"><a href="#3-使用" class="headerlink" title="3.使用"></a>3.使用</h1><p>代码我就不打算分析了，看注释很快就可以理解。</p>
<p>&#96;&#96;# -<em>- coding:utf-8 -</em>-</p>
<p>import numpy as np</p>
<p>from PIL import Image</p>
<p>import matplotlib.pyplot as plt</p>
<p>def square2fan(input, output, angle&#x3D;45):</p>
<h1 id="将扇形图像转化为矩阵图像"><a href="#将扇形图像转化为矩阵图像" class="headerlink" title="将扇形图像转化为矩阵图像"></a>将扇形图像转化为矩阵图像</h1><pre><code>input      - 输入文件名
output      - 输出文件名
angle       - 扇形夹角度数
angle在这个例子中是45度，如果改大的话将会缩小输出图片的宽度cols

im = Image.open(input)  # 打开输入图像为PIL对象 
mode = im.mode  # 输入图像模式\
w, h = im.size  # 输入图像分辨率(宽在前，高在后)
rows, cols = int(np.ceil(h)), int(np.ceil(w))  # 输出图像高度和宽度
in_interval = np.array(im)  # 输入图像转为numpy数组
# 生成输出图像的numpy数组（全透明）
out_interval = np.zeros((rows, cols, in_interval.shape[2]), dtype=np.uint8)

alpha = np.radians(np.linspace(-angle, angle, w))  # 生成扇形角度序列，长度与输入图像宽度一致
for i in range(w):  # 遍历输入图像的每一列
    # 当前列各像素在输出图像上的行号

    # d = np.cos(alpha[i])*h 和 d = np.cos(alpha[i])*rows效果等同，方便后边的切片
    d = np.cos(alpha[i])*h
    lats = np.int_(np.linspace(0, d, h)).astype(np.int)
    # 当前列各像素在输出图像上的列号
    d = np.sin(alpha[i])*h
    lons = np.int_(np.linspace(cols/2,
                   cols/2+d, h)).astype(np.int)
    # 将算出来的扇形的斜列的值，放进空矩阵中
    out_interval[:, i] = in_interval[(lats, lons)]
# 保存为文件
im = Image.fromarray(out_interval, mode=im.mode)
im.save(output)
</code></pre>
<p>if <strong>name</strong> &#x3D;&#x3D; ‘<strong>main</strong>‘:<br>    square2fan(‘out.png’, ‘rectangle.png’, angle&#x3D;45)</p>
<p>&#96;&#96;</p>
<h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h1><p>题目不难，但是花了我挺多时间，也暴露出了我一些问题…😅😅😅</p>
<blockquote>
<p>对Python的库不是很熟悉（其实不经常用，记不得我觉得也很正常）</p>
<p>嗯？让我想想我到底还有啥问题先？</p>
<p>……</p>
<p>好像并没有什么问题?😦</p>
</blockquote>
]]></content>
      <categories>
        <category>Homework</category>
      </categories>
  </entry>
  <entry>
    <title>感觉夏天来了!</title>
    <url>/2022/11/28/%E6%84%9F%E8%A7%89%E5%A4%8F%E5%A4%A9%E6%9D%A5%E4%BA%86/</url>
    <content><![CDATA[<p>今天十一月二十八日，连续一周的降雨让我整个人都感觉湿漉漉的。烦恼的不仅仅是衣物没法干鞋子该换着穿这种零碎的琐事，更多的是来自生活的压力…</p>
<span id="more"></span>
<p>压力什么的不想谈，谈了也没多大意思。</p>
<p>今天突然想写日记也并不是偶然，之前也想写，但是由于自己拖拉的性格，让我把这些想做的事情都堆在了心绪的箱底，一直都没法去做。这种坏习惯自打我上大学便沾染上了，很多时候都想改正，但是却无能为力，反而想用摆脱拖拉是否有意义这种问题来试图宽慰自己。我很清楚这一点，但我还是置之不管，任由其发展。像这种大步子的改变生活习惯的做法，我是一点计划都没有，这点消极态度感觉与齐宣王的有事钟无艳，无事夏迎春颇有几分相似呢！</p>
<p>我觉得疫情受困对于我来说并不是很大影响，因为我现在倒是过得自由自在的(不过要没有疫情我也可能过得更自由自在)。虽然宅在宿舍不错，但人总是要出去面对世界的嘛！现在有一点感觉困惑的就是，疫情可以说没有困住我，却把外面的世界给封住了，让我寸步难行。想要去附近走走还得查查目的地是否是风险地区这样的操作已经让我很心烦了，什么时候能够真正解放好像遥遥无期，不过像我这样做不了啥的升斗小市民还是做好自己分内的事吧！</p>
<p>刚才还想夸今天的风很有夏天的感觉，但走到阳台看到天空被蓝天和乌云像是被分成了泾渭两河，心里五味杂陈很不是滋味，感觉一些不好的事情正在酝酿。庆幸的是自己是在蓝天之下，这一点倒是让我宽慰了许多。我还记得前几天才过了小雪，今天的天气倒是光着膀子到处溜也没问题，广州的天气还真是很奇怪！</p>
<p>什么暴风雨过后的彩虹、照进我心底的一束久违的阳光这样肉麻的话我就不想说了，不过今天能够看到蓝天和太阳确实让自己的心情快活了许多。说实在，这几天下雨我也没有多盼望晴天能够到来，像是被阴雨天麻痹了一样。倒是今天看到了太阳，却吐槽太阳为什么不早点出来。看着天上的云，就像是夏天暴风雨前夕的那种云，浓墨重彩，什么阴影和线条被狠狠地勾勒出来，想说的就只有罗辑面对面壁者计划那句纯粹的卧槽！</p>
<p>风打到脸上，我很肯定这就是夏天的风！</p>
<img src="/uploads/dormitory.jpg" class="post-image">
<strong>里面是生活，外面是我的世界啊！</strong>

<hr>
<div class="video-container"><iframe src="https://www.youtube.com/embed/YAXTn0E-Zgo" frameborder="0" loading="lazy" allowfullscreen></iframe></div>]]></content>
      <categories>
        <category>School Life</category>
      </categories>
      <tags>
        <tag>音视频</tag>
        <tag>生活</tag>
        <tag>YouTube</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络CNN学习一</title>
    <url>/2022/11/24/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN%E5%AD%A6%E4%B9%A0%E4%B8%80/</url>
    <content><![CDATA[<p>今天二十四号，学习卷积神经网络的第一天。虽然以前就对CNN有过了解，但是没有经过系统性的学习，对许多方面的知识点都是一知半解。在学习CNN之前，首先要明确的一点是：Deep Learning是全部深度学习算法的总称，而CNN是深度学习算法在图像处理领域的一个应用罢了…</p>
<span id="more"></span>

<h1 id="为什么不使用全连接神经网络处理呢？"><a href="#为什么不使用全连接神经网络处理呢？" class="headerlink" title="为什么不使用全连接神经网络处理呢？"></a>为什么不使用全连接神经网络处理呢？</h1><p>如果使用全连接神经网络处理大尺寸的图像时，会有三个明显的缺点：</p>
<ol>
<li>将图像展开为向量会丢失空间信息</li>
<li>参数过多。效率低、训练难</li>
<li>大量的参数很快导致网络过拟合</li>
</ol>
<p>而卷积神经网络可以很好的解决以上问题。</p>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>在hexo搭建博客遇到的问题</title>
    <url>/2022/11/23/%E5%9C%A8hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>之前我用的主题感觉索然无味，于是我尝试换了一个主题，结果发现了新大陆！激动的话我就不在这里详细张开来讲了，我会放在另外一篇文章里，这里主要讲讲我在Hexo上搭建Next遇到的问题以及解决方法。</p>
<span id="more"></span>

<h1 id="Hexo搭建了博客显示不出Categories和Tags"><a href="#Hexo搭建了博客显示不出Categories和Tags" class="headerlink" title="Hexo搭建了博客显示不出Categories和Tags"></a>Hexo搭建了博客显示不出Categories和Tags</h1><h2 id="在主题配置文件中取消注释Categories和Tags"><a href="#在主题配置文件中取消注释Categories和Tags" class="headerlink" title="在主题配置文件中取消注释Categories和Tags"></a>在主题配置文件中取消注释Categories和Tags</h2><p>博客文件中一共有两类配置文件，一类是Hexo的配置文件、另一类是主题配置文件。首先要做的事是将主题配置文件打开，找到Menu Settings并且把Categories和Tags取消注释。</p>
<h2 id="新建页面"><a href="#新建页面" class="headerlink" title="新建页面"></a>新建页面</h2><p>在你的source文件夹中新建文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new page categories</span><br><span class="line">hexo new page tags</span><br><span class="line">hexo new page about</span><br><span class="line">hexo new page schedule</span><br></pre></td></tr></table></figure>

<h2 id="修改index-md"><a href="#修改index-md" class="headerlink" title="修改index.md"></a>修改index.md</h2><p>上面除了categories和tags我还写入了关于和日程表页面，只要你有需求就可以在主题配置文件中将他们打开。它们的处理方式都是类似的，所以我将它们放在一起讨论。</p>
<p>打开source文件夹下的index.md文件后，开头只有title和data，我们要做就是在后面加上一句<code>type: categories</code>，其它也是同理。注意冒号后面有空格。</p>
<p>之前有人说用<code>layout: categories</code>的方式也可以，我尝试了一下，发现已经失效了。原因可能是因为当前的hexo已经不支持layout这种格式了。</p>
<h1 id="hexo建立同级categories"><a href="#hexo建立同级categories" class="headerlink" title="hexo建立同级categories"></a>hexo建立同级categories</h1><p>之前我对categories还没有分级和同级的概念，直到我对一篇文章想要运用多个categories的时候才初现端倪。网上的人都说hexo已经不支持同级分类了（但是我确实实现同级分类了）</p>
<p>如果我们在outline如何命名：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">categories: </span><br><span class="line">- ML</span><br><span class="line">- Homework</span><br></pre></td></tr></table></figure>

<p>或者说是这样</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">categories: [ML, Homework]</span><br></pre></td></tr></table></figure>

<p>上面两种方法效果一样，Homework都是ML下的子类，你要是有<code>categories: [Homework]</code>这个目录，你会发现它们并不是相同的！因为一个是Homework一个是ML下的Homework。</p>
<p>要是真想ML和Homework有同样的级别，可以尝试一下以下方法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">categories:</span><br><span class="line">- [ML]</span><br><span class="line">- [Homework]</span><br></pre></td></tr></table></figure>

<h1 id="hexo主页不显示全文"><a href="#hexo主页不显示全文" class="headerlink" title="hexo主页不显示全文"></a>hexo主页不显示全文</h1><p>在outline下面，你需要加入一段简介，作为这篇文章的介绍，随后再加入<code>&lt;!-- more --&gt;</code>，那么下面的内容便可以被隐藏。若是不加简介的话，<code>&lt;!-- more --&gt;</code>隐藏下面的功能便会失效。</p>
<h1 id="hexo配置Next教程链接"><a href="#hexo配置Next教程链接" class="headerlink" title="hexo配置Next教程链接"></a>hexo配置Next教程链接</h1><ul>
<li><a href="https://zhuanlan.zhihu.com/p/351031589">知乎详细配置</a></li>
<li><a href="https://blog.csdn.net/nightmare_dimple/article/details/86661502?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-86661502-blog-100138838.pc_relevant_3mothn_strategy_and_data_recovery&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-86661502-blog-100138838.pc_relevant_3mothn_strategy_and_data_recovery&utm_relevant_index=3">CSDN-主题优化1</a></li>
<li><a href="https://blog.csdn.net/as480133937/article/details/100138838">CSDN-主题优化2-more extended functions!</a></li>
<li><a href="http://home.ustc.edu.cn/~liujunyan/blog/hexo-next-theme-config/#hexo-%E9%85%8D%E7%BD%AE">Next页面配置</a></li>
<li><a href="http://theme-next.iissnan.com/getting-started.html">Next官方文档</a></li>
</ul>
<h1 id="hexo常用命令"><a href="#hexo常用命令" class="headerlink" title="hexo常用命令"></a>hexo常用命令</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo n &quot;name&quot;       # 新建文章</span><br><span class="line">hexo new page &quot;name&quot;  # 新建页面</span><br><span class="line">hexo g                # 生成页面</span><br><span class="line">hexo d                # 部署</span><br><span class="line">hexo g -d             # 生成页面并部署</span><br><span class="line">hexo s                # 本地预览</span><br><span class="line">hexo clean            # 清除缓存和已生成的静态文件</span><br><span class="line">hexo help             # 帮助</span><br></pre></td></tr></table></figure>

<p>但是我通常都是使用<code>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</code>,因为其他的很少用到！</p>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title>插入YouTube视频</title>
    <url>/2022/11/23/%E6%8F%92%E5%85%A5YouTube%E8%A7%86%E9%A2%91/</url>
    <content><![CDATA[<p>尝试在文章中插入一段YouTube视频，就放我最近经常听的一首歌吧！</p>
<span id="more"></span>

<div class="video-container"><iframe src="https://www.youtube.com/embed/crIP7PuC8Bc" frameborder="0" loading="lazy" allowfullscreen></iframe></div>

]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>音视频</tag>
        <tag>YouTube</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习派系</title>
    <url>/2022/11/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B4%BE%E7%B3%BB/</url>
    <content><![CDATA[<p>机器学习有不同的学派，每个学派从不同的角度看问题。这也是偶然了解到，感觉对日后的理解和学习有帮助，于是便记录下来…</p>
<span id="more"></span>

<h1 id="机器学习5大学派！"><a href="#机器学习5大学派！" class="headerlink" title="机器学习5大学派！"></a>机器学习5大学派！</h1><p>机器学习有不同的学派，每个学派从不同的角度看问题。</p>
<ol>
<li><p>符号学派（symbolists） 更多关注哲学，逻辑学和心理学， 并将学习视为逆向演绎 。使用符号、规则和逻辑来表征知识和进行逻辑推理主要是基于规则的，算法如 ：决策树。</p>
</li>
<li><p>联结学派（connectionists）专注物理学和神经科学，并相信大脑的逆向工程。使用概率矩阵和加权神经元来动态地识别和归纳模式，算法如 ：神经网络 。</p>
</li>
<li><p>进化学派，在遗传学和进化生物学的基础上得出结论。生成变化，然后为特定目标获取其中最优的， 算法如 ：遗传算法 。</p>
</li>
</ol>
<p>4. 贝叶斯学派（Bayesians）注重统计学和概率推理。 获取发生的可能性来进行概率推理，算法如 ：朴素贝叶斯，马尔可夫。</p>
<p>5. 类推学派（analogizers）更多是关注心理学和数学优化来推断相似性判断。 根据约束条件来优化函数，算法如：支持向量机SVM。</p>
<h1 id="演化的阶段"><a href="#演化的阶段" class="headerlink" title="演化的阶段"></a>演化的阶段</h1><blockquote>
<p>1980 年代             主导流派：符号主义</p>
<p>1990 年代到 2000 年    主导流派：贝叶斯</p>
<p>2010 年代早期到中期   主导流派：联结主义</p>
<p>2010 年代末期    主导流派：联结主义+符号主义</p>
<p>2020 年代+         主导流派：联结主义+符号主义+贝叶斯+……</p>
<p>2040 年代+         主导流派：算法融合 </p>
</blockquote>
<h1 id="联结学派（The-connectionists）"><a href="#联结学派（The-connectionists）" class="headerlink" title="联结学派（The connectionists）"></a>联结学派（The connectionists）</h1><p>联结学派的主要思想是通过神经元之间的连接来推导知识。联结学派聚焦于物理学和神经科学，并相信大脑的逆向工程（reverse engineering）。他们相信用反向传播算法或“向后传播错误”的算法来训练人工神经网络以获取结果。</p>
<p>多伦多大学的 Geoff Hinton 是机器学习领域的顶尖研究者之一。Hinton 积极与谷歌合作，也是推动“深度学习”模式的人物。深度学习在许多不同领域彻底变革了 AI，如语音识别，图像描述及生成有意义的句子。</p>
<p>几乎所有大科技公司，包括 Facebook，微软，谷歌等，都正在使用这种模式来改进它们的系统。Navdeep Jaitly 是谷歌大脑团队的研究科学家，他在 Hinton 门下进行研究，使用深度学习模型超越了 Android 系统中已经“精细调好”（fine-tuned）的语音识别算法。</p>
<p>Facebook AI Research（FAIR）的主管 Yann LeCun 是这个研究领域的另一位大牛。Yann 也是在 Hinton 门下读博士学位，并致力于深度学习领域。</p>
<p>作为蒙特利尔学习算法研究所的负责人，Yoshua Bengio 是另一个值得注意的名字，是联结学派方法的领军人物。Bengio 致力于组织不同的 AI 相关活动和会议，包括学习研讨会。Bengio 和他的学生 Ian Goodfellow（现在是 OpenAI 的研究员）以及 Aaron Courville 一起合著了著名的深度学习教材Deep Learning。</p>
<p>机器学习领域的许多研究者，特别是联结学派者，认为深度学习模型是 AI 的所有问题的答案，并认为它是一个主算法。</p>
<h1 id="符号学派（The-symbolists）"><a href="#符号学派（The-symbolists）" class="headerlink" title="符号学派（The symbolists）"></a>符号学派（The symbolists）</h1><p>符号学派的方法基于对问题的“高阶”（high-level）解释。符号主义者更侧重哲学，逻辑学和心理学，并把学习视为逆向演绎（inverse of deduction）。John Haugeland 在他的著作 Artificial Intelligence: The Very Idea中称之为“Good Old-Fashioned Artificial Intelligence” (GOFAI)。符号学派解决问题的方法是使用预先存在的知识来填补空白。大多数专家系统使用符号学派的方法，以 If-Then 的方式解决问题。</p>
<p>卡内基梅隆大学的 Tom Mitchell 是符号学派的领军人物之一。Udacity 联合创始人，斯坦福大学教授，前谷歌副总裁 Sebastian Thrun，以及艾伦人工智能研究所 CEO Oren Etzioni 都是 Tom Mitchell 的学生。</p>
<p>伦敦帝国理工学院教授，Inductive Acquisition of Expert Knowledge的作者 Stephen Muggleton，以及 RuleRequest 的创始人 Ross Quinlan 均是推崇符号学派机器学习方法的著名研究者。</p>
<h1 id="进化学派（The-evolutionaries）"><a href="#进化学派（The-evolutionaries）" class="headerlink" title="进化学派（The evolutionaries）"></a>进化学派（The evolutionaries）</h1><p>第三个学派，是进化学派，他们在遗传学和进化生物学的基础上得出结论。2015年去世的 John Holland 曾在密歇根大学任教，他在将达尔文的进化理论引入计算机科学方面发挥了非常重要的作用。Holland 是遗传算法（genetics algorithms）的先驱，他提出的“遗传算法的基本定理”被认为是这个领域的基础。</p>
<p>机器人学，3D打印和生物信息学领域的许多工作是哥伦比亚大学创意力学实验室主任 Hod Lipson 等进化论者进行的。John Koza 是前斯坦福大学教授，Scientific Games 公司的创始人，也是遗传算法的另一名先驱人物。另外，Serafim 实验室的创始人，斯坦福大学计算机科学教授 Serafim Batzoglou 也是计算机基因组领域的著名研究者。</p>
<h1 id="贝叶斯学派（The-Bayesian-school-of-thought）"><a href="#贝叶斯学派（The-Bayesian-school-of-thought）" class="headerlink" title="贝叶斯学派（The Bayesian school of thought）"></a>贝叶斯学派（The Bayesian school of thought）</h1><p>如果你使用电子邮件超过10年，应该能感觉到垃圾邮件过滤系统的改进。这是机器学习中的贝叶斯学派的功劳。贝叶斯学派专注于研究概率推理和用贝叶斯定理解决问题。贝叶斯学派从一个信念开始，他们称之为“先验”（prior）。然后，他们收集一些数据，并基于该数据更新先验；得到的结果他们称之为“后验”（posterior）。然后，他们用更多的数据来处理后验，并使之变成先验。这个过程不断循环往复，知道得到最终的答案。大多数垃圾邮件过滤系统是在这种基础上起作用。</p>
<p>加州大学洛杉矶分校计算机科学系的 Judea Pearl 是贝叶斯方法的著名研究者之一。微软 Genomics Group 的负责人 David Heckerman 也是著名的贝叶斯方法研究者，他帮助微软在 Outlook 和 Hotmail 邮件系统中开发了不同的数据挖掘工具和垃圾邮件过滤工具。</p>
<p>加州大学伯克利分校的 Michael Jordan 也是这一领域的主要研究者。</p>
<h1 id="类推学派（The-analogizers）"><a href="#类推学派（The-analogizers）" class="headerlink" title="类推学派（The analogizers）"></a>类推学派（The analogizers）</h1><p>机器学习的第五个分支学派是类推学派（Analogizers），他们更多地关注心理学和数学最优化，通过外推来进行相似性判断。类推学派遵循“最近邻”原理进行研究。各种电子商务网站上的产品推荐（例如亚马逊或 Netflix的电影评级）是类推方法最常见的示例。</p>
<p>印第安纳大学的 Douglas Hofstadter（侯世达）是认知科学中最有名的科学家。同一领域的另一位知名科学家是 Vladimir Vapnik，他也是“支持向量机”的共同发明者和 Vapnik-Chervonenkis 理论的主要开发者。Facebook 最近聘请 Vapnik 与其他几位知名研究人员一起加入 Facebook AI 实验室。此外，理光创新（Ricoh Innovations）创始人 Peter Hart 也是遵循类推方法的著名学者，Hart 与人合著了《模式分类》一书。</p>
<h1 id="危机与问题"><a href="#危机与问题" class="headerlink" title="危机与问题"></a>危机与问题</h1><p>所有上述学派解决不同的问题，提出了不同的解决方案。而真正的挑战是设计一个算法，解决这些方法尝试要解决的所有不同的问题——单一的一个“终极算法”。</p>
<p>我们仍然处在机器学习和 AI 的早期，还有很多事情要做。我们不知道什么时候，哪里会出现问题，而这将会减缓整个发展进程，带来下一个“AI冬天”。又或者，将来会出现一个新的突破，彻底改变目前的情况。</p>
<p>机器学习的进步更像是一场演化。正如微生物的发展速度远比人类更快，机器学习的发展也比人类快，但会到达一个阶段，在这个阶段上这些学习算法会变得太过复杂而不能快速演化。</p>
<p>也存在其他的危机。一个“理想的”终极算法将了解有关我们的一切。虽然机器学习需要人类的输入作为启动，但它最终会达到一个点，它会超越人类。那么接下来会发生什么呢？只要它们的目标和我们的目标稍有分歧，可能就足以消灭人类。</p>
<p>这只是一种情况。假设我们成功建立了一个能够控制这些超级智能的机制，就类似于蚂蚁创造了一个能够控制我们人类的机制。但是，国家，人们和团体之间存在的利益冲突，可能会引发类似“天网”（终结者）的战争。</p>
<h1 id="机器学习如何改变世界？"><a href="#机器学习如何改变世界？" class="headerlink" title="机器学习如何改变世界？"></a>机器学习如何改变世界？</h1><p>有许多初创公司专注于机器学习及其为生活中的不同问题带来的解决方案；而且，更重要的是，有大型科技公司支持他们。例如，谷歌收购的 DeepMind 专注于医疗保健，利用机器学习研究癌症的治疗；Facebook 的 Chan Zuckerberg Initiative 宣布计划在未来十年投资30亿美元，以帮助治疗、预防和管控疾病。</p>
<p>另外，世界上最大的一些科技公司，包括亚马逊，Facebook，谷歌，微软等形成了联盟“Partnership on AI”，以共享他们的大型数据库进行研究，推广好的实践。</p>
<p>AI 是否将技术的发展引向了一条危险的路径？我们将要成为机器的奴隶，又或 AI 是将人类引向终极的进步的入口？</p>
<p>任何希望了解 AI 和机器学习的人士都应该阅读一下 Pedro Domingos 的《终极算法》一书。最后，让我们借用此书序言里的一句话作为本文的结语：围绕大数据以及机器学习的讨论充满争议，如果你对此感到好奇，且怀疑有比论文上看到的更为深层次的东西，那么这本书就是你进行革命的指南。</p>
<h1 id="出处"><a href="#出处" class="headerlink" title="出处"></a>出处</h1><p><em>今天在学习机器学习的时候，发现机器学习惊竟然还分派系，略感兴趣，遂转于此！</em></p>
<ol>
<li><a href="https://www.jianshu.com/p/55ccb15747b5">简书-转载</a></li>
<li><a href="https://techcrunch.com/2017/01/30/is-a-master-algorithm-the-solution-to-our-machine-learning-problems/">Yahoo原文</a></li>
</ol>
]]></content>
      <categories>
        <category>Mathine Learning</category>
        <category>Things of Interest</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>激活函数</title>
    <url>/2022/11/23/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<p>学习一下机器学习中常见的激活函数，大部分只是了解即可，不必深究</p>
<span id="more"></span>

<h1 id="常用的激活函数"><a href="#常用的激活函数" class="headerlink" title="常用的激活函数"></a>常用的激活函数</h1><h2 id="首先要知道什么是激活函数？"><a href="#首先要知道什么是激活函数？" class="headerlink" title="首先要知道什么是激活函数？"></a>首先要知道什么是激活函数？</h2><p>激活函数就是在神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端。它类似于人类大脑中基于神经元的模型，激活函数最终决定了要发射给下一个神经元的内容。</p>
<p>它的可视化过程如图所示：</p>
<p><img src="https://ask.qcloudimg.com/http-save/8352478/mn5asmil0s.png?imageView2/2/w/1620" alt="激活函数工作过程"></p>
<p>如果不用激励函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合。神经网络中使用激活函数来加入非线性因素，提高模型的表达能力。</p>
<h2 id="1-sigmoid激活函数"><a href="#1-sigmoid激活函数" class="headerlink" title="1. sigmoid激活函数"></a>1. sigmoid激活函数</h2><p><img src="https://ask.qcloudimg.com/http-save/8352478/nhi9swy8ln.png?imageView2/2/w/1620" alt="sigmoid函数"></p>
<p>Sigmoid 函数的图像看起来像一个 S 形曲线。它的表达式如下：</p>
<p>f(z) &#x3D; \frac{1}{1+e^{-z} } </p>
<p>Sigmoid函数是传统神经网络中最常用的激活函数，一度被视为神经网络的核心所在。 </p>
<p>从数学上来看，Sigmoid函数对中央区的信号增益较大，对两侧区的信号增益小，在信号的特征空间映射上，有很好的效果。从神经科学上来看，中央区酷似神经元的兴奋态，两侧区酷似神经元的抑制态，因而在神经网络学习方面，可以将重点特征推向中央区，将非重点特征推向两侧区。</p>
<h3 id="1-1-在什么情况下适合使用-Sigmoid-激活函数呢？"><a href="#1-1-在什么情况下适合使用-Sigmoid-激活函数呢？" class="headerlink" title="1.1 在什么情况下适合使用 Sigmoid 激活函数呢？"></a>1.1 在什么情况下适合使用 Sigmoid 激活函数呢？</h3><ul>
<li>Sigmoid 函数的输出范围是 0 到 1。由于输出值限定在 0 到 1，因此它对每个神经元的输出进行了归一化；</li>
<li>用于将预测概率作为输出的模型。由于概率的取值范围是 0 到 1，因此 Sigmoid 函数非常合适；</li>
<li>梯度平滑，避免「跳跃」的输出值；</li>
<li>函数是可微的。这意味着可以找到任意两个点的 sigmoid 曲线的斜率；</li>
<li>明确的预测，即非常接近 1 或 0。</li>
<li></li>
</ul>
<h3 id="1-2-Sigmoid-激活函数有哪些缺点？"><a href="#1-2-Sigmoid-激活函数有哪些缺点？" class="headerlink" title="1.2 Sigmoid 激活函数有哪些缺点？"></a>1.2 Sigmoid 激活函数有哪些缺点？</h3><ul>
<li>倾向于梯度消失；</li>
<li>函数输出不是以 0 为中心的，这会降低权重更新的效率；</li>
<li>Sigmoid 函数执行指数运算，计算机运行得较慢。</li>
</ul>
<p>现在基本上已经用不上sigmoid函数了。</p>
<h2 id="2-TanHyperbolic（tanh）双曲正切激活函数"><a href="#2-TanHyperbolic（tanh）双曲正切激活函数" class="headerlink" title="2. TanHyperbolic（tanh）双曲正切激活函数"></a>2. TanHyperbolic（tanh）双曲正切激活函数</h2><p><img src="https://ask.qcloudimg.com/http-save/8352478/gm9p8du88z.png?imageView2/2/w/1620" alt="tanh函数"></p>
<p>tanh 激活函数的图像也是 S 形，表达式如下：</p>
<p>f(z) &#x3D; tanh(z) &#x3D;  \frac{e^{z} - e^{-z}  }{e^{z} + e^{-z} }  &#x3D; \frac{2}{1 + e^{-2z} }-1 </p>
<p>tanh 是双曲正切函数。tanh 函数和 sigmoid 函数的曲线相似。但是它比 sigmoid 函数更有一些优势。</p>
<ul>
<li><p>sigmoid函数和tanh函数都存在一个问题：当神经网络的层数增多的时候，由于在进行反向传播的时候，链式求导，多项相乘，函数进入饱和区（导数接近于零的地方）就会逐层传递，这种现象被称为梯度消失。</p>
</li>
<li><p>首先要明确的一点是，当输入较大或较小时，输出几乎是平滑的并且梯度较小，这不利于权重更新。tanh 整个函数以 0 为中心，比 sigmoid 函数更好。在实际操作的时候，tanh 函数延迟了饱和期，在特征相差比较明显的时候效果会更好，并且在循环过程中也能够不断地扩大特征的效果。</p>
</li>
<li><p>在一般的二元分类问题中，tanh 函数用于隐藏层，而 sigmoid 函数用于输出层，但这并不是固定的，需要根据特定问题进行调整。</p>
</li>
</ul>
<h2 id="3-softmax激活函数"><a href="#3-softmax激活函数" class="headerlink" title="3. softmax激活函数"></a>3. softmax激活函数</h2><p>公式表达为：</p>
<p>f(z) &#x3D; \frac{e^{Z_j} }{\sum_{k}^{}e^{Z_k} } </p>
<p>Sigmoid函数如果用来分类的话，只能进行二分类，而这里的softmax函数可以看做是Sigmoid函数的一般化，可以进行多分类。</p>
<h3 id="3-0-Softmax激活函数的特点："><a href="#3-0-Softmax激活函数的特点：" class="headerlink" title="3.0 Softmax激活函数的特点："></a>3.0 Softmax激活函数的特点：</h3><ul>
<li>在零点不可微。</li>
<li>负输入的梯度为零，这意味着对于该区域的激活，权重不会在反向传播期间更新，因此会产生永不激活的死亡神经元。</li>
</ul>
<h3 id="3-1-sigmoid与softmax比较-–-gt-sigmoid"><a href="#3-1-sigmoid与softmax比较-–-gt-sigmoid" class="headerlink" title="3.1 sigmoid与softmax比较 –&gt; sigmoid"></a>3.1 sigmoid与softmax比较 –&gt; sigmoid</h3><p>二分类和多分类其实没有多少区别。用的公式仍然是y &#x3D; wx + b。 但有一个非常大的区别是他们用的激活函数是不同的。 逻辑回归用的是sigmoid，这个激活函数的除了给函数增加非线性之外还会把最后的预测值转换成在[0,1]中的数据值。也就是预测值是0&lt;y&lt;1。 我们可以把最后的这个预测值当做是一个预测为正例的概率。在进行模型应用的时候我们会设置一个阈值，当预测值大于这个阈值的时候，我们判定为正例子，反之我们判断为负例。这样我们可以很好的进行二分类问题。 </p>
<h3 id="3-2-sigmoid与softmax比较-–-gt-softmax"><a href="#3-2-sigmoid与softmax比较-–-gt-softmax" class="headerlink" title="3.2 sigmoid与softmax比较 –&gt; softmax"></a>3.2 sigmoid与softmax比较 –&gt; softmax</h3><p>Softmax函数是用于多类分类问题的激活函数，在多类分类问题中，超过两个类标签则需要类成员关系。对于长度为K的任意实向量，Softmax函数可以将其压缩为长度为K，值在[0,1]范围内，并且向量中元素的总和为1的实向量。</p>
<blockquote>
<p>Softmax函数与正常的max函数不同：max函数仅输出最大值，但Softmax函数确保较小的值具有较小的概率，不会直接丢弃。我们可以认为它是arg max函数的概率版本或“soft”版本。Softmax函数的分母结合了原始输出值的所有因子，这意味着Softmax函数获得的各种概率彼此相关。</p>
</blockquote>
<blockquote>
<p>利用 softmax 可以用于多分类问题，而用多个logistic回归通过叠加也同样可以实现多分类的效果，但是 softmax回归进行的多分类，类与类之间是互斥的，即一个输入只能被归为一类。多个logistic回归进行多分类，输出的类别并不是互斥的，即”苹果”这个词语既属于”水果”类也属于”3C”类别。</p>
</blockquote>
<h2 id="4-ReLU-激活函数"><a href="#4-ReLU-激活函数" class="headerlink" title="4. ReLU 激活函数"></a>4. ReLU 激活函数</h2><p><img src="https://ask.qcloudimg.com/http-save/8352478/ck888so4in.png?imageView2/2/w/1620" alt="ReLu激活函数"></p>
<p>ReLu函数的全称为Rectified Linear Units–&gt;修正线性单元,表达式为</p>
<p>f(z) &#x3D; max(0,z)</p>
<h3 id="Sigmoid-，tanh与ReLU-比较"><a href="#Sigmoid-，tanh与ReLU-比较" class="headerlink" title="Sigmoid ，tanh与ReLU 比较"></a>Sigmoid ，tanh与ReLU 比较</h3><p>sigmoid，tanh 会出现梯度消失问题，ReLU 的导数就不存在这样的问题。</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>从计算的角度上，Sigmoid和Tanh激活函数均需要计算指数，复杂度高，而ReLU只需要一个阈值即可得到激活值。</li>
<li>ReLU的非饱和性有效地解决梯度消失的问题，提供相对宽的激活边界。</li>
<li>ReLU的单侧抑制，提供了网络的稀疏表达能力</li>
</ul>
<p><strong>稀疏表示（Sparse Representations）的定义：用较少的基本信号的线性组合来表达大部分或者全部的原始信号。</strong></p>
<p><em>具体稀疏性的体现是：Relu会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生。</em><strong>只能说有利有弊了…</strong></p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>Dead ReLU 问题。当输入为负时，ReLU 完全失效，在正向传播过程中，这不是问题。但是在反向传播过程中，如果输入负数，则梯度将完全为零，即在训练过程中会导致神经元死亡。sigmoid 函数和 tanh 函数也具有相同的问题。</li>
<li>我们发现 ReLU 函数的输出为 0 或正数，这意味着 ReLU 函数不是以 0 为中心的函数。</li>
</ul>
<p><strong>神经元死亡会导致该神经元在之后不被任何数据激活，即流经该神经元的梯度永远为0，不对任何数据产生响应。在实际训练中，如果学习率设置较大，会导致一定比例的神经元不可逆死亡，进而参数梯度无法更新，整个训练过程失败。</strong></p>
<h2 id="5-softplus激活函数"><a href="#5-softplus激活函数" class="headerlink" title="5. softplus激活函数"></a>5. softplus激活函数</h2><p>公式表达式为：</p>
<p>softplus(z)&#x3D;log(1+e^z)</p>
<p>softplus函数与ReLU函数接近,但比较平滑, 同ReLU一样是单边抑制,有宽广的接受域(0,+inf), 但是由于指数运算,对数运算计算量大的原因,而不太被人使用。</p>
<p><img src="https://images2018.cnblogs.com/blog/1252882/201807/1252882-20180707095338849-1750990328.png" alt="softplus激活函数"></p>
<p>可以看到，softplus可以看作是ReLu的平滑。根据神经科学家的相关研究，softplus和ReLu与脑神经元激活频率函数有神似的地方。也就是说，在生物层面上，相比于早期的激活函数，softplus和ReLu更加接近脑神经元的激活模型。其中，<strong>RELU函数的引入给神经网络增加了生物学特性，可以称为灵魂激活函数。</strong></p>
<p>softplus的导数就是sigmoid函数，还是很巧合的。还有一点就是，据说softplus的出现要比ReLu要早，也就是说softplus可以看成是ReLu的鼻祖？</p>
<h2 id="6-Leaky-ReLU激活函数"><a href="#6-Leaky-ReLU激活函数" class="headerlink" title="6. Leaky ReLU激活函数"></a>6. Leaky ReLU激活函数</h2><p>它是一种专门设计用于解决 Dead ReLU 问题的激活函数：</p>
<p><img src="https://ask.qcloudimg.com/http-save/8352478/zdls8bt48h.png?imageView2/2/w/1620" alt="Leaky ReLu"></p>
<p>当 x &lt; 0的时候， f(x) &#x3D; \alpha x,其中\alpha 非常小，这样可以避免在x &lt; 0的时候，不能够学习的情况。</p>
<p>f(x) &#x3D; max(\alpha x,x)</p>
<blockquote>
<p>将\alpha 作为可学习的参数，称为Parametric Rectifier(PReLU)</p>
<p>当\alpha 从高斯分布中随机产生时称为Random Rectifier（RReLU）</p>
<p>当固定为\alpha &#x3D; 0.01时,称为Leaky ReLU</p>
</blockquote>
<h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><ul>
<li>不会过拟合(saturate)</li>
<li>计算简单有效</li>
<li>比sigmoid&#x2F;tanh收敛快</li>
</ul>
<h2 id="7-其他常见的激活函数"><a href="#7-其他常见的激活函数" class="headerlink" title="7. 其他常见的激活函数"></a>7. 其他常见的激活函数</h2><p>其他常见的激活函数还有</p>
<ul>
<li>Noisy ReLU</li>
<li>指数线性单元ELU(exponential linear unit)</li>
<li>SELU</li>
<li>GELU</li>
<li>Swish</li>
<li>…</li>
</ul>
<p>还有挺多的激活函数没有列举，但是我目前常见的就只有以上列举的几种，剩下的激活函数等到到时候用到的时候再来补充就好了！</p>
<p><em>参考的网站：</em></p>
<blockquote>
<p><a href="https://www.cnblogs.com/makefile/p/activation-function.html">https://www.cnblogs.com/makefile/p/activation-function.html</a><br><a href="https://www.cnblogs.com/nxf-rabbit75/p/9276412.html">https://www.cnblogs.com/nxf-rabbit75/p/9276412.html</a><br><a href="https://cloud.tencent.com/developer/article/1800954">https://cloud.tencent.com/developer/article/1800954</a><br><a href="https://blog.csdn.net/hy592070616/article/details/120618490">https://blog.csdn.net/hy592070616/article/details/120618490</a><br><a href="https://blog.csdn.net/weixin_42057852/article/details/84644348?spm=1001.2101.3001.6650.11&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-11-84644348-blog-120618490.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-11-84644348-blog-120618490.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=15">https://blog.csdn.net/weixin_42057852/article/details/84644348?spm=1001.2101.3001.6650.11&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-11-84644348-blog-120618490.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-11-84644348-blog-120618490.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=15</a></p>
<p><a href="https://www.cnblogs.com/pinard/p/6437495.html">https://www.cnblogs.com/pinard/p/6437495.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>Mathine Learning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习实验二</title>
    <url>/2022/11/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E9%AA%8C%E4%BA%8C/</url>
    <content><![CDATA[<p>这是机器学习课程上的一个小项目作业，具体是通过多种回归模型预测房价…</p>
<span id="more"></span>

<h1 id="机器学习实验二，使用多种回归模型预测房价"><a href="#机器学习实验二，使用多种回归模型预测房价" class="headerlink" title="机器学习实验二，使用多种回归模型预测房价"></a>机器学习实验二，使用多种回归模型预测房价</h1><blockquote>
<p>这次实验基于上一次对房价数据的预处理，使用多种回归模型对处理的数据进行预测任务。建立的回归模型主要有Lasso回归、弹性网络回归、岭回归、梯度加强回归、随机森林回归、XGBoost回归以及LightGBM回归七种模型。建立完回归模型完成任务，还需要对各个模型的性能进行评估与选择。并且考虑用网格搜索方法对表现最好的模型进行进一步的优化。</p>
</blockquote>
<h1 id="实验说明"><a href="#实验说明" class="headerlink" title="实验说明"></a>实验说明</h1><p>预测房价实验对1460条房价数据、80个房屋的属性进行分析，建立回归模型，然后预测1459条新房屋数据的价格。 </p>
<p>本实验是预测房价实验的第二部分，使用上个实验处理好的数据建立机器学习模型，并且对模型性能进行评估。</p>
<h1 id="实验准备"><a href="#实验准备" class="headerlink" title="实验准备"></a>实验准备</h1><h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><p><em>在桌面上新建一个目录，名字叫house_price。本实验中所有的数据集和代码都放在该目录下</em></p>
<p><strong>Spyder</strong></p>
<h2 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h2><p>本实验需要2个数据集，数据集的名字叫train.csv和test.csv，分别是房价的训练数据和测试数据。将train.csv和test.csv复制到刚刚创建的house_price目录下。</p>
<h1 id="建立回归模型"><a href="#建立回归模型" class="headerlink" title="建立回归模型"></a>建立回归模型</h1><h2 id="Lasso回归"><a href="#Lasso回归" class="headerlink" title="Lasso回归"></a>Lasso回归</h2><pre><code>#Lasso Regression
from sklearn.linear_model import Lasso
lasso = Lasso(alpha = 0.0005, random_state = 1)
</code></pre>
<blockquote>
<p>lasso [læˈsuː] (捕马、套牛等用的)套索; 用套索套捕(动物)</p>
</blockquote>
<h2 id="弹性网络回归"><a href="#弹性网络回归" class="headerlink" title="弹性网络回归"></a>弹性网络回归</h2><pre><code># Elastic Net Regerssion
from sklearn.linear_model import ElasticNet
enet = ElasticNet(alpla = 0.0005, l1_ratio = .9, random_state = 3)
</code></pre>
<blockquote>
<p>elastic [ɪˈlæstɪk]  有弹力的灵活的,可改变的,可伸缩的; 橡皮圈</p>
<p>ratio [ˈreɪʃiəʊ] 比率,比例</p>
</blockquote>
<h2 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h2><pre><code># Kernel Ridge Regression
from sklearn.kernel_ridge import KernelRidger
krr = KernelRidge(alpha = 0.6, kernel = &quot;polynomial&quot;, degree = 2, coef0 = 2.5)
</code></pre>
<blockquote>
<p>ridge [rɪdʒ] 山脊; 使隆起,使形成脊状</p>
<p>polynomial [ˌpɒli’nəʊmiəl] [ˌpɑli’noʊmiəl]  多项式的; 多项式</p>
<p>elapsed [ɪˈlæpst] (时间)消逝, 流逝 <strong>-&gt;</strong> elapse的过去分词和过去式</p>
</blockquote>
<hr>
<p>Lasso回归有时也叫做线性回归的L1正则化，和Ridge回归的主要区别就是在正则化项，Ridge回归用的是L2正则化，而Lasso回归用的是L1正则化。而弹性回归是岭回归和套索回归的混合技术，它同时使用 L2 和 L1 正则化。当有多个相关的特征时，弹性网络是有用的。套索回归很可能随机选择其中一个，而弹性回归很可能都会选择。<em>套索回归和核岭回归说到底就是在损失函数上加了两个不同的正则化项罢了，而弹性网络就是两个正则化项都加上去。但是引入核岭回归却不是直接从linear_model直接引入，而是单独出sklearn.kernel_ridge进行引入，真是奇怪？？？</em></p>
<p>Lasso回归使得一些系数变小，甚至还是一些绝对值较小的系数直接变为0，因此特别适用于参数数目缩减与参数的选择，因而用来估计稀疏参数的线性模型。</p>
<p>个人观点：但是Lasso回归有一个很大的问题，导致我们需要把它单独拎出来讲，就是它的损失函数不是连续可导的。由于L1范数用的是绝对值之和，导致损失函数有不可导的点。也就是说，我们的最小二乘法，梯度下降法，牛顿法与拟牛顿法对它统统失效了。🙄🙄🙄</p>
<h2 id="梯度加强回归"><a href="#梯度加强回归" class="headerlink" title="梯度加强回归"></a>梯度加强回归</h2><pre><code># Gradient Boosting Regression
from sklearn.ensemble import GradientBoostingRegressor
gboost = GradientBoostingRegressor(n_estimators = 3000, learning_rate = 0.05, max_depth = 4,max_features = &quot;sqrt&quot;, min_samples_leaf = 15, min_samples_split = 10,loss=&quot;huber&quot;,random_state = 5)
</code></pre>
<blockquote>
<p>ensemble [ɒnˈsɒmbl] n.乐团,全体,成套的东西; adv.一起</p>
<p>sklearn.ensemble我理解成Gradient Boosting Regression用得比较广泛，导致它放在了sklearn的全体kit里面</p>
</blockquote>
<p>我尝试搜寻梯度加强回归，但是只能搜索到梯度提升回归树，看来它是一种树模型。<em>它是一种决策树的集成方法，通过合并多个决策树来构建一个更为强大的模型。</em>虽然他的名字中有回归两个字，但是这种模型既可以用在回归上，也可以用在分类上。</p>
<p>与随机森林不同的是，梯度提升采用连续的方式构造树，每一棵树都试图纠正前一棵树的错误。默认情况下，梯度提升回归树中没有随机化，而是用到了强预剪枝。</p>
<p>梯度提升决策树是监督学习中最强大也是最常用的模型之一，缺点是需要仔细调参，而且训练的时间要很长。和其他基于树的模型类似，这个算法不需要对数据进行缩放就可以表现的很好，并且它也适用于二元特征与连续特征同时存在的数据集。同样，它的不足之处与其它基于树的模型也类似，它不适合处理高维稀疏数据。</p>
<blockquote>
<p>所谓<a href="https://www.cnblogs.com/JetpropelledSnake/p/14438484.html">特征缩放</a>、<a href="https://blog.csdn.net/qq_51228515/article/details/122431951">数据缩放</a>包含了归一化和标准化等。特征缩放的原因是，为消除各评价指标间量纲和数量级的差异、保证结果的可靠性，就需要对各指标的原始数据进行特征缩放。</p>
</blockquote>
<blockquote>
<p>个人观点：<em>对于稀疏数据，当前的研究方向是对稀疏数据进行聚类与降维。因为稀疏数据不同于一般数据，它的维度常常非常巨大，由于大量存在缺失值，导致数据信息极其不完整。常见的一些降维方法比如说主成分分析和因子分子方法都无法对稀疏数据进行应用</em></p>
</blockquote>
<h2 id="随机森林回归"><a href="#随机森林回归" class="headerlink" title="随机森林回归"></a>随机森林回归</h2><pre><code># random forest
from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(n_estimators = 500, random_state = 0)
</code></pre>
<p>随机森林属于<a href="https://blog.csdn.net/siyuangulu/article/details/122508931?spm=1001.2101.3001.6650.8&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-8-122508931-blog-82016442.pc_relevant_recovery_v2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-8-122508931-blog-82016442.pc_relevant_recovery_v2&utm_relevant_index=11">集成学习</a>中的Bagging算法，即引导聚合类算法，详情可以点击上面链接进行访问。🪐</p>
<p>首先要明确的是，当前集成学习分成两大类，一类是Bagging装袋法，第二类是Boosting提升法。</p>
<ul>
<li>Bagging（装袋法）: 如随机森林，每一个模型相互独立，互相平行</li>
<li>Boosting（提升法）: 模型循序渐进，依次增强，基评估器相互关联</li>
</ul>
<p>我们都知道随机森林就是通过集成学习的思想将多棵树集成的一种算法，它的基本单元是决策树。直观的说，每一棵决策树都是一个分类器（假设现在讨论的是分类问题），那么对于一个输入样本，N棵树有N个分类结果。而随机森林做的就是集成了所有的分类投票结果，将投票次数最多的类别指定为最终的输出，这就是一种最简单的Bagging思想。</p>
<p>在该模型中，有三个重要的参数分别为: &amp;nbsp <a href="https://blog.csdn.net/weixin_43479947/article/details/126813033">参考</a></p>
<ul>
<li>n_estimators(子树数量)</li>
<li>learning_rate(学习率)</li>
<li>max_depth(最大深度)</li>
</ul>
<p>想要进一步了解随机森林，可以通过以下链接进行学习：</p>
<blockquote>
<p><a href="https://blog.csdn.net/siyuangulu/article/details/122508931?spm=1001.2101.3001.6650.8&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-8-122508931-blog-82016442.pc_relevant_recovery_v2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-8-122508931-blog-82016442.pc_relevant_recovery_v2&utm_relevant_index=11">CSDN</a></p>
<p><a href="https://easyai.tech/ai-definition/random-forest/">EasyAi</a></p>
<p><a href="https://www.cnblogs.com/maybe2030/p/4585705.html">博客园</a></p>
<p><a href="https://www.cnblogs.com/fionacai/p/5894142.html">博客园</a></p>
</blockquote>
<h2 id="XGBoost回归"><a href="#XGBoost回归" class="headerlink" title="XGBoost回归"></a>XGBoost回归</h2><pre><code># XGBoost
# if xgboost packet doesnt exist, please install with command:conda install py-xgboost
import xgboost as xbg
xgb = xgb.XGBRegressor(colsample_bytree = 0.4603, gamma = 0.0468,learning_rate = 0.05, max_depth = 3, min_child_weight = 1.7817, n_estimators = 2200, reg_alpha = 0.4640, reg_lambda = 0.8571,subsample = 0.5213, silent = 1, random_state = 7, nthread = -1)
</code></pre>
<p>首先要知道的是，XGBoost算法是梯度提升树GBDT的高效实现。这里所提到的GBDT可能和上面所提到的梯度提升回归树有着异曲同工之处。作为梯度提升回归树的高效实现，XGBoost是一个上限非常高的算法。在竞赛题中，不考虑深度学习，XGBoost算法算是比赛中最热门的算法，它将GBDT的优化走向了一个极致。但是它的训练耗时长，内存占用比较大。</p>
<p>后续，微软推出了LightGBM，在内存占用和运行速度上做了不少的优化，但是<a href="https://www.cnblogs.com/pinard/p/10979808.html">刘建平pinard大哥</a>认为当前还是优先选择XGBoost，因为调优经验比较多一点，可以参考的资料也更多一些。如果使用XGBoost遇到的内存占用或者运行速度问题，这个时候再尝试LightGBM也不错。</p>
<h2 id="LightGBM回归"><a href="#LightGBM回归" class="headerlink" title="LightGBM回归"></a>LightGBM回归</h2><pre><code># LightGBM
import lightgbm as lgb
lgb = lgb.LGBMRegressor(objective = &quot;regression&quot;, num_leaves = 5, learning_rate = 0.05, n_estimators = 720, max_bin = 55, bagging_fraction = 0.8, bagging_freq = 5, feature_fraction = 0.2319, feature_fraction_seed = 9, bagging_seed = 9, min_data_in_leaf = 6,min_sum_hessian_in_leaf = 11)
</code></pre>
<blockquote>
<p>fraction [ˈfrækʃn] n.小部分,分数,小数</p>
</blockquote>
<p>LightGBM是快速的，分布式的，高性能的基于决策树算法的梯度提升框架。可以用于排序、分类、回归以及其他机器学习任务中。它是XGBoost的改进版，XGboost又是GBDT梯度提升回归树的高效实现，所以我理解成LightGBM与GBDT师出同门。</p>
<p>2017年的时候微软在GitHub上开源了一个新的算法<strong>LightGBM</strong>，根据某CSDN机翻文章称，它能够在不降低准确率的前提下，能够提升十倍左右的速度，并且占用内存下降三倍左右。虽然它和XGboost都是基于决策树算法的，但是LightGBM采用的分裂叶子结点策略貌似与XGBoost算法不同，并且极大地优于XGBoost，导致它的速度非常之快…</p>
<p><strong>到目前为止，七个回归模型的初始化都已经完成！</strong></p>
<h1 id="模型性能评估与选择"><a href="#模型性能评估与选择" class="headerlink" title="模型性能评估与选择"></a>模型性能评估与选择</h1><p>业界一般使用k-fold 交叉验证（k-fold cross validation）的方法评估模型性能。在这里k&#x3D;10。评估指标有2个，一个是 r^2（ r squared）, 另一个是mse（mean squared error）。为了加快执行速度，n_jobs &#x3D; 2表示使用2个CPU（我的电脑是2核CPU）。训练数据集有1458条数据，272列，模型执行起来可能相对较慢，请耐心等待。verbose &#x3D; 1表示执行过程中不断打印出信息，以帮助判断执行了多少了。</p>
<p><strong>提示</strong>：同学们可能疑惑为什么没有在验证集上检验模型性能，这可能会产生过拟合现象。k-fold 交叉验证的存在可以在不需要验证集的情况下，也能发现过拟合现象😅。</p>
<pre><code># k-fold cross validation function
from sklearn.model_selection import cross_val_score
def evaluation_model(model):
    rmse = np.sqrt(-cross_val_score(estimator = model, X = X_train, y = y_train, scoring = &#39;neg_mean_squared_error&#39;, cv = 10, n_jobs = 2, verbose = 1))
    r2_score = cross_val_score(estimator = model, X = X_train, y = y_train, scoring = &#39;r2&#39;, cv = 10, n_jobs = 2, verbose = 1)
    return (r2_score, rmse)
# print result function
def print_result(r2_score, rmse, model_name):
    print(&#39;%s evaluation: r2=%.4f (std=%.4f), rmse=%.4f (std=%.4f)&#39; %(model_name, r2_score.mean(), r2_score.std(), 
  rmse.mean(), rmse.std()))
</code></pre>
<p>定义好了函数，现在可以对每一模型执行。</p>
<pre><code># model score and rmse
lasso_r2_score, lasso_rmse = evaluation_model(lasso)
enet_r2_score, enet_rmse = evaluation_model(enet)
krr_r2_score, krr_rmse = evaluation_model(krr)
gboost_r2_score, gboost_rmse = evaluation_model(gboost)
rf_r2_score, rf_rmse = evaluation_model(rf)
xgb_r2_score, xgb_rmse = evaluation_model(xgb)
lgb_r2_score, lgb_rmse = evaluation_model(lgb)
# print result
print_result(lasso_r2_score, lasso_rmse, &#39;Lasso&#39;)
print_result(enet_r2_score, enet_rmse, &#39;Elastic Net&#39;)
print_result(krr_r2_score, krr_rmse, &#39;Kernel Ridge&#39;)
print_result(gboost_r2_score, gboost_rmse, &#39;Gradient Boost&#39;)
print_result(rf_r2_score, rf_rmse, &#39;Random Forest&#39;)
print_result(xgb_r2_score, xgb_rmse, &#39;XG Boost&#39;)
print_result(lgb_r2_score, lgb_rmse, &#39;Lightgbm&#39;)
</code></pre>
<p>模型性能的评估尤其是用sklearn进行模型评估貌似篇幅有点小长，我改天再写吧！现在可以看看别人对模型评估方法进行的一些<a href="https://www.cnblogs.com/jiaxin359/p/8627530.html">总结</a>，以及<a href="https://blog.csdn.net/weixin_35757704/article/details/118406255">运用</a>。</p>
<h1 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h1><p>结果发现XGBoost的性能最好:r2&#x3D;0.9227 (std&#x3D;0.0149), rmse&#x3D;0.2734 (std&#x3D;0.0340)，因为RMSE平均数最小，方差最小，并且R2&gt;0.9，模型性能比较好。值得注意的是，如果你们选择的是模型默认的超参数，那么执行的结果和我的就不一样啦，因为不同的超参数决定了模型的准确率的不同。这里给出了一个通用的原则：</p>
<blockquote>
<p><strong>选择r2&gt;0.9，且mse和std最小的那个模型</strong></p>
</blockquote>
<h1 id="使用GridSearchCV方法对XGBoost模型进行优化"><a href="#使用GridSearchCV方法对XGBoost模型进行优化" class="headerlink" title="使用GridSearchCV方法对XGBoost模型进行优化"></a>使用GridSearchCV方法对XGBoost模型进行优化</h1><p>在机器学习模型中，需要人工选择的参数称为超参数。比如随机森林中决策树的个数，人工神经网络模型中隐藏层层数和每层的节点个数，正则项中常数大小等等，他们都需要事先指定。超参数选择不恰当，就会出现欠拟合或者过拟合的问题。而在选择超参数的时候，有两个途径，一个是凭经验微调，另一个就是选择不同大小的参数，带入模型中，挑选表现最好的参数。</p>
<p>微调的一种方法是手工调制超参数，直到找到一个好的超参数组合，这么做的话会非常冗长，你也可能没有时间探索多种组合，所以可以使用Scikit-Learn的GridSearchCV来做这项搜索工作。</p>
<p>这里可以将Grid Search暂时理解为是一种调参手段，并且是非常耗时的穷举搜索。<em>至于进一步深究，我们暂时放到下一步。因为今天的篇幅有点长，担心如果我再展开讲下去的话会增加各位读者包括我的阅读负担。所以我打算把网格搜索放到了下一篇（也可能是下下篇）</em>你可以先看看<a href="https://blog.csdn.net/guoyc439/article/details/123381908">这里</a>🍉🍉🍉</p>
<h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><blockquote>
<p><a href="https://blog.csdn.net/huacha__/article/details/81057150">https://blog.csdn.net/huacha__/article/details/81057150</a></p>
<p><a href="https://blog.csdn.net/fenghuibian/article/details/91353348">https://blog.csdn.net/fenghuibian/article/details/91353348</a></p>
<p><a href="https://www.jianshu.com/p/17368988d6d9">监督学习(八)——决策树集成：梯度提升回归树</a></p>
<p><a href="https://blog.csdn.net/weixin_43479947/article/details/126813033">也是梯度提升回归树</a></p>
</blockquote>
]]></content>
      <categories>
        <category>Mathine Learning</category>
        <category>Homework</category>
      </categories>
  </entry>
  <entry>
    <title>数学建模大赛</title>
    <url>/2022/11/23/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%A4%A7%E8%B5%9B/</url>
    <content><![CDATA[<p>直到今天为止，数模比赛已经结束咯！任务完成，参赛题目也提交了，结果如何就看人品了🤗</p>
<span id="more"></span>

<h1 id="1-数模比赛"><a href="#1-数模比赛" class="headerlink" title="1.数模比赛"></a>1.数模比赛</h1><p>直到今天为止，数模比赛已经结束咯！任务完成，参赛题目也提交了，结果如何就看人品了🤗<br>这是是第一次使用Markdown写短文，虽然说Markdown很容易上手，但是一些细节上的东西总是无法反应过来😵😵😵</p>
<blockquote>
<p>下面是我学习Markdown的一些经历，希望在写作的时候对你有些帮助！😉</p>
<p>点击跳转Markdown  –&gt;目前这项功能还在开发中，ちょっと待っね！</p>
</blockquote>
<h1 id="2-比赛前"><a href="#2-比赛前" class="headerlink" title="2.比赛前"></a>2.比赛前</h1><h2 id="2-1第一次校赛"><a href="#2-1第一次校赛" class="headerlink" title="2.1第一次校赛"></a>2.1第一次校赛</h2><p>虽然说今年四月份就开始准备数模比赛了，到今天有五个多月的时间，但是我们队真正学习的时间却不多，至少对我来说。可能我真正静下心来学习数模知识的时间还不足两个星期吧！😅</p>
<p>刚开始我的工作是负责建模的工作，在队长的敦促下，买了份价值一百五的学习视频及教程。我对于视频学习并没有多大的想法，我还是更喜欢看书学。这就是为什么iPad里的电子书都发霉发臭了，都不曾被我看过的原因吧？再一点，比起付费的资料，我更喜欢白嫖（虽然这并不好），因为在我认为在网上寻找资料是一件很享受的事情，おかしいでしょ？</p>
<p>一个队伍的核心成员应该是建模手，作为整支队伍的leader，我带领着队伍齐头并进，最后连校三等都没有…</p>
<p>😀😀😀但是这也是在意料之内的，因为没有什么知识储备，脑子里当时就只有层次分析法这几个简单的模型，再加上论文的阅读次数都不足双位数，能获奖就有鬼！而且为期三天的数模，我们整整搞了十天才提交上去，虽然但是有多少水分谁不不揭穿了啊！</p>
<h2 id="2-2暑假"><a href="#2-2暑假" class="headerlink" title="2.2暑假"></a>2.2暑假</h2><p>搞完校赛，处理完期末考试，差不多就进入了暑假。由于和写作手的配合没有那么好，所以我们打算换一名成员。队长推荐了一名算法高手，很显然，我该换岗位了。</p>
<p>在漫长的暑假，我只希望自己能够每天抽出时间读一篇，哪怕是一篇数模优秀文章也好！但是事与愿违，事…还是没做成。后面学校组织训练，我们参加并且完成了一篇19年的C题。嗯，很显然我们又是十天左右才完成。当时就想着，这么搞肯定得玩完。于是思前想后，打算用LaTeX替换现在的WPS，说不定写作工具变了，我们的工作就更有效率了呢？😲</p>
<p>好主意！下一次训练连半成品都没有交上去…</p>
<p>当时学习LaTeX花了不到半天时间，便清楚它的工作流程，于是迫不及待的去找了一些有数模LaTeX的tex文件。看到了一个钟意的，便敲定了，也就是现在我使用的这也数模模板。</p>
<p>由于我没有将模板与正文分离，所以我两次写论文的时候，都是夹着别人的论文一起写的，这次数模也不例外…</p>
<blockquote>
<p>我将LaTeX文件放到了这里，模板和正文自己分离。懒😪😪😪</p>
<p>这项工作也还在完善中，请稍后！</p>
</blockquote>
<p>然后就开学咯🎉</p>
<h2 id="2-3开学到比赛前这段时间"><a href="#2-3开学到比赛前这段时间" class="headerlink" title="2.3开学到比赛前这段时间"></a>2.3开学到比赛前这段时间</h2><p>很显然，我什么都没有干。</p>
<h1 id="3-比赛"><a href="#3-比赛" class="headerlink" title="3.比赛"></a>3.比赛</h1><p>据说参加国赛需要校赛经历，我们已经算是合格的国赛选手了吧？我们比赛的时间是9月15号（周四）晚上六点钟到9月18号（周日）晚上十点钟之前。又多了四个小时时间，Lucky！希望能够用这多出来的四个小时改变点什么…</p>
<h2 id="3-1周四晚上"><a href="#3-1周四晚上" class="headerlink" title="3.1周四晚上"></a>3.1周四晚上</h2><p>出赛题的时候我们在饭堂，不是因为我们不准备坐着等题，而是我忘记打包进实验室了。当天晚上我们商量好，要确定选题，不要犹豫。今年的A题对于我们来说，简直是魔鬼程度的。两三页篇幅的说明，让我们望而祛步🙄。如果硬啃的话，肯定可以理解它想要表达什么，但是求解确实一大难事。后面看别人大佬绞尽脑汁的想，才发现这个决定无疑对我们来说是十分正确的。</p>
<p>选题按理来说应该要由建模手和编程手决定，因为他们更清楚问题的复杂性。他们现在卡在了B题和C题之前，队长更想选C题，但是算法糕手希望能够挑战一下。他内心看起来很动摇，因为他看不出解题思路。其实我和新队员也是第一次见面，之前都是在WeChat上聊天。谢天谢地，我们俩很快就磨合了，变得更多少年的好友一般畅所欲言？！</p>
<p>我在几何方面很敏感，但是对数学公式很感冒。当时想过选数学专业，但是哪有人只学几何不用数学公式啊？恰好B题就是与几何有关的，我用高中的知识看出了第一小问的求解思路，然后我就坚持选B题。最后没有依我，选择了C题。我当时虽然很不爽，但是我确实只想得出第一问，对于全局来说，我还是服气的。虽然题目更简单了，但是意味着更多人选。只有语文建模基础足够深厚，才有机会获得一个最小的省三。<strong>最后统计有三百八十多人选择了C题，这个人数差不多就是去年我们学校的参赛人数…</strong></p>
<h2 id="3-2周五"><a href="#3-2周五" class="headerlink" title="3.2周五"></a>3.2周五</h2><p>周五我们搜寻资料，解决了第一小问，然后卡在了第二小问的预测上，想了差不多一天的时间都没有想出来。确实浪费了很多时间，也做了很多无用功。第一小问的论文我很快就与论文交接了，但是剩余的时间与其是在划水，倒不如说是在无用功。C题与化学有关，于是我想着会用到化学方程式，去找了很多。但是最后发现要么就是用不上，要么就是没时间用。</p>
<h2 id="3-3周六"><a href="#3-3周六" class="headerlink" title="3.3周六"></a>3.3周六</h2><p>C题有大概六七个小问，想要查看原题的话点击这里。</p>
<p>我们一天时间才解决了第一小问，如果再这么下去，论文很有可能写不完。虽然我们也很努力，我也是第一次尝试了这种朝八晚十二的作息规律。嗯？怎么和我平时的作息有点像？关键是放弃了宝贵的午休时间。没有午休我的精神状态就会下降，特别是写论文的时候，无法理解模型的概念与问题的解决思路，又没有文思泉涌，将会导致写出来的论文质量差。一天除了睡觉的时间都呆在实验室，看起来很努力，在我看来是在做无用功（包括我）。队长和建模手对于模型的选择有一定的困难，导致了问题的拖延。明白了这一点，今天开始我尝试着来安排工作。</p>
<p>对于模型，需要用指标来衡量。我肯定表现好的模型，否定表现差的模型。这种斩钉截铁的工作模式很快让我和各位都进入了流水线上，开始各司其职。当然，前提是做出了跳过第二小问的决定。</p>
<p>直到晚上，第二问第一小问、第三问和第四问的问题都得到了解决。但是跟他们一起讨论，导致我到目前为止并没有进行论文撰写，也就是说只完成了论文进度还是停留在周五。</p>
<h2 id="3-4周日"><a href="#3-4周日" class="headerlink" title="3.4周日"></a>3.4周日</h2><p>即便如此，我早上还是睡到了差不多九点，因为我认为工作效率才是最重要的，假努力欺骗的是自己还有身边的人。但时间真的很赶！早上我留在宿舍通过大屏操作LaTeX很快就完成了第二问的论文撰写，并且我交代队友明天早上完成第三问的论文撰写以及求解出第二小问的预测结果。队友很给力，差不多两点我去实验室的时候他们已经完成了这两个任务。但我看完论文结构后猛地一惊，发现摘要和问题分析没有写！包括第四问在内，还有一些零零星星的结果没有贴到论文中，六个小时能够完成吗？真是一项挑战啊！我不禁擦了擦额头上的假汗😰😰😰</p>
<p>我安排他们完成了问题二和问题三的问题分析，因为他们求解的他们来写这种解题思路的话简直如鱼得水。而第四问的方法是我想出来的，所以我先完成第四问先。但是做了一半，发现SPSSPro上的热力图根本无法反映出我想要的结果。于是在三点钟的时候我临时改用了其它方法，用画图代替了建立模型的繁琐。</p>
<p>大概五点钟我们就完成了基本上的任务，但是对于XeLatex编译出来的文件，还是有很多bug。并且每一个bug都是包含致命错误的，一旦出现即无缘获奖（<em>虽然说这次的也不知道能不能够获奖😵‍💫</em>）其中解决的很多问题都是以前遇到过但是解决不出的🤔</p>
<ul>
<li>从使用之初一直困扰我的表格边框以及复杂表格的LaTeX代码</li>
<li>LaTeX含特殊字符的那段文字会超出编译生成的PDF之外</li>
<li>LaTeX中图片并列</li>
<li>LaTeX正文会被图片和表格夹断，阅读出现障碍</li>
<li>LaTeX模板上页眉的内容不知道在哪个文件清空</li>
<li>LaTeX附录粘贴代码有点麻烦</li>
</ul>
<p><code>解决方案放到了LaTeX篇，如果有需要请点击此处跳转...</code></p>
<p>多亏LaTeX有在源代码和PDF相互跳转到指定位置的功能，不然真的用不下去了😭😭😭</p>
<p>我们一起改论文，改到了7点57还有很多问题，但是8点钟之前可以提交多次PDF论文和RAR压缩包，也就是说MD5码在8点钟之前是允许反复更改的。但是在8点到10点之内，就只能提交一次文件和生成指定不可变的MD5码。并且MD5码在8点后生成的，就不允许更改文件了，一旦你更改文件，或许只是打开一下PDF都有可能让MD5码发生改变，机器会判定在10点钟之后正式提交参赛作品的时候你的文件发生了改动，这个时候它是不承认你的MD5码，也就是说你无法参赛了。这是一个很严重的问题，自己辛辛苦苦做了这么久，结果却交不上去，心态多少有点崩溃。所以我们为了保险起见，先在8点钟之前提交一次。</p>
<p>然后我们预测在9点钟之前正式将作品做最后一次的提交（10点钟之前的提交可以认为只是参赛资格的获取），但是发现bug根本改不过来。三个人忙得团团转，当时想着9点半之前提交就好了，网络不会这么拥挤的。但是忙到了9点半，bug依然有，而且严重程度会让论文直接降档。没办法，抱着试一逝的心态，我们改bug改到了9点45。虽然说还有不少bug，但都是不痛不痒的，对阅读论文没有什么大影响的小问题了。</p>
<p>我编译出最新的PDF，通过WeChat准备发给队长时，由于轻薄本已经承担了太多软件，并且三四天都没有合过眼了。LaTeX直接卡退，屏幕被黑块笼罩着，就像我们此刻的心情一样。大概到9点50的时候，电脑缓过来了，我赶紧将PDF发给队长。压缩完我的LaTeX代码文件后突然发现我电脑里的压缩软件是360压缩，只能生成zip类型的压缩包。而我之前一直想着队长有WinRAR就够了，反正是他通过客户端提交的。下载WinRAR显然不切实际，由于多天的劳累，我们的CPU已经转不过来了。我赶紧将文件压缩成zip格式，然后发给建模手，因为此时队长在忙活着PDF名称的修改。但未承想建模手把我的文件解压放进总附件文件中，压缩后找不到找不到压缩包，遂叫我来操作。我看到他的安装路径，狂点桌面，然后点击确定。终于，我们的压缩包出现在了桌面。但他的桌面都是蓝蓝的doc和绿绿xls，一时间竟无法找出压缩包！此时时间已经来到了9点55分。一顿丝滑的操作后视野来到了队长这边，只见他颤颤巍巍地移动着鼠标，指尖高频触动着鼠标左键，但就是无法达到那最后的终点！“好了吗？”“好！冲！”伴随着呐喊声，我们点击了提交。幸运的是，软件并没有卡顿，显得如此顺理成章，此时时间是9点57分。一切都结束后，没有欢呼、没有喝彩，只留下一片鸦雀无声。紧绷着的心情还没有完全放松下来，眼前还停留着黑白的文字与代码，一切都还显得这么历历在目！</p>
<h1 id="4-Final"><a href="#4-Final" class="headerlink" title="4.Final"></a>4.Final</h1><p>虽然过程很苦很累，甚至对一百蚊有点舍不得。但就最后两个小时的感受而言，让我觉得这钱交的值了！自打上大学以来，还是第一次切实地体会到了团队合作的重要性。以前一直都是单打独斗，现在发现自己并不是万能的，队友就是用来弥补自己的缺点的。虽然说有百分之五十的概率获奖，但是无论结果如何我都能平淡接受，因为这场比赛我已经获得了自己想要的东西！<em>（其实心里还是想着希望得个省三就好了，因为有一千块钱回血…）</em>🐤🐤🐤</p>
]]></content>
      <categories>
        <category>School Life</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>学校</tag>
        <tag>比赛</tag>
      </tags>
  </entry>
  <entry>
    <title>特征缩放</title>
    <url>/2022/11/23/%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE/</url>
    <content><![CDATA[<p>将数据进行归一化和标准化可以使不同维度的特征放在一起进行比较，可以大大提高模型的准确性。</p>
<span id="more"></span>

<h1 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h1><h2 id="1-为什么要进行特征缩放"><a href="#1-为什么要进行特征缩放" class="headerlink" title="1. 为什么要进行特征缩放"></a>1. 为什么要进行特征缩放</h2><h3 id="1-1-统一特征的权重和提升模型准确性"><a href="#1-1-统一特征的权重和提升模型准确性" class="headerlink" title="1.1 统一特征的权重和提升模型准确性"></a>1.1 统一特征的权重和提升模型准确性</h3><p>如果某个特征的取值范围比其他特征大很多，那么数值计算（比如说计算欧式距离）就受该特征的主要影响。但实际上并不一定是这个特征最重要，通常需要把每个特征看成同等重要。归一化和标准化数据可以使不同维度的特征放在一起进行比较，可以大大提高模型的准确性。</p>
<h3 id="1-2-提升梯度下降法的收敛速度"><a href="#1-2-提升梯度下降法的收敛速度" class="headerlink" title="1.2 提升梯度下降法的收敛速度"></a>1.2 提升梯度下降法的收敛速度</h3><p><img src="https://img-blog.csdnimg.cn/20191113192133110.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzAwODgwNA==,size_16,color_FFFFFF,t_70" alt="左边是未归一化数据的梯度下降过程"></p>
<h2 id="2-特征缩放的方法有哪些？"><a href="#2-特征缩放的方法有哪些？" class="headerlink" title="2. 特征缩放的方法有哪些？"></a>2. 特征缩放的方法有哪些？</h2><h3 id="2-1-最大最小值归一化（min-max-normalization）：将数值范围缩放到-0-1-区间里"><a href="#2-1-最大最小值归一化（min-max-normalization）：将数值范围缩放到-0-1-区间里" class="headerlink" title="2.1 最大最小值归一化（min-max normalization）：将数值范围缩放到 [0, 1] 区间里"></a>2.1 最大最小值归一化（min-max normalization）：将数值范围缩放到 [0, 1] 区间里</h3><p><img src="https://img2018.cnblogs.com/blog/1247570/201901/1247570-20190103162752557-711062993.png"></p>
<h3 id="2-2-均值归一化（mean-normalization）：将数值范围缩放到-1-1-区间里，且数据的均值变为0"><a href="#2-2-均值归一化（mean-normalization）：将数值范围缩放到-1-1-区间里，且数据的均值变为0" class="headerlink" title="2.2 均值归一化（mean normalization）：将数值范围缩放到 [-1, 1] 区间里，且数据的均值变为0"></a>2.2 均值归一化（mean normalization）：将数值范围缩放到 [-1, 1] 区间里，且数据的均值变为0</h3><p><img src="https://img2018.cnblogs.com/blog/1247570/201901/1247570-20190103162807303-1305019357.png"></p>
<h3 id="2-3-标准化-Z-值归一化（standardization-x2F-z-score-normalization）：将数值缩放到0附近，且数据的分布变为均值为0，标准差为1的标准正态分布（先减去均值来对特征进行-中心化-mean-centering-处理，再除以标准差进行缩放）"><a href="#2-3-标准化-Z-值归一化（standardization-x2F-z-score-normalization）：将数值缩放到0附近，且数据的分布变为均值为0，标准差为1的标准正态分布（先减去均值来对特征进行-中心化-mean-centering-处理，再除以标准差进行缩放）" class="headerlink" title="2.3 标准化 ,Z 值归一化（standardization &#x2F; z-score normalization）：将数值缩放到0附近，且数据的分布变为均值为0，标准差为1的标准正态分布（先减去均值来对特征进行 中心化 mean centering 处理，再除以标准差进行缩放）"></a>2.3 标准化 ,Z 值归一化（standardization &#x2F; z-score normalization）：将数值缩放到0附近，且数据的分布变为均值为0，标准差为1的标准正态分布（先减去均值来对特征进行 中心化 mean centering 处理，再除以标准差进行缩放）</h3><p><img src="https://img2018.cnblogs.com/blog/1247570/201901/1247570-20190103162903434-1406801774.png"></p>
<h3 id="2-4-最大绝对值归一化（max-abs-normalization-）：也就是将数值变为单位长度（scaling-to-unit-length），将数值范围缩放到-1-1-区间里"><a href="#2-4-最大绝对值归一化（max-abs-normalization-）：也就是将数值变为单位长度（scaling-to-unit-length），将数值范围缩放到-1-1-区间里" class="headerlink" title="2.4 最大绝对值归一化（max abs normalization ）：也就是将数值变为单位长度（scaling to unit length），将数值范围缩放到 [-1, 1] 区间里"></a>2.4 最大绝对值归一化（max abs normalization ）：也就是将数值变为单位长度（scaling to unit length），将数值范围缩放到 [-1, 1] 区间里</h3><p><img src="https://img2018.cnblogs.com/blog/1247570/201901/1247570-20190112114759202-190163995.png"> </p>
<h3 id="2-5-稳键标准化（robust-standardization）：先减去中位数，再除以四分位间距（interquartile-range），因为不涉及极值，因此在数据里有异常值的情况下表现比较稳健"><a href="#2-5-稳键标准化（robust-standardization）：先减去中位数，再除以四分位间距（interquartile-range），因为不涉及极值，因此在数据里有异常值的情况下表现比较稳健" class="headerlink" title="2.5 稳键标准化（robust standardization）：先减去中位数，再除以四分位间距（interquartile range），因为不涉及极值，因此在数据里有异常值的情况下表现比较稳健"></a>2.5 稳键标准化（robust standardization）：先减去中位数，再除以四分位间距（interquartile range），因为不涉及极值，因此在数据里有异常值的情况下表现比较稳健</h3><p><img src="https://img2018.cnblogs.com/blog/1247570/201908/1247570-20190811172514046-446486849.png"></p>
<blockquote>
<p><em>有一些时候，只对数据进行中心化和缩放是不够的，还需对数据进行白化（whitening）处理来消除特征间的线性相关性</em></p>
</blockquote>
<h2 id="3-标准化和归一化的区别是什么？"><a href="#3-标准化和归一化的区别是什么？" class="headerlink" title="3. 标准化和归一化的区别是什么？"></a>3. 标准化和归一化的区别是什么？</h2><h3 id="3-1-归一化-NormalizationNormalization-：将一列数据变化到某个固定区间-范围-中，通常，这个区间是-0-1-，广义的讲，可以是各种区间，比如映射到-0，1-一样可以继续映射到其他范围，图像中可能会映射到-0-255-，其他情况可能映射到-1-1"><a href="#3-1-归一化-NormalizationNormalization-：将一列数据变化到某个固定区间-范围-中，通常，这个区间是-0-1-，广义的讲，可以是各种区间，比如映射到-0，1-一样可以继续映射到其他范围，图像中可能会映射到-0-255-，其他情况可能映射到-1-1" class="headerlink" title="3.1 归一化(NormalizationNormalization)：将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0, 1]，广义的讲，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]"></a>3.1 归一化(NormalizationNormalization)：将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0, 1]，广义的讲，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]</h3><h3 id="3-2-标准化-StandardizationStandardization-：将数据变换为均值为0，标准差为1的分布切记，并非一定是正态的"><a href="#3-2-标准化-StandardizationStandardization-：将数据变换为均值为0，标准差为1的分布切记，并非一定是正态的" class="headerlink" title="3.2 标准化(StandardizationStandardization)：将数据变换为均值为0，标准差为1的分布切记，并非一定是正态的"></a>3.2 标准化(StandardizationStandardization)：将数据变换为均值为0，标准差为1的分布切记，并非一定是正态的</h3><p><img src="https://img-blog.csdnimg.cn/20191021220509274.png#pic_center"></p>
<h3 id="3-3-中心化：另外，还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值"><a href="#3-3-中心化：另外，还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值" class="headerlink" title="3.3 中心化：另外，还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值"></a>3.3 中心化：另外，还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值</h3><p><img src="https://img-blog.csdnimg.cn/20191021220535129.png#pic_center"></p>
<h2 id="4-什么时候用标准化，什么时候用归一化？"><a href="#4-什么时候用标准化，什么时候用归一化？" class="headerlink" title="4. 什么时候用标准化，什么时候用归一化？"></a>4. 什么时候用标准化，什么时候用归一化？</h2><p>某博主理解：如果你对处理后的数据范围有严格要求，那肯定是归一化，个人经验，标准化是机器学习中更通用的手段，如果你无从下手，可以直接使用标准化。如果数据不为稳定，存在极端的最大最小值，不要用归一化。</p>
<p>在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，标准化表现更好；在不涉及距离度量、协方差计算的时候，可以使用归一化方法。</p>
<p><strong>在需要使用距离来度量相似性的算法中，或者使用PCA技术进行降维的时候，通常使用标准化（standardization）或均值归一化（mean normalization）比较好，但如果数据分布不是正态分布或者标准差非常小，以及需要把数据固定在 [0, 1] 范围内，那么使用最大最小值归一化（min-max normalization）比较好（min-max 常用于归一化图像的灰度值）。但是min-max比较容易受异常值的影响，如果数据集包含较多的异常值，可以考虑使用稳键归一化（robust normalization）。对于已经中心化的数据或稀疏数据的缩放，比较推荐使用最大绝对值归一化（max abs normalization ），因为它会保住数据中的０元素，不会破坏数据的稀疏性（sparsity）。</strong></p>
<h2 id="5-什么机器学习模型需要用到特征缩放？"><a href="#5-什么机器学习模型需要用到特征缩放？" class="headerlink" title="5. 什么机器学习模型需要用到特征缩放？"></a>5. 什么机器学习模型需要用到特征缩放？</h2><h3 id="5-1-通过梯度下降法求解的模型需要进行特征缩放，这包括线性回归（Linear-Regression）、逻辑回归（Logistic-Regression）、感知机（Perceptron）、支持向量机（SVM）、神经网络（Neural-Network）等模型。此外，近邻法（KNN），K均值聚类（K-Means）等需要根据数据间的距离来划分数据的算法也需要进行特征缩放。主成分分析（PCA），线性判别分析（LDA）等需要计算特征的方差的算法也会受到特征缩放的影响。"><a href="#5-1-通过梯度下降法求解的模型需要进行特征缩放，这包括线性回归（Linear-Regression）、逻辑回归（Logistic-Regression）、感知机（Perceptron）、支持向量机（SVM）、神经网络（Neural-Network）等模型。此外，近邻法（KNN），K均值聚类（K-Means）等需要根据数据间的距离来划分数据的算法也需要进行特征缩放。主成分分析（PCA），线性判别分析（LDA）等需要计算特征的方差的算法也会受到特征缩放的影响。" class="headerlink" title="5.1 通过梯度下降法求解的模型需要进行特征缩放，这包括线性回归（Linear Regression）、逻辑回归（Logistic Regression）、感知机（Perceptron）、支持向量机（SVM）、神经网络（Neural Network）等模型。此外，近邻法（KNN），K均值聚类（K-Means）等需要根据数据间的距离来划分数据的算法也需要进行特征缩放。主成分分析（PCA），线性判别分析（LDA）等需要计算特征的方差的算法也会受到特征缩放的影响。"></a>5.1 通过梯度下降法求解的模型需要进行特征缩放，这包括线性回归（Linear Regression）、逻辑回归（Logistic Regression）、感知机（Perceptron）、支持向量机（SVM）、神经网络（Neural Network）等模型。此外，近邻法（KNN），K均值聚类（K-Means）等需要根据数据间的距离来划分数据的算法也需要进行特征缩放。主成分分析（PCA），线性判别分析（LDA）等需要计算特征的方差的算法也会受到特征缩放的影响。</h3><h3 id="5-2-决策树（Decision-Tree），随机森林（Random-Forest）等基于树的分类模型不需要进行特征缩放，因为特征缩放不会改变样本在特征上的信息增益。"><a href="#5-2-决策树（Decision-Tree），随机森林（Random-Forest）等基于树的分类模型不需要进行特征缩放，因为特征缩放不会改变样本在特征上的信息增益。" class="headerlink" title="5.2 决策树（Decision Tree），随机森林（Random Forest）等基于树的分类模型不需要进行特征缩放，因为特征缩放不会改变样本在特征上的信息增益。"></a>5.2 决策树（Decision Tree），随机森林（Random Forest）等基于树的分类模型不需要进行特征缩放，因为特征缩放不会改变样本在特征上的信息增益。</h3><h2 id="6-在进行特征缩放的时候需要注意的地方？"><a href="#6-在进行特征缩放的时候需要注意的地方？" class="headerlink" title="6. 在进行特征缩放的时候需要注意的地方？"></a>6. 在进行特征缩放的时候需要注意的地方？</h2><p><em>需要先把数据先拆分成训练集与验证集，在训练集上计算出需要的数值（如均值和标准值），对训练集数据做标准化&#x2F;归一化处理，然后再用之前计算出的数据（如均值和标准值）对验证集数据做相同的标准化&#x2F;归一化处理。不要在整个数据集上直接做标准化&#x2F;归一化处理，因为这样会将验证集的信息带入到训练集中，这是一个非常容易犯的错误</em></p>
<h2 id="7-参考链接"><a href="#7-参考链接" class="headerlink" title="7. 参考链接"></a>7. 参考链接</h2><p><a href="https://www.cnblogs.com/HuZihu/p/9761161.html">https://www.cnblogs.com/HuZihu/p/9761161.html</a></p>
<p><a href="https://blog.csdn.net/weixin_43008804/article/details/103087447">https://blog.csdn.net/weixin_43008804/article/details/103087447</a></p>
<p><a href="https://blog.csdn.net/weixin_36604953/article/details/102652160">https://blog.csdn.net/weixin_36604953/article/details/102652160</a></p>
]]></content>
      <categories>
        <category>Mathine Learning</category>
      </categories>
  </entry>
  <entry>
    <title>猫狗大战之CNN分类</title>
    <url>/2022/11/24/%E7%8C%AB%E7%8B%97%E5%A4%A7%E6%88%98%E4%B9%8BCNN%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<p>实践出真知！在kaggle上找的CNN经典案例练练手，猫狗大战属于图像分类问题。可以从此处下载所需要用到的数据<a href="https://www.kaggle.com/datasets/tongpython/cat-and-dog">Here!</a></p>
<span id="more"></span>

<h1 id="Import-required-libraries-x2F-dependencies"><a href="#Import-required-libraries-x2F-dependencies" class="headerlink" title="Import required libraries &#x2F; dependencies"></a>Import required libraries &#x2F; dependencies</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> Adam</span><br></pre></td></tr></table></figure>

<p><strong>tf.keras</strong>是用于构建和训练深度学习模型的 TensorFlow 高阶 API。它和TensorFlow相比具有以下的优点：</p>
<ol>
<li>对错误实现精确反馈，方便用户使用</li>
<li>将可配置的构造块组合在一起便能构建Keras模型，模块化</li>
<li>得益于上一点，我们可以编写自定义构造块，表达新的研究创意，即易于拓展</li>
</ol>
<p>而对于<code>from keras.models import Sequential</code>，在Keras中有两种深度学习的模型，分别是序列模型（Sequential）和通用模型（Model），两者的差异在于它们之间允许的不同的拓扑结构。详细地可以参考<a href="https://keras.io/models/sequential/">Keras官方文档</a>，这里我就简单讲解一下。Sequential模型结构是一种简单的线性结构，是多个网络层的堆叠（这说的网络层指的是卷积层、池化层等）。而Model模型结构是非线性的，允许多输入多输出的模型。利用Model模型我们设计非常复杂、任意拓扑的神经网络，可以说用法更灵活，但难度明显更大。</p>
<p><code>from keras import layers</code>允许我们使用各种各样的网络结构，是组成完整模型的零件。</p>
<ul>
<li><a href="https://blog.csdn.net/ssswill/article/details/88310812">CSDN-keras-layers:Dense,Embedding,LSTM</a></li>
<li><a href="https://blog.csdn.net/winter_python/article/details/108612636">CSDN-keras.layers汇总</a></li>
</ul>
<p><code>from tensorflow.keras.optimizers import Adam</code>这是一个名叫Adam的优化器，在监督学习中我们使用梯度下降算法的时候，学习率是一个很重要的指标。Adam能够让学习率从大到小自适应，实现效率与效果的兼得。</p>
<blockquote>
<p><a href="https://blog.csdn.net/I_canjnu/article/details/106035640">CSDN-机器学习之优化器keras.optimizers.Adam()详解</a></p>
</blockquote>
<h1 id="Generate-the-datasets-both-the-training-and-the-test-sets"><a href="#Generate-the-datasets-both-the-training-and-the-test-sets" class="headerlink" title="Generate the datasets, both the training and the test sets"></a>Generate the datasets, both the training and the test sets</h1><h2 id="define-the-paths-to-the-dataset"><a href="#define-the-paths-to-the-dataset" class="headerlink" title="define the paths to the dataset."></a>define the paths to the dataset.</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">training_path = <span class="string">&#x27;../input/cat-and-dog/training_set/training_set/&#x27;</span></span><br><span class="line">test_path = <span class="string">&#x27;../input/cat-and-dog/test_set/test_set/&#x27;</span></span><br></pre></td></tr></table></figure>


<h2 id="Create-dataset"><a href="#Create-dataset" class="headerlink" title="Create dataset"></a>Create dataset</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">image_size = (<span class="number">200</span>, <span class="number">200</span>)</span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">training_set = keras.preprocessing.image.image_dataset_from_directory(</span><br><span class="line">    directory=training_path,</span><br><span class="line">    class_names=[<span class="string">&#x27;cats&#x27;</span>, <span class="string">&#x27;dogs&#x27;</span>],</span><br><span class="line">    image_size=image_size,</span><br><span class="line">    batch_size=batch_size</span><br><span class="line">)</span><br><span class="line">test_set = keras.preprocessing.image.image_dataset_from_directory(</span><br><span class="line">    directory=test_path,</span><br><span class="line">    class_names=[<span class="string">&#x27;cats&#x27;</span>, <span class="string">&#x27;dogs&#x27;</span>],</span><br><span class="line">    image_size=image_size,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    </span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>keras.preprocessing.image.image_dataset_from_directory可以理解成数据预处理工具包，TensorFlow的官方文档在<a href="https://tensorflow.google.cn/api_docs/python/tf/keras/utils/image_dataset_from_directory">此</a>。它能够从文件夹里对子目录猫和狗分别生成标签0和1，将数据返回到tf.data.Dateset中，并且在加载的同时还会打乱数据。</p>
<h1 id="Visualize-some-images-from-the-training-set"><a href="#Visualize-some-images-from-the-training-set" class="headerlink" title="Visualize some images from the training set"></a>Visualize some images from the training set</h1><h2 id="visualize-the-training-set"><a href="#visualize-the-training-set" class="headerlink" title="visualize the training set"></a>visualize the training set</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">9</span>))</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cat_or_dog</span>(<span class="params">a</span>):</span><br><span class="line">    <span class="keyword">if</span> a==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Cat&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;Dog&#x27;</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> training_set.take(<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>):</span><br><span class="line">        plt.subplot(<span class="number">3</span>, <span class="number">4</span>, i+<span class="number">1</span>)</span><br><span class="line">        plt.imshow(images[i].numpy().astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line">        plt.title(<span class="string">f&#x27;<span class="subst">&#123;<span class="built_in">int</span>(labels[i])&#125;</span> (<span class="subst">&#123;cat_or_dog(<span class="built_in">int</span>(labels[i]))&#125;</span>)&#x27;</span>)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="visualize-the-test-set"><a href="#visualize-the-test-set" class="headerlink" title="visualize the test set"></a>visualize the test set</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">9</span>))</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cat_or_dog</span>(<span class="params">a</span>):</span><br><span class="line">    <span class="keyword">if</span> a==<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;Cat&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;Dog&#x27;</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> test_set.take(<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>):</span><br><span class="line">        plt.subplot(<span class="number">3</span>, <span class="number">4</span>, i+<span class="number">1</span>)</span><br><span class="line">        plt.imshow(images[i].numpy().astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line">        plt.title(<span class="string">f&#x27;<span class="subst">&#123;<span class="built_in">int</span>(labels[i])&#125;</span> (<span class="subst">&#123;cat_or_dog(<span class="built_in">int</span>(labels[i]))&#125;</span>)&#x27;</span>)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>要是对<code>plt.figure(figsize = (a, b))</code>和<code>plt.subplot()</code>不懂的话，可以看看<a href="https://blog.csdn.net/weixin_43685844/article/details/88982811">这里</a>。而这里的<code>dataset.take(1)</code>指的是取构建dataset的第一组元素，看样子一组好像有12个（因为下面的circle）,并且可以返回图片image和标签label两个值。</p>
<ul>
<li><a href="https://blog.csdn.net/weixin_43935696/article/details/112691755">CSDN-dataset.take</a></li>
<li><a href="https://www.jianshu.com/p/95f11648be2c">简书-dataset.take</a></li>
</ul>
<h1 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h1><blockquote>
<p>augmentation &#x2F;ˌɔːɡmenˈteɪʃ(ə)n&#x2F; 增大，增多；增加物；延长，扩充</p>
</blockquote>
<h2 id="define-some-layers-of-data-augmentation"><a href="#define-some-layers-of-data-augmentation" class="headerlink" title="define some layers of data augmentation"></a>define some layers of data augmentation</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">augmented_data = Sequential([</span><br><span class="line">    layers.RandomFlip(<span class="string">&#x27;horizontal&#x27;</span>),</span><br><span class="line">    layers.RandomRotation(<span class="number">0.1</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h2 id="visualize-it"><a href="#visualize-it" class="headerlink" title="visualize it"></a>visualize it</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">9</span>))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> test_set.take(<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>):</span><br><span class="line">        plt.subplot(<span class="number">3</span>, <span class="number">4</span>, i+<span class="number">1</span>)</span><br><span class="line">        augmented_image = augmented_data(images[<span class="number">0</span>])</span><br><span class="line">        plt.imshow(augmented_image.numpy().astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line">        plt.title(<span class="built_in">int</span>(labels[<span class="number">0</span>]))</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>tf.keras.layers.RandomFlip</strong>的作用是一个预处理层,在训练期间随机翻转图像<a href="https://runebook.dev/zh-CN/docs/tensorflow/keras/layers/randomflip">runebook</a>、<a href="https://keras.io/api/layers/preprocessing_layers/image_preprocessing/random_flip/">官方文档</a></p>
<h1 id="Build-a-model"><a href="#Build-a-model" class="headerlink" title="Build a model"></a>Build a model</h1><h2 id="build-the-model"><a href="#build-the-model" class="headerlink" title="build the model"></a>build the model</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Sequential([</span><br><span class="line">    layers.Conv2D(filters=<span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>, input_shape=(<span class="number">200</span>, <span class="number">200</span>, <span class="number">3</span>)),</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># preprocessing</span></span><br><span class="line">    layers.CenterCrop(<span class="number">180</span>, <span class="number">180</span>),</span><br><span class="line">    layers.Rescaling(scale=<span class="number">1.</span>/<span class="number">255</span>),</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># applying image data augmentation</span></span><br><span class="line">    layers.RandomFlip(<span class="string">&#x27;horizontal&#x27;</span>),</span><br><span class="line">    layers.RandomRotation(<span class="number">0.1</span>),</span><br><span class="line">    </span><br><span class="line">    layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>),</span><br><span class="line">    </span><br><span class="line">    layers.Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>),</span><br><span class="line">    </span><br><span class="line">    layers.Conv2D(filters=<span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>),</span><br><span class="line">    </span><br><span class="line">    layers.Conv2D(filters=<span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>),</span><br><span class="line">    </span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># output layer</span></span><br><span class="line">    layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<p>tf.keras.layers.Conv2D的filter为什么是128呢？这一点让我很疑惑。查阅资料发现许多都讲得模棱两可，不过大概可以解释的是这个filter指的是过滤器的深度。我没有查阅官方文档，后来发现<a href="https://zhuanlan.zhihu.com/p/498713060">知乎-tf.keras.layers.Conv2D参数详解</a>中的分析比较可取。”我几乎总是建议使用2的次方作为值”说明2的次方并不是filter的专利，并且我们需要根据数据集的复杂性和神经网络的深度来调整确切的值，也就是说filter的选择主观性强。</p>
<ol>
<li><a href="https://runebook.dev/zh-CN/docs/tensorflow/keras/layers/centercrop" title="runebook的Keras文档">tf.keras.layers.CenterCropCrop</a>对图片进行裁切，去两边留中心。官方解释–&gt;<em>the central portion of the images to target height and width</em></li>
<li><a href="https://docs.w3cub.com/tensorflow~2.9/keras/layers/rescaling.html" title="W3C的Keras文档">tf.keras.layers.Rescaling</a>To rescale an input in the [0, 255] range to be in the [0, 1] range, you would pass scale&#x3D;1.&#x2F;255</li>
<li>Dense层(全连接层）</li>
<li>Flatten层用来将输入“压平”，即把多维的输入一维化，常用在从卷积层到全连接层的过渡。Flatten不影响batch的大小。据说Convolution卷积层之后是无法直接连接Dense全连接层的，需要把Convolution层的数据压平（Flatten），然后才可以直接加Dense层。</li>
<li><a href="https://www.cnblogs.com/peng8098/p/keras_7.html#:~:text=%20Flatten%E5%B1%82%E7%94%A8%E6%9D%A5%E5%B0%86%E8%BE%93%E5%85%A5%E2%80%9C%E5%8E%8B%E5%B9%B3%E2%80%9D%EF%BC%8C%E5%8D%B3%E6%8A%8A%E5%A4%9A%E7%BB%B4%E7%9A%84%E8%BE%93%E5%85%A5%E4%B8%80%E7%BB%B4%E5%8C%96%EF%BC%8C%E5%B8%B8%E7%94%A8%E5%9C%A8%E4%BB%8E%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%88%B0%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E7%9A%84%E8%BF%87%E6%B8%A1%E3%80%82%20Flatten%E4%B8%8D%E5%BD%B1%E5%93%8Dbatch%E7%9A%84%E5%A4%A7%E5%B0%8F%E3%80%82,%E8%BE%93%E5%85%A5shape%EF%BC%9A%E4%BB%BB%E6%84%8F%EF%BC%8C%E4%BD%86%E8%BE%93%E5%85%A5%E7%9A%84shape%E5%BF%85%E9%A1%BB%E5%9B%BA%E5%AE%9A%E3%80%82%20%E5%BD%93%E4%BD%BF%E7%94%A8%E8%AF%A5%E5%B1%82%E4%B8%BA%E6%A8%A1%E5%9E%8B%E9%A6%96%E5%B1%82%E6%97%B6%EF%BC%8C%E9%9C%80%E8%A6%81%E6%8C%87%E5%AE%9Ainput_shape%E5%8F%82%E6%95%B0%20Permute%E5%B1%82%E5%B0%86%E8%BE%93%E5%85%A5%E7%9A%84%E7%BB%B4%E5%BA%A6%E6%8C%89%E7%85%A7%E7%BB%99%E5%AE%9A%E6%A8%A1%E5%BC%8F%E8%BF%9B%E8%A1%8C%E9%87%8D%E6%8E%92%EF%BC%8C%E4%BE%8B%E5%A6%82%EF%BC%8C%E5%BD%93%E9%9C%80%E8%A6%81%E5%B0%86RNN%E5%92%8CCNN%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%E6%97%B6%EF%BC%8C%E5%8F%AF%E8%83%BD%E4%BC%9A%E7%94%A8%E5%88%B0%E8%AF%A5%E5%B1%82%E3%80%82" title="cnblog">cnblog对Keras.layers各种层的介绍-比较准确</a></li>
</ol>
<h2 id="model-summary"><a href="#model-summary" class="headerlink" title="model summary"></a>model summary</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<p>使用keras构建深度学习模型，我们会通过model.summary()输出模型各层的参数状况。通过这些参数，可以看到模型各个层的组成（dense表示全连接层）。也能看到数据经过每个层后，输出的数据维度。还能看到Param，它表示每个层参数的个数，详情参考<a href="https://blog.csdn.net/ybdesire/article/details/85217688" title="CSDN">此处</a>。这一步是先将模型搭建起来，然后用summary查看相关的信息，不属于训练过程，所以运行不需要花多少时间。</p>
<h1 id="Train-the-model"><a href="#Train-the-model" class="headerlink" title="Train the model"></a>Train the model</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">epochs = <span class="number">50</span></span><br><span class="line"><span class="comment"># callbacks (save the model at each epoch)</span></span><br><span class="line">callbacks = [</span><br><span class="line">    keras.callbacks.ModelCheckpoint(<span class="string">&quot;checkpoints/model_at_&#123;epoch&#125;.h5&quot;</span>),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong>tf.keras.callbacks.ModelCheckpoint</strong>回调函数的作用是在每个训练期（epoch）后保存模型–&gt;<a href="https://www.w3cschool.cn/tensorflow_python/tf_keras_callbacks_ModelCheckpoint.html" title="W3C">Reference</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># compile the model</span></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=Adam(learning_rate=<span class="number">0.001</span>),</span><br><span class="line">    loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">    metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>Keras的model.compile参数介绍：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">   optimizer, </span><br><span class="line">   loss = <span class="literal">None</span>, </span><br><span class="line">   metrics = <span class="literal">None</span>, </span><br><span class="line">   loss_weights = <span class="literal">None</span>, </span><br><span class="line">   sample_weight_mode = <span class="literal">None</span>, </span><br><span class="line">   weighted_metrics = <span class="literal">None</span>, </span><br><span class="line">   target_tensors = <span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>常用的就下面三个参数：</p>
<ol>
<li>optimizer：优化器，用于控制梯度裁剪</li>
<li>loss：损失函数（或称目标函数、优化评分函数）</li>
<li>metrics：评价函数用于评估当前训练模型的性能。当模型编译后（compile），评价函数应该作为 metrics 的参数来输入。评价函数和损失函数相似，只不过评价函数的结果不会用于训练过程中。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fit the model</span></span><br><span class="line">model.fit(training_set, validation_data=test_set, epochs=epochs, callbacks=callbacks, verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>这里的fit起到将训练集和测试集载入模型的作用。但是还有另外一个fit_generator函数，作用相似。首先Keras中的fit()函数传入的x_train和y_train是被完整的加载进内存的,当然用起来很方便，但是如果我们数据量很大，那么是不可能将所有数据载入内存的，必将导致内存泄漏，这时候我们可以用fit_generator函数来进行训练。<br><a href="https://www.w3cschool.cn/article/62757839.html#:~:text=%E9%A6%96%E5%85%88Keras%E4%B8%AD%E7%9A%84fit,%28%29%E5%87%BD%E6%95%B0%E4%BC%A0%E5%85%A5%E7%9A%84x_train%E5%92%8Cy_train%E6%98%AF%E8%A2%AB%E5%AE%8C%E6%95%B4%E7%9A%84%E5%8A%A0%E8%BD%BD%E8%BF%9B%E5%86%85%E5%AD%98%E7%9A%84%2C%E5%BD%93%E7%84%B6%E7%94%A8%E8%B5%B7%E6%9D%A5%E5%BE%88%E6%96%B9%E4%BE%BF%EF%BC%8C%E4%BD%86%E6%98%AF%E5%A6%82%E6%9E%9C%E6%88%91%E4%BB%AC%E6%95%B0%E6%8D%AE%E9%87%8F%E5%BE%88%E5%A4%A7%EF%BC%8C%E9%82%A3%E4%B9%88%E6%98%AF%E4%B8%8D%E5%8F%AF%E8%83%BD%E5%B0%86%E6%89%80%E6%9C%89%E6%95%B0%E6%8D%AE%E8%BD%BD%E5%85%A5%E5%86%85%E5%AD%98%E7%9A%84%EF%BC%8C%E5%BF%85%E5%B0%86%E5%AF%BC%E8%87%B4%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%EF%BC%8C%E8%BF%99%E6%97%B6%E5%80%99%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E7%94%A8fit_generator%E5%87%BD%E6%95%B0%E6%9D%A5%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83%E3%80%82" title="W3C">参考</a>其中有一个常见的参数verbose–&gt;<em>verbose:默认值为1，是指在训练过程中日志的显示模式，取 1 时表示“进度条模式”，取2时表示“每轮一行”，取0时表示“安静模式”</em></p>
<h1 id="Visualize-the-predicted-images"><a href="#Visualize-the-predicted-images" class="headerlink" title="Visualize the predicted images"></a>Visualize the predicted images</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># visualize the predicted data</span></span><br><span class="line">loaded_model = keras.models.load_model(<span class="string">&#x27;checkpoints/model_at_50.h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">9</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">imgs</span>):</span><br><span class="line">    pred = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> loaded_model.predict(images.numpy().astype(<span class="string">&#x27;uint8&#x27;</span>)):</span><br><span class="line">        <span class="keyword">if</span> i[<span class="number">0</span>] &gt; <span class="number">.5</span>:</span><br><span class="line">            pred.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pred.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> pred</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> test_set.take(<span class="number">1</span>):</span><br><span class="line">    pred = predict(images)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>):</span><br><span class="line">        plt.subplot(<span class="number">3</span>, <span class="number">4</span>, i+<span class="number">1</span>)</span><br><span class="line">        plt.imshow(images[i].numpy().astype(<span class="string">&#x27;uint8&#x27;</span>))</span><br><span class="line">        plt.title(<span class="string">f&#x27;True: <span class="subst">&#123;<span class="built_in">int</span>(labels[i])&#125;</span>, Predicted: <span class="subst">&#123;pred[i]&#125;</span>&#x27;</span>)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>CNN</tag>
        <tag>比赛</tag>
        <tag>图像分类</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程</title>
    <url>/2022/11/23/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</url>
    <content><![CDATA[<p>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已</p>
<span id="more"></span>

<h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><p><a href="https://easyai.tech/ai-definition/feature-engineering/">特征工程</a>是机器学习工作流程中重要的组成部分，它将原始数据「翻译」成模型可理解的形式。</p>
<p>美国计算机科学家 Peter Norvig 说过两句经典名言</p>
<ol>
<li>基于大量数据的简单模型优于基于少量数据的复杂模型</li>
<li>更多的数据优于聪明的算法，而好的数据优于多的数据</li>
</ol>
<p>足以可见数据量和特征工程的重要性，不过数据量已经给定了，我们能做的只有特征工程。如何基于原来的数据发挥出更大的数据价值就是特征工程要做的事情。</p>
<p><em>在16年的一项调查中发现，<a href="https://whatsthebigdata.com/2016/05/01/data-scientists-spend-most-of-their-time-cleaning-data/">数据科学家</a>的工作中，有80%的时间都在获取、清洗和组织数据。构造机器学习流水线的时间不到20%…</em></p>
<h1 id="1-特征工程一些注意事项"><a href="#1-特征工程一些注意事项" class="headerlink" title="1.特征工程一些注意事项"></a>1.特征工程一些注意事项</h1><p>e.g. 人类是需要吃加工过的食物才行，这样更安全也更美味。机器算法模型也是类似，原始数据不能直接喂给模型，也需要对数据进行清洗、组织、转换。最后才能得到模型可以消化的特征。这样你对特征工程在数据和模型之间扮演的角色已经十分了解了吧？</p>
<h2 id="1-1-当前我对特征工程的理解"><a href="#1-1-当前我对特征工程的理解" class="headerlink" title="1.1 当前我对特征工程的理解"></a>1.1 当前我对特征工程的理解</h2><p>当前我对特征工程的理解仅仅停留在特征提取和特征选择，这样是待会会提到的内容。首先要知道，这两种方法都是降维的方法。特征选择后的字段是原数据字段的子集，也就是说删减了一些冗杂的对模型训练没有用的字段。特征提取理解成原来特征的映射，e.g.三个字段合并在一起表现的会比三个字段独立更好一些–&gt;<a href="https://blog.csdn.net/Neil_Pan/article/details/51940849">特征选择和特征提取区别</a></p>
<p>如果想要看看，特征工程具体是包括哪些具体步骤的，还可以参考<a href="https://blog.csdn.net/tiange_xiao/article/details/79723177#:~:text=%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%20%E6%98%AF%E4%BD%BF%E7%94%A8%E4%B8%93%E4%B8%9A%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86%E5%92%8C%E6%8A%80%E5%B7%A7%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%EF%BC%8C%E4%BD%BF%E5%BE%97%20%E7%89%B9%E5%BE%81%20%E8%83%BD%E5%9C%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%8A%E5%8F%91%E6%8C%A5%E6%9B%B4%E5%A5%BD%E7%9A%84%E4%BD%9C%E7%94%A8%E7%9A%84%E8%BF%87%E7%A8%8B%E3%80%82%20%E8%BF%87%E7%A8%8B%20%E5%8C%85%E5%90%AB%20%E4%BA%86%20%E7%89%B9%E5%BE%81,%E7%89%B9%E5%BE%81%20%E6%9E%84%E5%BB%BA%E3%80%81%20%E7%89%B9%E5%BE%81%20%E9%80%89%E6%8B%A9%E7%AD%89%E6%A8%A1%E5%9D%97%E3%80%82%20%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%20%E7%9A%84%E7%9B%AE%E7%9A%84%E6%98%AF%E7%AD%9B%E9%80%89%E5%87%BA%E6%9B%B4%E5%A5%BD%E7%9A%84%20%E7%89%B9%E5%BE%81%20%EF%BC%8C%E8%8E%B7%E5%8F%96%E6%9B%B4%E5%A5%BD%E7%9A%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E3%80%82">这里</a></p>
<h2 id="1-2-更好的业务逻辑表达"><a href="#1-2-更好的业务逻辑表达" class="headerlink" title="1.2 更好的业务逻辑表达"></a>1.2 更好的业务逻辑表达</h2><p>将特征工程理解成是业务逻辑的一种数学表达。说是说业务逻辑表达，其实实质上就是指为了解决机器学习中特定的问题。因为原始数据有很多种转换为特征的方式，我们需要选择那些能够「更好的表示业务逻辑」，从而更好的解决问题，而不是那些更简单的方法。</p>
<h2 id="1-3-提升机器学习性能"><a href="#1-3-提升机器学习性能" class="headerlink" title="1.3 提升机器学习性能"></a>1.3 提升机器学习性能</h2><p>性能意味着更短时间和更低成本，哪怕相同的模型，也会因为特征工程的不同而性能不同。所以我们需要选择那些可以发挥更好性能的特征工程</p>
<h1 id="2-特征选择"><a href="#2-特征选择" class="headerlink" title="2. 特征选择"></a>2. 特征选择</h1><p>特征选择是特征工程里的一个重要问题，其目标是寻找最优特征子集。特征选择能剔除不相关(irrelevant)或冗余(redundant)的特征，从而达到减少特征个数，提高模型精确度，减少运行时间的目的。另一方面，<strong>选取出真正相关的特征简化模型</strong>，协助理解数据产生的过程。并且常能听到“数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已”，由此可见其重要性。但是它几乎很少出现于机器学习书本里面的某一章。然而在机器学习方面的成功很大程度上在于如果使用特征工程。</p>
<p>之所以要考虑特征选择，是因为机器学习经常面临过拟合的问题。 过拟合的表现是模型参数太贴合训练集数据，模型在训练集上效果很好而在测试集上表现不好。简言之模型的泛化能力差。过拟合的原因是模型对于训练集数据来说太复杂，要解决过拟合问题，一般考虑如下方法：<a href="https://zhuanlan.zhihu.com/p/74198735#:~:text=%E4%B9%8B%E6%89%80%E4%BB%A5%E8%A6%81%E8%80%83%E8%99%91%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%EF%BC%8C%E6%98%AF%E5%9B%A0%E4%B8%BA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%B8%B8%E9%9D%A2%E4%B8%B4%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E9%97%AE%E9%A2%98%E3%80%82%20%E8%BF%87%E6%8B%9F%E5%90%88,%E7%9A%84%E8%A1%A8%E7%8E%B0%E6%98%AF%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%20%E5%A4%AA%E8%B4%B4%E5%90%88%E8%AE%AD%E7%BB%83%E9%9B%86%E6%95%B0%E6%8D%AE%20%EF%BC%8C%E6%A8%A1%E5%9E%8B%E5%9C%A8%E8%AE%AD%E7%BB%83%E9%9B%86%E4%B8%8A%E6%95%88%E6%9E%9C%E5%BE%88%E5%A5%BD%E8%80%8C%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%8A%E8%A1%A8%E7%8E%B0%E4%B8%8D%E5%A5%BD%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E5%9C%A8%E9%AB%98%E6%96%B9%E5%B7%AE%E3%80%82">参考</a></p>
<ol>
<li>收集更多数据</li>
<li>通过正则化引入对复杂度的惩罚</li>
<li>选择更少参数的简单模型</li>
<li>对数据降维（降维有两种方式：特征选择和特征抽取）</li>
</ol>
<p>其中第1条一般是很难做到的，一般主要采用第2和第4点</p>
<h1 id="3-特征提取"><a href="#3-特征提取" class="headerlink" title="3. 特征提取"></a>3. 特征提取</h1><p>像上面所说，将特征提取理解成原来特征的映射，只是一种不同于特征选择的选取字段的方式罢了。</p>
<h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h1><ul>
<li><a href="https://blog.csdn.net/hren_ron/article/details/80914491">了解生成特征子集的搜索方式</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/74198735#:~:text=%E4%B9%8B%E6%89%80%E4%BB%A5%E8%A6%81%E8%80%83%E8%99%91%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%EF%BC%8C%E6%98%AF%E5%9B%A0%E4%B8%BA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%B8%B8%E9%9D%A2%E4%B8%B4%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E9%97%AE%E9%A2%98%E3%80%82%20%E8%BF%87%E6%8B%9F%E5%90%88,%E7%9A%84%E8%A1%A8%E7%8E%B0%E6%98%AF%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%20%E5%A4%AA%E8%B4%B4%E5%90%88%E8%AE%AD%E7%BB%83%E9%9B%86%E6%95%B0%E6%8D%AE%20%EF%BC%8C%E6%A8%A1%E5%9E%8B%E5%9C%A8%E8%AE%AD%E7%BB%83%E9%9B%86%E4%B8%8A%E6%95%88%E6%9E%9C%E5%BE%88%E5%A5%BD%E8%80%8C%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%8A%E8%A1%A8%E7%8E%B0%E4%B8%8D%E5%A5%BD%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E5%9C%A8%E9%AB%98%E6%96%B9%E5%B7%AE%E3%80%82">详细地介绍了特征选择的方法</a></li>
<li><a href="https://asialee.blog.csdn.net/article/details/84863410?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-84863410-blog-79723177.pc_relevant_multi_platform_whitelistv3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-84863410-blog-79723177.pc_relevant_multi_platform_whitelistv3&utm_relevant_index=6">机器学习特征工程的具体步骤</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html">sklearn.select_feature.SelectKBest官方文档</a></li>
<li><a href="https://www.cnblogs.com/ai-ldj/p/14269023.html">SelectKBest博客园</a></li>
<li><a href="https://blog.csdn.net/moonoon1/article/details/120074949">SelectKBest-CSDN</a></li>
</ul>
]]></content>
      <categories>
        <category>Mathine Learning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>维度灾难</title>
    <url>/2022/11/23/%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE/</url>
    <content><![CDATA[<p>今天學習機器學習的時候，發現有<em>維度災難</em>這個東西。挺感興趣的，於是一探究竟！</p>
<span id="more"></span>

<h1 id="机器学习中的维度灾难"><a href="#机器学习中的维度灾难" class="headerlink" title="机器学习中的维度灾难"></a>机器学习中的维度灾难</h1><p>在介绍机器学习的维度灾难之前，我推荐给大家一个网站，名字虽然说是<a href="https://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/">计算机视觉的傻瓜书</a>，但是有关机器学习的答疑部分它做得还是蛮好的。除此之外还有<a href="https://www.kdnuggets.com/news/index.html">KDnuggest</a>，也是有关机器学习的论坛。</p>
<p>本文是参考<a href="https://www.jianshu.com/p/867193608bbd">简书-红色石头Will</a>所得到的观点，虽然他是翻译<a href="https://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/">计算机视觉的傻瓜书</a>的，但是对于我理解维度灾难起着指导方向的作用。</p>
<h2 id="1-介绍维度灾难"><a href="#1-介绍维度灾难" class="headerlink" title="1.介绍维度灾难"></a>1.介绍维度灾难</h2><p>维度灾难是在设计一个分类器的时候需要注意的问题。为了得到更好的分类效果，我们可以无限的增加特征。但是事实上，特征数量超过一定值的时候，分类器的效果反而会下降。这种由于特征数量太多导致的分类效果下降的情况，就被称作是<strong>维度灾难</strong>。</p>
<h2 id="2-维度灾难与过拟合"><a href="#2-维度灾难与过拟合" class="headerlink" title="2.维度灾难与过拟合"></a>2.维度灾难与过拟合</h2><p>貌似特征越多，越有可能实现正确分类，但是情况并非如此。一个直观的情况时，随着特征维度的增加，训练样本在特征空间中的密度是呈指数下降的。</p>
<blockquote>
<p>样本数不变，但是特征空间不断地增加，那训练样本在特征空间中的密度岂不是就是呈指数下降的？</p>
</blockquote>
<p>如果我们继续增加特征，整个特征空间维度增加，并变得越来越稀疏。由于稀疏性，我们更加容易找到一个超平面来实现分类。这是因为随着特征数量变得无限大，训练样本在最佳超平面的错误侧的可能性将会变得无限小。然而，如果我们将高维的分类结果投影到低维空间中，将会出现一个严重的问题。</p>
<p>比如说样本数据在3D是线性可分的，但是在2D却并非如此。事实上，增加第三个维度来获得最佳的线性分类效果，等同于在低维特征空间中使用非线性分类器。其结果是，分类器学习了训练数据的噪声和异常，而对样本外的数据拟合效果并不理想，甚至很差。这个概念称为过拟合，是维度灾难的一个直接后果。</p>
<p><em>换句话讲，如果增加特征维度，为了覆盖同样的特征值范围，防止过拟合，需要用到的样本数就会呈指数型增长！</em></p>
<h2 id="3-维度灾难与数据稀疏程度分布不均"><a href="#3-维度灾难与数据稀疏程度分布不均" class="headerlink" title="3.维度灾难与数据稀疏程度分布不均"></a>3.维度灾难与数据稀疏程度分布不均</h2><p>我们展示了维度灾难会引起训练数据的稀疏化。使用的特征越多，数据就会变得越稀疏，从而导致分类器的分类效果就会越差。维度灾难还会造成<strong>搜索空间的数据稀疏程度</strong>分布不均。事实上，围绕原点的数据（在超立方体的中心）比在搜索空间的角落处的数据要稀疏得多。</p>
<p>举例2D，如果大部分的样本都落在了单位内接圆里的话，会更容易分类。但是在高维的空间中，大部分的训练数据都是分布在定义为特征空间的超立方体的角落处，导致难以分类。、</p>
<p>对于8维的超球体，大约98%的数据集中在它256个角落处。其结果是，当特征空间的维度变得无限大时，从样本点到质心的最大、最小欧氏距离的差值与其最小欧式距离的比值趋于零。因此，距离测量在高维空间中逐渐变得无效。因为分类器是基于这些距离测量的（例如Euclidean距离、Mahalanobis距离、Manhattan距离），所以低维空间特征更少，分类更加容易。同样地，在高维空间的高斯分布会变平坦且尾巴更长。</p>
<h2 id="4-如何避免维度灾难"><a href="#4-如何避免维度灾难" class="headerlink" title="4.如何避免维度灾难"></a>4.如何避免维度灾难</h2><p>很遗憾，在分类问题中，没有固定的规则来指定该使用多少特征。事实上，用多少特征量取决于你训练样本的数量、决策边界的复杂性和使用的是啥分类器。</p>
<p>比如说一些非线性决策边界的分类器（e.g. 神经网络、KNN分类器、决策树等），它们的分类效果虽然好，但是泛化能力差容易发生过拟合，这个时候就需要降低点维度。如果使用泛化能力稍微好点的（e.g. 贝叶斯分类器、线性分类器），那么就可以使用稍微多一点的特征。</p>
<h2 id="5-参考链接"><a href="#5-参考链接" class="headerlink" title="5.参考链接"></a>5.参考链接</h2><blockquote>
<p><a href="https://www.jianshu.com/p/867193608bbd">简书</a><br><a href="https://cloud.tencent.com/developer/article/1143269">手工特征选取降维</a><br><a href="https://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html">原文</a></p>
</blockquote>
]]></content>
      <categories>
        <category>Mathine Learning</category>
      </categories>
  </entry>
  <entry>
    <title>网格搜索</title>
    <url>/2022/11/24/%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2/</url>
    <content><![CDATA[<p>在进行机器学习的过程中，最为核心的概念就是参数了，要得到最好的参数可以采取网格搜索策略。网格搜索是应用最广泛的超参数搜索算法，网格搜索通过查找搜索范围内的所有的点，来确定最优值。</p>
<span id="more"></span>

<h1 id="调节超参数的方法-GridSearchCV网格搜索"><a href="#调节超参数的方法-GridSearchCV网格搜索" class="headerlink" title="调节超参数的方法-GridSearchCV网格搜索"></a>调节超参数的方法-GridSearchCV网格搜索</h1><p><em>在进行机器学习的过程中，最为核心的概念就是参数了，而参数又可以分为模型参数和超参数。模型参数指的是我们使用的模型根据训练数据的分布学习到的参数，这一部分是不需要我们人为的先验知识。而超参数是在开始学习之前需要设置的一组参数，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给模型选择一组最优的超参数，以提高学习的性能与效果。</em></p>
<p>这里简单介绍一下常用的超参数调参方法:除了网格搜索，还有随机搜索、贝叶斯优化和自动超参搜索（遗传算法GA）</p>
<h2 id="网格搜索"><a href="#网格搜索" class="headerlink" title="网格搜索"></a>网格搜索</h2><p>网格搜索是应用最广泛的超参数搜索算法，网格搜索通过查找搜索范围内的所有的点，来确定最优值。一般通过给出较大的搜索范围以及较小的步长，网格搜索是一定可以找到全局最大值或最小值的。但是，网格搜索一个比较大的问题是，它<strong>十分消耗计算资源</strong>，特别是需要调优的超参数比较多的时候。在比赛中，需要调参的模型数量与对应的超参数比较多，而涉及的数据量又比较大，因此相当的耗费时间。<em>此外，由于给出的超参数组合比较多，因此一般都会固定多数参数，分步对1~2个超参数进行调解，这样能够减少时间但是缺难以自动化进行，而且由于目标参数一般是非凸的，因此容易陷入局部最小值。</em></p>
<p><a href="https://www.jianshu.com/p/5378ef009cae">原作者</a>是用网格搜索来寻找LightGBM的最优超参数，这里我尝试用它来寻找XGBoost的最优超参数。一方面当做学习，另一方面是当做完成上一次机器学习的拓展作业。</p>
<h2 id="简单介绍需要向GridSearchCV内传什么东西？"><a href="#简单介绍需要向GridSearchCV内传什么东西？" class="headerlink" title="简单介绍需要向GridSearchCV内传什么东西？"></a>简单介绍需要向GridSearchCV内传什么东西？</h2><p>要实现网格搜索，肯定得暴力遍历超参数。查找GridSearchCV函数的参数，其中有一项是含有待优化超参的字典。<a href="https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/model_selection/_search.py#L867">官方</a>给的参数如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=<span class="literal">None</span>, n_jobs=<span class="literal">None</span>, iid=<span class="string">&#x27;deprecated&#x27;</span>, refit=<span class="literal">True</span>, cv=<span class="literal">None</span>, verbose=<span class="number">0</span>, pre_dispatch=<span class="string">&#x27;2*n_jobs&#x27;</span>, error_score=nan, return_train_score=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>其中重要的参数说明如下：</p>
<ol>
<li>estimator：表示选择使用的分类器，并且需要传入除了需要确定最佳的参数之外的其他参数。<em>（还有什么参数？不是很清楚）</em>每一个分类器都需要一个scoring参数，或者说是score方法，例子如下：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">estimator = RandomForestClassifier(min_sample_split=100,min_samples_leaf = 20,max_depth = 8,max_features = &#x27;sqrt&#x27; , random_state =10)</span><br></pre></td></tr></table></figure></li>
<li>param_grid：需要最优化的参数的取值，值为字典或者列表，例如：</li>
</ol>
<p><code>param_grid = param_test1, param_test1 = &#123;&#39;n_estimators&#39; : range(10,71,10)&#125;</code><br>或者另外一种表达形式：<br><code>param_grid = [&#123;&#39;n_estimators&#39;: [3, 10, 30],&#39;max_features&#39;: [2, 4, 6, 8]&#125;,&#123;&#39;bootstrap&#39;: [False],&#39;n_estimators&#39;: [3, 10],&#39;max_features&#39;: [2, 3, 4]&#125;,</code><br>3. scoring &#x3D; None ：模型评价标准，默认为None，这时需要使用score函数；或者如scoring &#x3D; ‘roc_auc’，根据所选模型不同，评价准则不同，字符串（函数名），或是可调用对象，需要其函数签名，形如：scorer(estimator，X，y）；如果是None，则使用estimator的误差估计函数。<br>4. n_jobs &#x3D; 1 ： n_jobs：并行数，默认为1，当n_jobs &#x3D; -1：表示使用所有处理器（建议）<br>5. refit &#x3D; True ：默认为True，程序将会以交叉验证训练集得到的最佳参数，重新对所有可能的训练集与开发集进行，作为最终用于性能评估的最佳模型参数。即在搜索参数结束后，用最佳参数结果再次fit一遍全部数据集（不用管即可）<br>6. cv &#x3D; None：交叉验证参数，默认None，使用五折交叉验证。指定fold数量，默认为5(之前版本为3)，也可以是yield训练&#x2F;测试数据的生成器</p>
<h1 id="寻找XGBoost的参数及一般定义范围"><a href="#寻找XGBoost的参数及一般定义范围" class="headerlink" title="寻找XGBoost的参数及一般定义范围"></a>寻找XGBoost的参数及一般定义范围</h1><p>首先要知道xgb.XGBRegressor的<a href="https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters">参数分布</a>,这一点可以靠查询官方文档，或者寻找<a href="https://www.codeleading.com/article/77024318818/">相关的资料</a>进行补充。由于代码格式我想参照<a href="https://www.jianshu.com/p/5378ef009cae">简书某博主</a>的写法，所以需要找到xgboost的参数并且规定遍历的范围。</p>
<p>找到机器学习实验二的XGBoost部分代码，然后根据参数规范范围。因为现在对参数并不熟悉，我打算对参数的范围规定的大一点，以便可以找到全局最优解。</p>
<h1 id="装库跑代码"><a href="#装库跑代码" class="headerlink" title="装库跑代码"></a>装库跑代码</h1><p>在Anaconda上执行命令<strong>conda install py-xgboost</strong>，下载到所需要用到的xgboost库（另外还有<strong>from sklearn.model_selection import GridSearchCV</strong>）。我发现上面下载xgboost库的conda指令慢的离谱（其实<strong>pip install xgboost</strong>也很慢），于是换清华源<strong>pip install xgboost -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></strong>，速度嘎嘎起飞。虽然也是在Anaconda上执行的pip指令，但是pip用起来真就是比conda舒服。</p>
<p>在<a href="https://www.jianshu.com/p/5378ef009cae">参考代码</a>处我们发现了有一段代码很奇怪,<code>regr = lgb.LGBMRegressor(**params)</code>这里的 **号是什么意思呢？这里的 **params其实指的是，你在上面代码所输入的字典形式的变量。如果你想研究更多有关*和**的实例，可以参考以下这篇<a href="https://blog.csdn.net/zkk9527/article/details/88675129">博文</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">import numpy as np</span><br><span class="line">import xgboost as xgb</span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def GridSearch(clf, params, X, y):</span><br><span class="line">    cscv = GridSearchCV(</span><br><span class="line">        clf, params, scoring=&quot;neg_mean_squared_error&quot;, n_jobs=1, cv=5)</span><br><span class="line">    cscv.fit(X, y)</span><br><span class="line">    print(cscv.cv_results_)</span><br><span class="line">    print(cscv.best_params_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def Dataprocessing(trainPath):</span><br><span class="line">    training_set = pd.read_csv(trainPath)</span><br><span class="line">    training_set.drop(&quot;Id&quot;, axis=1, inplace=True)</span><br><span class="line">    training_set = training_set.drop(training_set[(</span><br><span class="line">        training_set[&#x27;GrLivArea&#x27;] &gt; 4000) &amp; (training_set[&#x27;SalePrice&#x27;] &lt; 300000)].index)</span><br><span class="line">    train_y = training_set.SalePrice.values</span><br><span class="line">    train_x = training_set.drop(&quot;SalePrice&quot;, axis=1, inplace=True)</span><br><span class="line">    return train_x, train_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    train_x, train_y = Dataprocessing(&#x27;train.csv&#x27;)</span><br><span class="line"></span><br><span class="line">    params = &#123;</span><br><span class="line">        &#x27;colsample_bytree&#x27;: 0.4603,</span><br><span class="line">        &#x27;gamma&#x27;: 0.0468,</span><br><span class="line">        &#x27;learning_rate&#x27;: 0.05,</span><br><span class="line">        &#x27;max_depth&#x27;: 3,</span><br><span class="line">        &#x27;min_child_weight&#x27;: 1.7817,</span><br><span class="line">        &#x27;n_estimators&#x27;: 2200,</span><br><span class="line">        &#x27;reg_alpha&#x27;: 0.4640,</span><br><span class="line">        &#x27;reg_lambda&#x27;: 0.8571,</span><br><span class="line">        &#x27;subsample&#x27;: 0.5213,</span><br><span class="line">        &#x27;silent&#x27;: 1,</span><br><span class="line">        &#x27;random_state&#x27;: 7,</span><br><span class="line">        &#x27;nthread&#x27;: -1</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    regr = xgb.XGBRegressor(**params)</span><br><span class="line"></span><br><span class="line">    adj_params = &#123;</span><br><span class="line">        &#x27;colsample_bytree&#x27;: np.arange(0.1, 1, 0.1),</span><br><span class="line">        &#x27;gamma&#x27;: [0.01, 0.1, 1],</span><br><span class="line">        &#x27;learning_rate&#x27;: [0.01, 0.1, 1],</span><br><span class="line">        &#x27;max_depth&#x27;: range(1, 11),</span><br><span class="line">        &#x27;min_child_weight&#x27;: np.arange(0.1, 2, 0.1),</span><br><span class="line">        &#x27;n_estimators&#x27;: range(300, 1000, 100),</span><br><span class="line">        &#x27;reg_alpha&#x27;: [0.01, 0.1, 1],</span><br><span class="line">        &#x27;reg_lambda&#x27;: [0.01, 0.1, 1],</span><br><span class="line">        &#x27;subsample&#x27;: [0.01, 0.1, 1],</span><br><span class="line">        # &#x27;silent&#x27;:1,</span><br><span class="line">        &#x27;random_state&#x27;: range(1, 11),</span><br><span class="line">        # &#x27;nthread&#x27;:-1</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    GridSearch(regr, adj_params, train_x, train_y)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>代码实在是跑不动，估计是参数有些缺了的问题，具体操作方法先贴在这里，等到下次有项目的时候再继续研究吧！</p>
<h2 id="随机搜索"><a href="#随机搜索" class="headerlink" title="随机搜索"></a>随机搜索</h2><p>与网格搜索相比，随机搜索并没有尝试所有给定的参数值，而是从指定的分布中采样固定数量的参数设置。它的理论依据是，如果随即样本点集足够大，那么也可以找到全局的最大或最小值，或它们的近似值。通过对搜索范围的随机取样，随机搜索一般会比网格搜索要快一些。但是和网格搜索的快速版（非自动版）相似，结果也是没法保证的。</p>
<p>随机搜索的过程如下，使用方法与网格搜索完全一致：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import lightgbm as lgb</span><br><span class="line">from sklearn.model_selection import  RandomizedSearchCV</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def RandomSearch(clf, params, X, y):</span><br><span class="line">    rscv = RandomizedSearchCV(clf, params, scoring=&#x27;neg_mean_squared_error&#x27;, n_jobs=1, cv=5)</span><br><span class="line">    rscv.fit(X, y)</span><br><span class="line"></span><br><span class="line">    print(rscv.cv_results_)</span><br><span class="line">    print(rscv.best_params_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    train_X, train_y = get_data()</span><br><span class="line"></span><br><span class="line">    param = &#123;</span><br><span class="line">        &#x27;objective&#x27;: &#x27;regression&#x27;,</span><br><span class="line">        &#x27;n_estimators&#x27;: 275,</span><br><span class="line">        &#x27;max_depth&#x27;: 6,</span><br><span class="line">        &#x27;min_child_samples&#x27;: 20,</span><br><span class="line">        &#x27;reg_lambd&#x27;: 0.1,</span><br><span class="line">        &#x27;reg_alpha&#x27;: 0.1,</span><br><span class="line">        &#x27;metric&#x27;: &#x27;rmse&#x27;,</span><br><span class="line">        &#x27;colsample_bytree&#x27;: 1,</span><br><span class="line">        &#x27;subsample&#x27;: 0.8,</span><br><span class="line">        &#x27;num_leaves&#x27; : 40,</span><br><span class="line">        &#x27;random_state&#x27;: 2018</span><br><span class="line">        &#125;</span><br><span class="line">    regr = lgb.LGBMRegressor(**param)</span><br><span class="line"></span><br><span class="line">    adj_params = &#123;&#x27;n_estimators&#x27;: range(100, 400, 10),</span><br><span class="line">                 &#x27;min_child_weight&#x27;: range(3, 20, 2),</span><br><span class="line">                 &#x27;colsample_bytree&#x27;: np.arange(0.4, 1.0),</span><br><span class="line">                 &#x27;max_depth&#x27;: range(5, 15, 2),</span><br><span class="line">                 &#x27;subsample&#x27;: np.arange(0.5, 1.0, 0.1),</span><br><span class="line">                 &#x27;reg_lambda&#x27;: np.arange(0.1, 1.0, 0.2),</span><br><span class="line">                 &#x27;reg_alpha&#x27;: np.arange(0.1, 1.0, 0.2),</span><br><span class="line">                 &#x27;min_child_samples&#x27;: range(10, 30)&#125;</span><br><span class="line"></span><br><span class="line">    RandomSearch(regr , adj_params , train_X, train_y)</span><br></pre></td></tr></table></figure>

<h2 id="贝叶斯优化"><a href="#贝叶斯优化" class="headerlink" title="贝叶斯优化"></a>贝叶斯优化</h2><p>贝叶斯优化用于机器学习调参由J. Snoek(2012)提出，主要思想是，给定优化的目标函数(广义的函数，只需指定输入和输出即可，无需知道内部结构以及数学性质)，通过不断地添加样本点来更新目标函数的后验分布(高斯过程,直到后验分布基本贴合于真实分布。简单的说，就是考虑了上一次参数的信息，从而更好的调整当前的参数。</p>
<p><em>贝叶斯优化与常规的网格搜索或者随机搜索的区别是：</em></p>
<ol>
<li>贝叶斯调参采用高斯过程，考虑之前的参数信息，不断地更新先验；网格搜索未考虑之前的参数信息</li>
<li>贝叶斯调参迭代次数少，速度快；网格搜索速度慢,参数多时易导致<strong>维度爆炸</strong></li>
<li>贝叶斯调参针对非凸问题依然稳健；网格搜索针对非凸问题易得到局部优最</li>
</ol>
<p>如果想要深究贝叶斯优化，可以参考<a href="https://www.sohu.com/a/165565029_465975">这里</a></p>
<h2 id="其他方法"><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h2><p>其他常见的超参数优化方法还有比如自动超参搜索（遗传算法）等等，方法总比问题多，对不同的问题总需要根据情况使用不同的方法来解决。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://www.sohu.com/a/165565029_465975">搜狐新闻-贝叶斯优化细究</a></li>
<li><a href="https://www.jianshu.com/p/d240dbd62d45">简书-炼丹美学</a></li>
<li><a href="https://www.cnblogs.com/dalege/p/14175192.html">博客园-具体使用GridSearchCV</a></li>
<li><a href="https://www.codeleading.com/article/77024318818/">代码先锋网-具体调试LightGBM</a><em>让我清楚了，调参也是得按顺序来的，没有说一口气调完全部</em></li>
<li><a href="https://blog.csdn.net/csiao_Bing/article/details/84978725">CSDN-XGBoost参数详解</a></li>
<li><a href="https://blog.csdn.net/Ling_Ze/article/details/126045472">CSDN-XGBoost参数详解</a></li>
<li><a href="https://www.jianshu.com/p/5378ef009cae">简书-超参调节之我主要参考!</a></li>
</ol>
]]></content>
      <categories>
        <category>Mathine Learning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>调参</tag>
      </tags>
  </entry>
  <entry>
    <title>docker打开报错</title>
    <url>/2022/12/11/docker%E6%89%93%E5%BC%80%E6%8A%A5%E9%94%99/</url>
    <content><![CDATA[<p>docker之前安装我记得是不需要翻墙的（可能也是用镜像源装的），但是这次直接去到官网安装，发现要翻墙…不仅如此，我安装好docker运行后竟然有报错–&gt;Hardware assisted virtualization and data execution protection must be enabled in the BIOS🤨</p>
<span id="more"></span>

<h1 id="需要检查的第一个地方-BIOS"><a href="#需要检查的第一个地方-BIOS" class="headerlink" title="需要检查的第一个地方-BIOS"></a>需要检查的第一个地方-BIOS</h1><p>我打开任务管理器，进入blos界面，发现确实开启了虚拟化。明明是在blos已经启用了虚拟硬件了，怎么还会报错呢？</p>
<h1 id="需要检查的第二个地方-Windows功能"><a href="#需要检查的第二个地方-Windows功能" class="headerlink" title="需要检查的第二个地方-Windows功能"></a>需要检查的第二个地方-Windows功能</h1><p>于是我打开了启用或关闭windows的界面，检查Hyper-V Manager是否安装以及开启。结果发现Hyper—V也是打开的，看来并不是这里出了问题。按照docker的官方文档也并不能成功解决问题。</p>
<h1 id="我成功的方法-CMD"><a href="#我成功的方法-CMD" class="headerlink" title="我成功的方法-CMD"></a>我成功的方法-CMD</h1><ol>
<li><p>首先要用管理员工权限运行cmd，然后使用管理员权限运行命令：<code>bcdedit /set hypervisorlaunchtype off</code></p>
</li>
<li><p>然后执行Hyper-V的命令：<code>bcdedit /set hypervisorlaunchtype auto</code></p>
</li>
<li><p>最后重启电脑就OK啦！</p>
</li>
</ol>
<p>我的操作是重启这个服务，如果问题仍然存在的话，那么就可能需要重安装Hyper-V了😭😭😭</p>
]]></content>
      <categories>
        <category>report an error</category>
      </categories>
      <tags>
        <tag>安装</tag>
      </tags>
  </entry>
  <entry>
    <title>关于那些我一直搞不懂的市制单位</title>
    <url>/2022/12/13/%E5%85%B3%E4%BA%8E%E9%82%A3%E4%BA%9B%E6%88%91%E4%B8%80%E7%9B%B4%E6%90%9E%E4%B8%8D%E6%87%82%E7%9A%84%E5%B8%82%E5%88%B6%E5%8D%95%E4%BD%8D/</url>
    <content><![CDATA[<p>高秋马肥健，挟矢射汉月！又到了晒腊肉和腊肠的季节…🐎🐎🐎</p>
<span id="more"></span>

<p>上面那句诗出自杜甫的《<a href="https://www.gushiciqu.com/shiwen/pinyin-a474546.html">留花门</a>》，其实它并不是用来描绘到了秋冬该晒腊肠和腊肉的季节，而是我一想到腊肉不知道为何就联想起肥马，想到肥马就想到这诗句了！其实它们之间是一点关系都没有的啦！今天到此我只是想吐槽一些事情…</p>
<p>今天遣返回乡的第八天，其中不能包括回到家的那天，因为那天空着肚子从早到晚都在车上，精神状态可谓是全无，也自然没法提什么创作了吧？不过现在的生活还算是日趋正常，习惯了宿舍里的生活作息，家里的倒时差生活目前总算是适应过来了😊</p>
<p>回了家，除了忙着学校的杂事，还得照料父母的情感，毕竟不听话就在耳边疯狂输出是谁都受不了啊！这不前几天我妈晒好了腊肠和腊肉，但是挂在窗边老有🦅麻雀🦅来偷吃，委托我去买铁网保护食材。去了五金店里，老板问要多少尺？虽然<strong>尺</strong>这个字从小听到大，但是你说要多少尺我怎么知道？于是我上网上找了一些市制单位，便豁然开朗…</p>
<blockquote>
<p>1米 &#x3D; 1公尺 &#x3D; 3市尺 &#x3D; 3.2808英尺 &#x3D; 1.0936码yard<br>1市尺 &#x3D; 1&#x2F;3米 &#x3D; 10寸</p>
</blockquote>
<p>原来如此，所以1寸大概就是3.33厘米，1尺大概就是33.33厘米，这算是消除了我多年以来的疑惑。</p>
<blockquote>
<p>1英尺 &#x3D; 30.48厘米 &#x3D; 1&#x2F;3码 &#x3D; 12英寸<br>1英寸 &#x3D; 2.54厘米 </p>
</blockquote>
<p>寸比英寸略大？怪不得电视机不卖寸的！😆😆😆</p>
<p><em>尺的话有公尺、市尺和英尺，其中公尺指的就是一米，市尺是公尺的三分之一，英尺嘛，记住比市尺略小就好了</em></p>
<p>1寸等于3.33厘米我觉得生活中还是很常见的，这个1市尺等于10寸还算好记，不过为什么1英寸要等于12英寸这种数字呢？真是不理解…</p>
<p>还有这个比1米略小的码yard单位，我还以为是鞋子的码数，结果算了算好像并不是这样…😅</p>
<p>既然看到这里，不妨再想想外婆家的田，天天说有几亩几亩的，这让没有概念的我像个十足的门外汉（虽然也就是门外汉了）</p>
<blockquote>
<p>1公顷&#x3D;10000平方米&#x3D;100公亩&#x3D;15市亩<br>1公亩&#x3D;100平方米<br>1亩&#x3D;666.67平方米</p>
</blockquote>
<p>亩竟然还分市亩和公亩，这么麻烦，还是不记了，反正以后没田种😨</p>
]]></content>
      <categories>
        <category>Home Life</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>吐槽</tag>
      </tags>
  </entry>
</search>
